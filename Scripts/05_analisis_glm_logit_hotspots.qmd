---
title: "Análisis de regresión logit de hotspots"
author: "Carlos M. Guío Blanco"
format: html
editor: visual
---

En este cuaderno se presenta el análisis mediante la metodología de modelos lineares generalizados, para la función logística. El modelo importa archivos csv que contienen los datos procesados de imágenes satelitales Landsat 8 y SRTM para explicar la ocurrencia de “hotspots” de pedodiversidad.

Las covariables se eligieron partiendo de la hipótesis, que la diversidad de suelos está condicionada por la diversidad de otras variables formadoras cuyos proxis de largo plazo pueden derivarse de imágenes satelitales: geomorfología, clima, hidrología. La vegetación, debido a su alta variabilidad temporal, no se utiliza como proxi para explicar la diversidad de suelos, que se entiende como un proceso que puede durar cientos a millones de años.

```{r configuracion}
#Para exportar como .R plano
# knitr::purl('05_analisis_glm_logit_hotspots.qmd')

if (!"pacman" %in% installed.packages()) install.packages("pacman")
pacman::p_load(
  here,         # manejo de rutas relativas al proyecto
  remotes,      # instalar paquetes desde GitHub
  sf,           # manejo de objetos espaciales vectoriales
  dplyr,        # manipulación de data frames (verbos como filter, mutate, join)
  tidyr,        # transformación de datos (pivot_longer, pivot_wider, etc.)
  readr,        # lectura rápida de archivos CSV
  performance,  # métricas de modelos (R2 de Tjur, VIF, etc.)
  ggdist,       # distribución visual de predicciones (stat_halfeye, intervalos)
  scales,       # transformación de escalas (log10, percentiles, breaks)
  ggplot2,      # sistema de gráficos base
  grid,
  GGally,       # mapa de correlación
  sjPlot,       # visualización de modelos y efectos marginales
  spdep,        # Análisis de dependencia espacial
  scales,       # Transformación de escalas
  classInt,     # cortes con cuantiles 
  paletteer,    # acceso a múltiples paletas de colores (ej. viridis, wesanderson)
  googledrive,  # autenticación y manipulación de archivos en Google Drive
  patchwork,    # combinación de gráficos ggplot (p1 + p2)
  qs            # guardado y carga rápida de objetos R
)


# Ajusta tamaño base de letra para todos los gráficos
theme(base_size = 14)

# === Autenticación Google Drive ===
# googledrive::drive_auth()

```

## 1. Carga de datos

Traemos las Unidades Cartográficas de Suelo (UCS) ya depuradas, nos aseguramos de que las geometrías sean válidas y retenemos solo los campos clave (identificador, área y diversidad *Q*).

```{r carga_pedodiversidad}

# Carga UCS ya procesadas y armonizadas (ver script externo)
source(here::here("Scripts", "00_funcion_carga_ucs_procesadas_qs.R"), encoding = "UTF-8")

# Asegura geometrías válidas y selecciona columnas clave
ucs_sf_4326  <- ucs_rao_sf |> 
  st_make_valid() |> 
  select(id_creado, UCSuelo, AREA_HA, Q) |>
  st_transform(4326)

# Elimina geometrías vacías (requerido para procesar con sf_as_ee)
ucs_sf_4326 <- ucs_sf_4326[!st_is_empty(ucs_sf_4326), ]


```

Leemos los CSV generados en los scripts anteriores y calculamos, para cada UCS, medias, coeficientes de variación (CV) y versiones densidad/log de DEM, pendiente, temperatura superficial y precipitación. Dejamos todo estandarizado (z-scores) para que los coeficientes del modelo logístico sean comparables.

Excepto DEM y pendiente (que pueden tener medias ≤ 0), los demás promedios son positivos; por tanto, no requieren el ajuste ∣μ∣

```{r carga_covariables}

# ─────────────────────────────────────────────────────────────────────────────
# 0 · Ajuste de precisión para divisiones seguras
# ─────────────────────────────────────────────────────────────────────────────
eps <- 1e-6                         # ε evita CV = σ/0
safe_log10 <- function(x) log10(pmax(x, eps))

# ─────────────────────────────────────────────────────────────────────────────
# 1 · DEM  · media, CV y derivados (todas las variables en español)
# ─────────────────────────────────────────────────────────────────────────────
dem_csv <- readr::read_csv(           # <- nombre lógico del objeto CSV
  here::here("Data/OUT_covars_csv/OUT_DEM_combinado.csv"),
  show_col_types = FALSE
)

covars_dem <- st_as_sf(
  data.frame(dem_csv, geometry = geojson_sf(dem_csv$.geo)), crs = 4326
) |>
  # «media» en lugar de «mean»
  dplyr::rename(dem_media = mean) |>
  dplyr::mutate(
    # Coef. de variación espacial de la elevación
    dem_cv              = stdDev / pmax(abs(dem_media), eps),
    log_dem_cv          = safe_log10(dem_cv),

    # Densidad de CV por unidad de superficie
    dem_cv_densidad     = dem_cv / AREA_HA,
    log_dem_cv_densidad = safe_log10(dem_cv_densidad),

    # Versión estandarizada (Z-score) de cada métrica
    across(c(dem_media, dem_cv, log_dem_cv,
             dem_cv_densidad, log_dem_cv_densidad),
           ~ scale(.x)[,1], .names = "{.col}_z")
  ) |>
  dplyr::select(-.geo, -stdDev, -system.index)

# ─────────────────────────────────────────────────────────────────────────────
# 2 · SLOPE (media & CV espacial)
# ─────────────────────────────────────────────────────────────────────────────
slope_cv <- readr::read_csv(
  here::here("Data/OUT_covars_csv/OUT_SLOPE_combinado.csv"),
  show_col_types = FALSE
)

covars_pendiente <- st_as_sf(
  data.frame(slope_cv, geometry = geojson_sf(slope_cv$.geo)), crs = 4326
) |>
  dplyr::rename(pendiente_media = mean) |>
  dplyr::mutate(
    pendiente_cv          = stdDev / pmax(abs(pendiente_media), eps),
    log_pendiente_cv      = safe_log10(pendiente_cv),
    pendiente_cv_densidad = pendiente_cv / AREA_HA,
    log_pendiente_cv_densidad = safe_log10(pendiente_cv_densidad),
    across(c(pendiente_cv, log_pendiente_cv,
             pendiente_cv_densidad, log_pendiente_cv_densidad,
             pendiente_media),
           ~ scale(.x)[,1], .names = "{.col}_z")
  ) |>
  dplyr::select(-.geo, -stdDev, -system.index)

# ─────────────────────────────────────────────────────────────────────────────
# 3 · LST media espacial (2013-2023)
# ─────────────────────────────────────────────────────────────────────────────
lst_media_esp <- readr::read_csv(
  here::here("Data/OUT_covars_csv/OUT_LST_media_espacial_combinado.csv"),
  show_col_types = FALSE
)

covars_lst_media <- st_as_sf(
  data.frame(lst_media_esp, geometry = geojson_sf(lst_media_esp$.geo)), crs = 4326
) |>
  dplyr::rename(lst_media = mean) |>
  dplyr::mutate(
    log_lst_media          = safe_log10(lst_media),
    lst_media_densidad     = lst_media / AREA_HA,
    log_lst_media_densidad = safe_log10(lst_media_densidad),
    across(c(lst_media, log_lst_media,
             lst_media_densidad, log_lst_media_densidad),
           ~ scale(.x)[,1], .names = "{.col}_z")
  ) |>
  dplyr::select(-.geo, -stdDev, -system.index)  

# ─────────────────────────────────────────────────────────────────────────────
# 4 · LST CV temporal (2013-2023)
# ─────────────────────────────────────────────────────────────────────────────

lst_cv_temp <- readr::read_csv(
  here::here("Data/OUT_covars_csv/OUT_LST_cv_temporal_combinado.csv"),
  show_col_types = FALSE
)

covars_lst_cv_temp <- st_as_sf(
  data.frame(lst_cv_temp, geometry = geojson_sf(lst_cv_temp$.geo)), crs = 4326
) |>
  dplyr::rename(lst_cv_temporal = mean) |>
  dplyr::mutate(
    log_lst_cv_temporal          = safe_log10(lst_cv_temporal),
    lst_cv_temporal_densidad     = lst_cv_temporal / AREA_HA,
    log_lst_cv_temporal_densidad = safe_log10(lst_cv_temporal_densidad),
    across(c(lst_cv_temporal, log_lst_cv_temporal,
             lst_cv_temporal_densidad, log_lst_cv_temporal_densidad),
           ~ scale(.x)[,1], .names = "{.col}_z")
  ) |>
  dplyr::select(-.geo, -stdDev, -system.index)

# ─────────────────────────────────────────────────────────────────────────────
# 5 · PRECIP CV temporal  &  6 · PRECIP media espacial (idéntica lógica)
# ─────────────────────────────────────────────────────────────────────────────

# Precip cv temporal
precip_cv_temp <- readr::read_csv(
  here::here("Data/OUT_covars_csv/OUT_PRECIP_cv_temporal_combinado.csv"),
  show_col_types = FALSE
)

covars_precip_cv_temp <- st_as_sf(
  data.frame(precip_cv_temp, geometry = geojson_sf(precip_cv_temp$.geo)), crs = 4326
) |>
  dplyr::rename(precip_cv_temporal = mean) |>
  dplyr::mutate(
    log_precip_cv_temporal          = safe_log10(precip_cv_temporal),
    precip_cv_temporal_densidad     = precip_cv_temporal / AREA_HA,
    log_precip_cv_temporal_densidad = safe_log10(precip_cv_temporal_densidad),
    across(c(precip_cv_temporal, log_precip_cv_temporal,
             precip_cv_temporal_densidad, log_precip_cv_temporal_densidad),
           ~ scale(.x)[,1], .names = "{.col}_z")
  ) |>
  dplyr::select(-.geo, -stdDev, -system.index)   


# Precip media espacial
precip_media_esp <- readr::read_csv(
  here::here("Data/OUT_covars_csv/OUT_PRECIP_media_espacial_combinado.csv"),
  show_col_types = FALSE
)

covars_precip_media <- st_as_sf(
  data.frame(precip_media_esp, geometry = geojson_sf(precip_media_esp$.geo)), crs = 4326
) |>
  dplyr::rename(precip_media = mean) |>
  dplyr::mutate(
    log_precip_media          = safe_log10(precip_media),
    precip_media_densidad     = precip_media / AREA_HA,
    log_precip_media_densidad = safe_log10(precip_media_densidad),
    across(c(precip_media, log_precip_media,
             precip_media_densidad, log_precip_media_densidad),
           ~ scale(.x)[,1], .names = "{.col}_z")
  ) |>
  dplyr::select(-.geo, -stdDev, -system.index)


```

## 2. Post procesamiento

Este bloque construye la tabla base `modelo_df` **uniendo la pedodiversidad observada con las covariables** derivadas de elevación, pendiente, temperatura superficial y precipitación ( medias y coeficientes de variación temporal). Se incluyen métricas transformadas y estandarizadas, útiles para el modelado posterior. Aquí mismo densificamos la diversidad (Qdens) y su logaritmo, de modo que la respuesta y los predictores queden listos para la etapa de modelado.

```{r unir_variables}

# Une por id_creado, AREA_HA y UCSuelo
modelo_df <- ucs_sf_4326 |>
  tidyr::drop_na(Q) |>
  mutate(
    Q = if_else(Q == 0, 1e-3, Q),              # Evita log(0)
    Qdens = Q / AREA_HA,                       # Densidad de diversidad
    log_Qdens = log10(Qdens)                   # Transformación log10
  ) |>
  left_join(covars_dem            |> st_drop_geometry(),
            by = c("id_creado","AREA_HA","UCSuelo")) |>
  left_join(covars_pendiente      |> st_drop_geometry(),
            by = c("id_creado","AREA_HA","UCSuelo")) |>
  left_join(covars_lst_cv_temp    |> st_drop_geometry(),
            by = c("id_creado","AREA_HA","UCSuelo")) |>
  left_join(covars_lst_media      |> st_drop_geometry(),
            by = c("id_creado","AREA_HA","UCSuelo")) |>
  left_join(covars_precip_cv_temp |> st_drop_geometry(),
            by = c("id_creado","AREA_HA","UCSuelo")) |>
  left_join(covars_precip_media   |> st_drop_geometry(),
            by = c("id_creado","AREA_HA","UCSuelo"))

# Verifica que la unión fue exitosa
glimpse(modelo_df)
```

Filtramos UCS completas (sin NA), definimos el percentil 95 de log Qdens como umbral y creamos la variable binaria de hotspot. Este paso delimita la muestra y la respuesta que alimentarán el modelo logístico.

```{r preparacion_modelado}

## Filtra UCS con covariables completas y crea la variable hotspot ------------

modelo_df_completo <- modelo_df |>
  drop_na(
    # diversidad
    log_Qdens,
    # magnitudes
    dem_media, pendiente_media, lst_media, precip_media,
    # CV densificado + sus log-10
    dem_cv_densidad,  log_dem_cv_densidad,
    pendiente_cv_densidad,  log_pendiente_cv_densidad,
    lst_cv_temporal_densidad,  log_lst_cv_temporal_densidad,
    precip_cv_temporal_densidad, log_precip_cv_temporal_densidad,
    # CV “puro” (temporal) + log-10
    lst_cv_temporal,  log_lst_cv_temporal,
    precip_cv_temporal, log_precip_cv_temporal
  )

# Umbral P95 para definir hotspot de diversidad logarítmica-densificada
umbral_hot95 <- quantile(modelo_df_completo$log_Qdens, 0.95, na.rm = TRUE)

modelo_df_completo <- modelo_df_completo |>
  mutate(hotspot_95 = as.integer(log_Qdens >= umbral_hot95))
```

Para evitar un modelo sesgado por la disparidad de clases, tomamos todos los hotspots y seleccionamos aleatoriamente un número cuatro veces mayor de no-hotspots. Así obtenemos un conjunto de entrenamiento equilibrado sobre el cual calcularemos correlaciones y ajustaremos el GLM.

```{r subconjuntos_balanceados}


# contiene hotspots (1) y un subconjunto aleatorio balanceado de no-hotspots (0)
# Número total de hotspots (clase positiva)
n_hot   <- modelo_df_completo |> filter(hotspot_95 == 1) |> nrow()

# Número de no-hotspots deseado (proporción 1:3)
n_nohot <- n_hot * 4   

# Semilla para reproducibilidad
set.seed(123)

# Selección de muestra con proporción 1:3
modelo_df_balanceado <- modelo_df_completo |>
  mutate(fila = row_number()) |>
  filter(
    hotspot_95 == 1 |
      fila %in% sample(which(hotspot_95 == 0), n_nohot)
  ) |>
  select(-fila)

```

## 3. Modelado

Calculamos la matriz de Pearson entre los candidatos y la mostramos en un correlograma sombreado. Esto nos permite detectar pares altamente correlacionados y decidir qué predictores retener antes de construir el modelo.

```{r analisis_correlacion}

# Umbral de colinealidad (Pearson)
r_thr <- 0.70   # umbral |r|    


# Define la fórmula *antes* de ajustar el modelo -----------------------------------------

form_candidatos <-
  hotspot_95 ~ dem_media_z + pendiente_media_z + lst_media_z + precip_media_z +
  log_dem_cv_z + log_pendiente_cv_z + log_lst_cv_temporal_z + log_precip_cv_temporal_z +
  log_dem_cv_densidad_z + log_pendiente_cv_densidad_z +
  log_lst_cv_temporal_densidad_z + precip_cv_temporal_densidad_z

vars_cand <- all.vars(form_candidatos)[-1]   # excluye la respuesta


# Matriz de correlaciones ------------------------------------------------------------------

mat_cor <- modelo_df_balanceado |>
  st_drop_geometry() |>
  select(all_of(vars_cand)) |>
  cor(use = "pairwise.complete.obs")


# Visualización de correlograma -------------------------------------------------------------

#Define paleta de colores
pal_low  <- "#56B4E9"; pal_mid <- "#F8F0C3FF"; pal_high <- "#FFD700"

# Crea mapa de calor de correlaciones Pearson
p_corr_covs <- ggcorr(
  mat_cor,
  low         = pal_low,
  mid         = pal_mid,
  high        = pal_high,
  midpoint    = 0,
  hjust       = 0.9,
  size        = 4,
  color       = "grey60",
  label       = TRUE,
  label_alpha = TRUE,
  label_size  = 3,
  label_round = 2
) +
  ggtitle("Matriz de correlaciones entre predictores (Pearson)") +
  theme_minimal(base_size = 12) +
  coord_cartesian(clip = "off") +
  theme(panel.clip = "off",
        plot.margin = unit(c(5, 5, 5, 90), "pt"))


# Guarda la figura
ggsave(here("Figures", "correlacion_covariables.png"),
       plot = p_corr_covs,
       width = 6,
       height = 4,
       dpi = 350)

```

Se puede extraer también la tabla con los pares de alta correlación

```{r tabla_correlacion}

## Tabla de pares con |r| > r_thr
pares_altos <- 
  as.data.frame(as.table(mat_cor)) |>                  # pasa a long
  rename(var1 = Var1, var2 = Var2, r = Freq) |>
  filter(var1 != var2, abs(r) >= r_thr) |>             # quita diagonal
  mutate(across(c(var1, var2), as.character)) |>
  rowwise() |>                                         # ordena alfabéticamente
  mutate(pair_id = paste(sort(c(var1, var2)), collapse = "_")) |> 
  ungroup() |>
  distinct(pair_id, .keep_all = TRUE) |>               # evita duplicados A~B / B~A
  arrange(desc(abs(r)))

print(pares_altos, n = Inf)
```

Ajustamos un GLM logístico con la combinación de predictores que superó el filtro de colinealidad. Añadimos las probabilidades predichas y los residuos al data frame, sentando la base para inspecciones gráficas y contrastes de autocorrelación.

```{r ajuste_modelo}

# columnas finales del modelo
vars_glm <- c(
  "hotspot_95",
  "dem_media_z",  "precip_media_z",
  "log_pendiente_cv_densidad_z",
  "log_lst_cv_temporal_densidad_z", "precip_cv_temporal_densidad_z"
)

# Deja sólo esas columnas + geometría  y elimina cualquier NA
modelo_df_glm <- modelo_df_balanceado |>
  dplyr::select(all_of(vars_glm), geometry) |>
  tidyr::drop_na()

#  Ajusta el logit;  na.action = na.exclude  →  predict() devuelve NAs
glm_hot_bal <- glm(
  hotspot_95 ~ .,
  data      = st_drop_geometry(modelo_df_glm), #glm no necesita geometría
  family    = binomial(),
  na.action = na.exclude
)


# Añade predicciones y residuos (longitud coincide con modelo_df_glm)
modelo_df_glm <- modelo_df_glm |>
  mutate(
    prob_hot_bal  = predict(glm_hot_bal, type = "response"),
    resid_hot_bal = residuals(glm_hot_bal, type = "response")
  )

# Breve diagnóstico
summary(glm_hot_bal)
print(performance::r2_tjur(glm_hot_bal))

```

El modelo mostró:

-   Estabilidad numérica adecuada.
-   Coeficientes significativos para algunas variables clave.
-   R² de Tjur = 0.87 (alto, pero plausible).

El \*modelo B es preferido por su robustez, interpretabilidad y aplicabilidad predictiva.\*\* En adelante, nos enfocaremos en describir gráficamente sus efectos, residuales y predicciones espaciales.

## 4. Visualización de resultados

### 4.1 Coeficientes (efectos fijos)

Graficamos los coeficientes estandarizados y, con effectsize::oddsratio(), añadimos sus odds ratios y sus IC 95 %. Esta lectura conjunta facilita la interpretación práctica de cada predictor y conecta con las curvas marginales que siguen.

```{r visualizacion_coeficientes}

p_coeficientes <- plot_model(glm_hot_bal, 
                             type = "est", 
                             vline.color = "black", 
                             show.values = TRUE, 
                             transform = NULL,
                             value.offset = .3) +
  labs(title = "Coeficientes estimados del modelo") +
  theme_sjplot2() +
  scale_color_sjplot("blambus")

p_coeficientes

# Guarda la figura
ggsave(here("Figures", "coeficientes_logit_b.png"),
       plot = p_coeficientes,
       width = 6,
       height = 3,
       dpi = 350)

```

### 4.2 Gráfica de efectos marginales

Mostramos cómo varía la probabilidad de hotspot a lo largo del rango estandarizado de cada predictor. Estas curvas ilustran la dirección y la magnitud del efecto detectado en el bloque de coeficientes.

```{r visualizacion_marginales}


# Helper ─ evita repetir theme & estilo de eje Y -------------------------------------------
marg_plot <- function(var, xlbl){
  plot_model(glm_hot_bal,
             type  = "pred",
             terms = sprintf("%s [all]", var),
             title = NULL) +                     # sin título interno
    labs(x = xlbl, y = "P(hotspot)") +
    theme_minimal(base_size = 11)
}

# Generar los cinco gráficos --------------------------------------------------------------
p_dem_media_z            <- marg_plot("dem_media_z", "Elevación media (z)")
p_precip_media_z         <- marg_plot("precip_media_z", "Precipitación media (z)")
p_log_slope_cv_dens_z   <- marg_plot("log_pendiente_cv_densidad_z","log₁₀ CV pend/Área (z)")
p_log_lst_cv_temp_dens_z<- marg_plot("log_lst_cv_temporal_densidad_z",
                                     "log₁₀ CV LST temp/Área (z)")
p_precip_cv_temp_dens_z <- marg_plot("precip_cv_temporal_densidad_z",
                                     "CV precip temp/Área (z)")


# Mosaico 3×2  (la última celda queda vacía para mantener proporción) ----------------------

p_curvas_marginales <- p_dem_media_z + p_precip_media_z + p_log_slope_cv_dens_z + p_log_lst_cv_temp_dens_z + p_precip_cv_temp_dens_z + plot_layout(ncol = 5) 

p_curvas_marginales

# Guardar si se desea
ggsave(
  here::here("Figures", "p_curvas_marginales.png"),
  plot   = p_curvas_marginales,
  width  = 13, height = 3.2, dpi = 350
)

```

### 4.3 Residuales

El análisis de los residuales del modelo logit permite evaluar qué tan bien se ajusta el modelo a los datos observados. En modelos GLM (como el logit), los residuales no deben interpretarse igual que en regresiones lineales clásicas, pero siguen siendo cruciales para detectar mal ajuste, patrones no explicados o estructura espacial remanente.

Existen distintos tipos de residuales en modelos binomiales:

* Residuos de respuesta (response): diferencia entre el valor observado (0/1) y la probabilidad predicha.
* Residuos de Pearson: estandarizados respecto a la varianza esperada bajo el modelo. Útiles para detectar outliers.
* Residuos deviance: basados en la función de verosimilitud. Informan sobre la contribución de cada observación al deviance total.

En este caso usamos residuos de tipo response, los más directos para interpretar y visualizar espacialmente.

Un residuo de +1 indica que el modelo predijo 0 pero el valor real fue 1 (hotspot observado, no predicho), mientras que un valor de -1 significa que el modelo predijo un hotspot donde no lo había. Valores cercanos a 0 indican buen ajuste.

```{r visualizaicon_residuales}

resid_plot <- function(var, xlbl){
  ggplot(modelo_df_glm,
         aes(x = .data[[var]], y = resid_hot_bal)) +
    geom_point(alpha = .25, colour = "#56B4E9", size = 1) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    labs(x = xlbl, y = "Residuo") +
    theme_minimal(base_size = 11)
}

p_residuos <- 
  resid_plot("dem_media_z",                 "Elevación media (z)")        +
  resid_plot("precip_media_z",              "Precip. media (z)")          +
  resid_plot("log_pendiente_cv_densidad_z", "log₁₀ CV pend/Área (z)")     +
  resid_plot("log_lst_cv_temporal_densidad_z","log₁₀ CV LST temp/Área (z)")+
  resid_plot("precip_cv_temporal_densidad_z","CV precip temp/Área (z)")   +
  plot_layout(ncol = 5)


ggsave(
  here::here("Figures", "mosaico_residuales_logit.png"),
  plot   = p_residuos,
  width  = 13, height = 3.2, dpi = 350
)
```

En esta sección mostramos tres mapas clave para interpretar el modelo logístico:

* Hotspots observados: zonas donde la diversidad densificada supera el percentil 95. Sirve como referencia empírica para evaluar el modelo.
* Probabilidad predicha de hotspot: valores continuos entre 0 y 1 generados por el modelo. Una alta probabilidad indica que el modelo espera un hotspot allí.
* Residuos del modelo: diferencia entre observación y predicción. Permiten identificar zonas donde el modelo sobrestima o subestima la probabilidad de hotspot.

La comparación visual entre estas capas permite detectar áreas donde el modelo falla sistemáticamente o donde hay alta incertidumbre, lo que justifica el análisis espacial posterior.

```{r visualizacion_mapas}

# Paleta “Zissou 1” (100 tonos); tomo un rojo intenso para marcar hotspots
pal_zissou <- paletteer::paletteer_c("grDevices::Zissou 1", 100)
col_hot    <- pal_zissou[90]     # rojo-naranja fuerte

# ── 1 · Hotspots observados -------------------------------------------------
# (puntos) sobre el contorno de las UCS del data-set usado en el modelo
hotspots_obs_sf <- modelo_df_glm |>
  filter(hotspot_95 == 1)        # ← antes era log_Qdens_hot95

p_mapa_obs <- ggplot() +
  geom_sf(data = modelo_df_glm, fill = NA, colour = "grey90", linewidth = .1) +
  geom_sf(data = hotspots_obs_sf, colour = col_hot, size = 2) +
  labs(title = "Hotspots observados (puntos)") +
  theme_minimal(base_size = 11)

# ── 2 · Probabilidad predicha (quintiles) -----------------------------------
cortes <- classInt::classIntervals(modelo_df_glm$prob_hot_bal,
                                   n = 5, style = "quantile")$brks

p_mapa_pred <- ggplot(modelo_df_glm) +
  geom_sf(aes(fill = cut(prob_hot_bal, cortes,
                         include.lowest = TRUE, dig.lab = 3)),
          colour = NA) +
  scale_fill_manual(
    values = rev(viridis::plasma(5)),
    name   = "Cuantiles de p"
  ) +
  labs(title = "Probabilidad predicha de hotspot (quintiles)") +
  theme_minimal(base_size = 11)

# ── 3 · Residuos del modelo --------------------------------------------------
p_mapa_resid <- ggplot(modelo_df_glm) +
  geom_sf(aes(fill = resid_hot_bal), colour = NA) +
  scale_fill_gradientn(
    colours = viridis::viridis(100),
    limits  = c(-0.5, 0.5),
    name    = "Residuo"
  ) +
  labs(title = "Residuales del modelo") +
  theme_minimal(base_size = 11)

# ── Mosaico 3×1 --------------------------------------------------------------
p_mapas_logit <- p_mapa_obs + p_mapa_pred + p_mapa_resid +
                 patchwork::plot_layout(ncol = 3)

ggsave(
  filename = here::here("Figures", "mosaico_mapa_prediccion_logit.png"),
  plot     = p_mapas_logit,
  width    = 12,
  height   = 5.5,
  dpi      = 350
)

```

## 5.Autocorrelación espacial de los residuales (Moran I)

A continuación, se evalúa si los residuales del modelo logit presentan autocorrelación espacial, es decir, si las discrepancias entre predicciones y observaciones tienden a agruparse espacialmente. Esta evaluación permite responder preguntas como:

¿Hay zonas del territorio donde el modelo falla sistemáticamente? ¿Podría haber variables omitidas con estructura espacial? ¿Los errores del modelo son aleatorios o siguen patrones regionales?

Para esto, calculamos el Moran I de los residuos para radios crecientes (25 – 300 km) y graficamos su evolución. Esto revela la escala a la que persisten estructuras espaciales no explicadas por el modelo.

```{r analisis_moran_I}

## ----analisis_moran_I (corregido y comentado) --------------------------------
# Objetivo → Moran I global de los residuos a varios radios               ----
# --------------------------------------------------------------------------- #


# 1 · Centroides del subconjunto modelado  (CRS 9377,  m) ------------------
centros_9377 <- modelo_df_glm |>
  sf::st_centroid(of_largest_polygon = TRUE) |>
  sf::st_transform(9377)                                  # coordenadas métricas
xy <- sf::st_coordinates(centros_9377)                    # matriz (x, y)

# 2 · Función protegida: Moran I global para un radio r_km ------------------
get_MI_fast <- function(r_km){
  r_m <- r_km * 1e3                                       # km → m

  ## 2·1 · Vecindad genuina para ese radio (evita recortes manuales)
  nb_i <- spdep::dnearneigh(xy, d1 = 0, d2 = r_m)

  ## 2·2 · Algún polígono aislado → devolvemos NA
  if (any(spdep::card(nb_i) == 0)) {
    return(tibble::tibble(dist_km = r_km,
                          I       = NA_real_,
                          p.value = NA_real_))
  }

  ## 2·3 · Pesos espaciales y prueba de Moran
  lw_i <- spdep::nb2listw(nb_i, style = "W", zero.policy = TRUE)
  mi   <- spdep::moran.test(modelo_df_glm$resid_hot_bal,
                            lw_i, zero.policy = TRUE)

  tibble::tibble(dist_km = r_km,
                 I       = unname(mi$estimate["Moran I"]),
                 p.value = mi$p.value)
}

# 3 · Ejecutamos para radios 25-300 km (paso 25 km) ------------------------
radios_km <- seq(25, 300, by = 25)
moran_tab <- purrr::map_dfr(radios_km, get_MI_fast)

# 4 · Gráfico I vs distancia (rojo = p < 0.05) -----------------------------
pal_sig <- c(`TRUE` = "#d73027", `FALSE` = "grey90")

g_moran <- ggplot(moran_tab,
                  aes(dist_km, I, colour = p.value < 0.05)) +
  geom_line(na.rm = TRUE) +
  geom_point(size = 2, na.rm = TRUE) +
  scale_colour_manual(values = pal_sig,
                      labels = c("No", "Sí"),
                      name   = "p < 0.05") +
  labs(x = "Radio (km)",
       y = "Moran I global",
       title = "Autocorrelación espacial de los residuos según distancia") +
  theme_minimal()

print(g_moran)



```

Moran's I > 0: indica autocorrelación espacial positiva en los residuos: valores similares (altos o bajos) tienden a agruparse espacialmente.

Z-score elevado y p-valor < 0.001: este patrón es estadísticamente significativo y no aleatorio.

Para I > 0 y p-valor < 0.001, el modelo no captura completamente la estructura espacial de los hotspots de pedodiversidad. Hay información espacial residual: zonas donde el modelo sobrepredice (High-High) o subpredice (Low-Low) de forma agrupada.

Esto puede deberse a:

-   Covariables espaciales faltantes o mal representadas.
-   Efectos espaciales latentes (estructura de paisaje, geología, clima).
-   Posible efecto MAUP (problemas por escala y forma de unidades espaciales).

Dado este resultado, se justifica implementar modelos espaciales explícitos, como modelos bayesianos con estructuras CAR o SAR (INLA, brms).

```{r analisis_LISA}

# Moran local (LISA)
moran_local <- localmoran(modelo_df_glm$resid_hot_bal, listw = pesos, zero.policy = TRUE)

# Calcula el lag espacial de los residuos (para el scatterplot)
modelo_df_glm <- modelo_df_glm |>
  mutate(
    local_moran_I = moran_local[, 1],
    p_valor_local = moran_local[, 5],
    lag_resid = lag.listw(pesos, resid_hot_bal)
  )

# Clasifica tipo de agrupamiento espacial
modelo_df_glm <- modelo_df_glm |>
  mutate(
    cluster_tipo = case_when(
      resid_hot_bal > 0 & lag_resid > 0 ~ "High-High",
      resid_hot_bal < 0 & lag_resid < 0 ~ "Low-Low",
      resid_hot_bal > 0 & lag_resid < 0 ~ "High-Low",
      resid_hot_bal < 0 & lag_resid > 0 ~ "Low-High",
      TRUE ~ "No significativo"
    ),
    cluster_tipo = ifelse(p_valor_local > 0.05, "No significativo", cluster_tipo)
  )

```

Aplicamos el estadístico local de Moran para identificar agrupamientos de residuos alto-alto, bajo-bajo, etc., y los mapeamos junto con el diagrama de dispersión Moran. Con ello cerramos el análisis señalando dónde el modelo deja señales espaciales sin capturar. Observamos:

* Diagrama de dispersión de Moran local (izquierda): muestra la relación entre cada residuo y el promedio de sus vecinos (lag espacial). Cada punto está coloreado según el tipo de agrupamiento LISA (e.g., High-High, Low-Low). La pendiente indica el grado de autocorrelación local.
* Mapa de agrupamientos LISA (centro): clasifica cada unidad en cinco categorías según la combinación de su residuo y el de sus vecinos. Ayuda a identificar zonas con agrupamiento significativo de errores (e.g., agrupaciones de sobrepredicción).
* Mapa del estadístico local (Ii) (derecha): representa la magnitud del valor de autocorrelación local, sin categorizarlo. Útil para detectar valores extremos y la intensidad del patrón espacial.

```{r visualizacion_LISA}

# Define colores personalizados desde paleta Zissou1 (viridis-like)
pal <- wes_palette("Zissou1", 100, type = "continuous")
colores_lisa <- c(
  "High-High"        = pal[90],   # rojo intenso
  "Low-Low"          = pal[10],   # azul oscuro
  "High-Low"         = pal[70],   # naranja
  "Low-High"         = pal[30],   # celeste
  "No significativo" = "grey90"   # gris neutro
)

# Gráfico 1: Scatterplot de Moran local coloreado por tipo de agrupamiento
p_scatter_lisa <- ggplot(modelo_df_glm, aes(x = resid_hot_bal, y = lag_resid)) +
  geom_point(aes(color = cluster_tipo), alpha = 0.8, size = 1.5) +
  geom_smooth(method = "lm", se = FALSE, color = "black", linewidth = 0.5) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey60") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey60") +
  scale_color_manual(values = colores_lisa) +
  labs(
    title = "Diagrama de dispersión Moran local",
    x = "Residuo del modelo",
    y = "Lag espacial",
    color = "Tipo de agrupamiento"
  ) +
  theme_minimal()

# Gráfico 2: Mapa LISA de agrupamientos espaciales
p_moran_lisa <- ggplot(modelo_df_glm) +
  geom_sf(aes(fill = cluster_tipo), color = NA) +
  scale_fill_manual(values = colores_lisa, na.value = "white") +
  labs(title = "Mapa: agrupamientos LISA (residuales)",
       fill = "Tipo de agrupamiento") +
  theme_minimal()

# Gráfico 3: Mapa de valores Ii (magnitude de autocorrelación local)
p_ii_mapa <- ggplot(modelo_df_glm) +
  geom_sf(aes(fill = local_moran_I), color = NA) +
  scale_fill_viridis_c(name = "Ii", option = "magma", direction = -1) +
  labs(title = "Mapa: valor del estadístico local (Ii)") +
  theme_minimal()

# Composición de los tres gráficos
p_lisa_tripanel <- p_scatter_lisa + p_moran_lisa + p_ii_mapa + 
  plot_layout(ncol = 3)

# Mostrar y guardar
print(p_lisa_tripanel)

ggsave(
  here::here("Figures", "moran_local_composicion_logit.png"),
  plot = p_lisa_tripanel,
  width = 15,
  height = 5,
  dpi = 300
)

```

En este contexto, un Low-Low indica un conjunto de unidades cartográficas de suelo (UCS) cuyos residuos son consistentemente negativos, y además están rodeadas por otras UCS con residuos negativos, de manera significativa.

Esto sugiere una subpredicción sistemática en esa zona: es decir, el modelo está prediciendo probabilidades más bajas de hotspot que las que realmente se observan.

En resumen: los agrupamientos Low-Low son zonas donde el modelo tiende a subestimar la probabilidad de hotspots, y esa subestimación no es aleatoria sino espacialmente agrupada.
