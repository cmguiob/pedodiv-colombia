---
title: "Análisis de regresión con modelos lineales generalziados (GLM)"
author: "Carlos M. Guío Blanco"
format: html
editor: visual
---

En este cuaderno se presenta el análisis mediante la metodología de modelos lineares generalizados, para la función logística. El modelo importa archivos csv que contienen los datos procesados de imágenes satelitales Landsat, Sentinel y SRTM para explicar la ocurrencia de “hotspots” de pedodiversidad.

Las covariables se eligieron partiendo de la hipótesis, que la diversidad de suelos está condicionada por la diversidad de otras variables formadoras cuyos proxis de largo plazo pueden derivarse de imágenes satelitales: geomorfología, clima, hidrología. La vegetación, debido a su alta variabilidad temporal, no se utiliza como proxi para explicar la diversidad de suelos, que se entiende como un proceso que puede durar cientos a millones de años.

```{r configuracion}
#Para exportar como .R plano
# knitr::purl('05_analisis_glm_hotspots.qmd')

if (!"pacman" %in% installed.packages()) install.packages("pacman")
pacman::p_load(
  here,        # rutas del proyecto
  remotes,     # instalar desde GitHub
  sf,          # vectores espaciales
  dplyr,       # manipulación tabular
  tidyr,
  readr,       # leer CSV rápido
  performance,
  ggdist,
  scales,      #transformaciones y escalas gráficas
  ggplot2,     # gráficos
  paletteer,   #paletas de colores
  googledrive, #importar y exportar a Google Drive
  patchwork,   # unir gráficos
  qs           # guardar objetos rápido
)

# Ajusta tamaño de letra para todo e lscript
theme(base_size = 14)

# === Autenticación Google Drive ===
#googledrive::drive_auth()
```

## 1. Carga de datos

La pedodiversidad "Q de Rao" es la variable dependiente a predecir, para cada polígono de UCS.

```{r carga_pedodiversidad}

# Corre script externo para cargar
source(here::here("Scripts", "00_funcion_carga_ucs_procesadas_qs.R"), encoding = "UTF-8")

# Asignación de id único para cada polígono
ucs_rao_sf <- ucs_rao_sf |> 
  sf::st_make_valid() |> #valida geometrias problemáticas
  dplyr::select(id_creado, UCSuelo, AREA_HA, Q) 

ucs_rao_sf <- ucs_rao_sf[!st_is_empty(ucs_rao_sf), ]


# Transforma a crs 4326 antes de pasarlo a GEE
ucs_sf_4326 <- st_transform(ucs_rao_sf, 4326)

```

Se cargan las covariables y se convierte geometria de GeoJSON a sf

```{r}

# Ruta al CSV combinado
dem_cv <- read_csv(here::here("Data", "OUT_covars_csv","OUT_DEM_combinado.csv" ))

# Convierte geometría desde .geo (GeoJSON como texto) a objeto sf
dem_cv_sf <- st_as_sf(
  data.frame(dem_cv, geometry = geojson_sf(dem_cv$.geo)), #convierte a sf
  crs = 4326) |>
  select(-.geo) |> #elimina columna de geometria obsoleta
  mutate(
      dem_cv = stdDev / mean, #calcula coeficiente de variación
      log_dem_cv = log(dem_cv + 1), #calcula log de coeficiente de variación
      dem_cv_dens = dem_cv/AREA_HA, #calcula la densidad del coeficiente de variación
      log_dem_cv_dens = log(dem_cv_dens + 1) 
  ) |>
rename(dem_mean = mean, dem_stdDev = stdDev)


# Ruta al CSV combinado
slope_cv <- read_csv(here::here("Data", "OUT_covars_csv","OUT_SLOPE_combinado.csv" ))

# Convierte geometría desde .geo (GeoJSON como texto) a objeto sf
slope_cv_sf <- st_as_sf(
  data.frame(slope_cv, geometry = geojson_sf(slope_cv$.geo)), #convierte a sf
  crs = 4326) |>
  select(-.geo) |> #elimina columna de geometria obsoleta
  mutate(mean = mean / (180 / pi), #correccion temporal, mientras se descarga lote
         stdDev = stdDev / (180 / pi)) |>
  mutate(
      slope_cv = stdDev / mean, #calcula coeficiente de variación
      log_slope_cv = log(slope_cv + 1), #calcula log de coeficiente de variación
      slope_cv_dens = slope_cv/AREA_HA, #calcula la densidad del coeficiente de variación
      log_slope_cv_dens = log(slope_cv_dens + 1) 
  ) |>
rename(slope_mean = mean, slope_stdDev = stdDev)


```

## 2. Post procesamiento

Se unen las covariables

```{r join_covars}

# Extraer solo columnas útiles de dem y slope
dem_df <- dem_cv_sf |> 
  st_drop_geometry() |>
  select(-system.index)

slope_df <- slope_cv_sf |> 
  st_drop_geometry() |>
  select(-system.index)

# Unir a la tabla base
modelo_df <- ucs_rao_sf |>
  mutate(
    #Q = if_else(Q == 0, 1e-3, Q),               # evitar log(0)
    Qdens = Q / AREA_HA,                        # diversidad por unidad de área
    log_Qdens = log(Qdens + 1),                     # log-transformación
  ) |>
  left_join(
    dem_df,
    by = c("id_creado", "AREA_HA", "UCSuelo")
  ) |>
  left_join(
    slope_df,
    by = c("id_creado", "AREA_HA", "UCSuelo")
  ) 


```

Separo los datos con y sin NA, para inspección y para correr modelo

```{r}

# Subconjunto sin NA: usado para modelado
modelo_df_completo <- modelo_df |> 
drop_na(log_Qdens, dem_cv, slope_cv, dem_mean, slope_mean, log_dem_cv, log_slope_cv, dem_cv_dens, slope_cv_dens)

# Subconjunto con al menos un NA
modelo_df_NA <- modelo_df |> 
  filter(if_any(c(
    log_Qdens, dem_cv, slope_cv, dem_mean, slope_mean, log_dem_cv, log_slope_cv, dem_cv_dens, slope_cv_dens), is.na))
```

Se establecen los percentiles y clasifican los extremos:

```{r}

umbral95 <- quantile(modelo_df_completo$log_Qdens, 0.95, na.rm = TRUE)


modelo_df_completo <- modelo_df_completo |>
  # Agregar variable binaria a modelo_df_completo
  mutate(log_Qdens_hot95 = as.integer(log_Qdens >= umbral95)) |>
  mutate(across(
    c(dem_cv, slope_cv, dem_mean, slope_mean, log_dem_cv, log_slope_cv, dem_cv_dens, slope_cv_dens, log_dem_cv_dens, log_slope_cv_dens),
    ~ scale(.)[,1],
    .names =  "{.col}_z" 
  ))

```

## 3. Modelado

Se corre un modelo GLM binomial para explicar los hotspots

```{r}

# 2. Ajustar modelo directamente sobre modelo_df_completo
glm_hot <- glm(
    log_Qdens_hot95 ~ dem_mean_z + log_slope_cv_dens_z, 
    data = modelo_df_completo,
    family = binomial())

# 3. Calcular predicciones y residuos en la misma tabla
modelo_df_completo <- modelo_df_completo |>
  mutate(
    prob_hot95 = predict(glm_hot, newdata = modelo_df_completo, type = "response"),
    resid_hot95 = residuals(glm_hot, type = "response")
  )

#Resumen estadístico
summary(glm_hot)
performance::r2_tjur(glm_hot)


```

### 4.1 Visualización de resultados

Líneas de regresión con intervalos, puntos y R²

```{r}


library(sjPlot)
library(ggplot2)

# Estilo base como el que usas para p_logQdens
theme_set(theme_minimal())

p1 <- plot_model(glm_hot, type = "pred", terms = "dem_cv [all]", title = NULL) + theme_minimal()
p2 <- plot_model(glm_hot, type = "pred", terms = "slope_cv [all]", title = NULL) + theme_minimal()
p3 <- plot_model(glm_hot, type = "pred", terms = "dem_mean [all]", title = NULL) + theme_minimal()
p4 <- plot_model(glm_hot, type = "pred", terms = "slope_mean [all]", title = NULL) + theme_minimal()
p5 <- plot_model(glm_hot, type = "pred", terms = "dem_cv_dens [all]", title = NULL) + theme_minimal()
p6 <- plot_model(glm_hot, type = "pred", terms = "slope_cv_dens [all]", title = NULL) + theme_minimal()

p_curvas_marginales_logit <- (p1 + p2 + p3) / (p4 + p5 + p6)

ggsave(here("Figures", "mosaico_curvas_marginales_logit.png"),
       plot = p_curvas_marginales_logit,
       width = 10,
       height = 6,
       dpi = 350)

```

Chequeo de residuales

```{r}

p_resid_dem_mean <- ggplot(modelo_df_completo, aes(x = dem_mean, y = resid_hot95)) +
  geom_point(alpha = 0.3, color = "#56B4E9") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Residuales vs dem_mean", y = "Residuos", x = "Altitud media") +
  theme_minimal()

p_resid_log_slope_cv_dens_logit <- ggplot(modelo_df_completo, aes(x = log_slope_cv_dens, y = resid_hot95)) +
  geom_point(alpha = 0.3, color = "#56B4E9") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Residuales vs log(slope CV densificado)", y = "Residuos", x = "log(slope CV densificado)") +
  theme_minimal()


p_resid_dem_mean + p_resid_log_slope_cv_dens_logit
```

Mapas de predicción y residuo

```{r}

library(patchwork)

p1 <- ggplot(modelo_df_completo) +
  geom_sf(aes(fill = prob_hot95), color = NA) +
  scale_fill_viridis_c(option = "viridis", na.value = "white") +
  labs(title = "Probabilidad predicha de hotspot", fill = "Prob") +
  theme_minimal()

p2 <- ggplot(modelo_df_completo) +
  geom_sf(aes(fill = resid_hot95), color = NA) +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", na.value = "white") +
  labs(title = "Residuo del modelo binomial", fill = "Residuo") +
  theme_minimal()

p1 + p2  # con patchwork




#guarda el último gráfico generado
ggsave(here("Figures", "mosaico_mapa_prediccion_logit.png"),
       plot = p_map_predi_logit,
       width = 10,
       height = 6,
       dpi = 350)
```
