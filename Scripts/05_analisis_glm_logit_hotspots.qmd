---
title: "Análisis de regresión logit de hotspots"
author: "Carlos M. Guío Blanco"
format: html
editor: visual
---

En este cuaderno se presenta el análisis mediante la metodología de modelos lineares generalizados, para la función logística. El modelo importa archivos csv que contienen los datos procesados de imágenes satelitales Landsat 8 y SRTM para explicar la ocurrencia de “hotspots” de pedodiversidad.

Las covariables se eligieron partiendo de la hipótesis, que la diversidad de suelos está condicionada por la diversidad de otras variables formadoras cuyos proxis de largo plazo pueden derivarse de imágenes satelitales: geomorfología, clima, hidrología. La vegetación, debido a su alta variabilidad temporal, no se utiliza como proxi para explicar la diversidad de suelos, que se entiende como un proceso que puede durar cientos a millones de años.

```{r configuracion}
#Para exportar como .R plano
# knitr::purl('05_analisis_glm_logit_hotspots.qmd')

if (!"pacman" %in% installed.packages()) install.packages("pacman")
pacman::p_load(
  here,         # manejo de rutas relativas al proyecto
  remotes,      # instalar paquetes desde GitHub
  sf,           # manejo de objetos espaciales vectoriales
  dplyr,        # manipulación de data frames (verbos como filter, mutate, join)
  tidyr,        # transformación de datos (pivot_longer, pivot_wider, etc.)
  readr,        # lectura rápida de archivos CSV
  performance,  # métricas de modelos (R2 de Tjur, VIF, etc.)
  ggdist,       # distribución visual de predicciones (stat_halfeye, intervalos)
  scales,       # transformación de escalas (log10, percentiles, breaks)
  ggplot2,      # sistema de gráficos base
  sjPlot,       # visualización de modelos y efectos marginales
  spdep,        # Análisis de dependencia espacial
  scales,       # Transformación de escalas
  paletteer,    # acceso a múltiples paletas de colores (ej. viridis, wesanderson)
  googledrive,  # autenticación y manipulación de archivos en Google Drive
  patchwork,    # combinación de gráficos ggplot (p1 + p2)
  qs            # guardado y carga rápida de objetos R
)

#Paleta de colores
pal <- wes_palette("Zissou1", 100, type = "continuous")

col_hot  <- pal[90] 

# Ajusta tamaño base de letra para todos los gráficos
theme(base_size = 14)

# === Autenticación Google Drive ===
# googledrive::drive_auth()

```

## 1. Carga de datos

Carga los datos base de unidades cartográficas de suelos (UCS) y selecciona columnas claves

```{r carga_pedodiversidad}

# Carga UCS ya procesadas y armonizadas (ver script externo)
source(here::here("Scripts", "00_funcion_carga_ucs_procesadas_qs.R"), encoding = "UTF-8")

# Asegura geometrías válidas y selecciona columnas clave
ucs_rao_sf <- ucs_rao_sf |> 
  st_make_valid() |> 
  select(id_creado, UCSuelo, AREA_HA, Q)

# Elimina geometrías vacías (requerido para procesar con sf_as_ee)
ucs_rao_sf <- ucs_rao_sf[!st_is_empty(ucs_rao_sf), ]

# Transforma a WGS84 (EPSG:4326), requerido por GEE
ucs_sf_4326 <- st_transform(ucs_rao_sf, 4326)

```

En este bloque se leen los archivos `.csv` generados por GEE, se convierten a objetos `sf`, se calculan métricas derivadas (como el coeficiente de variación y su densidad por área), y se renombran las columnas para mantener consistencia.

```{r carga_covariables}

# === DEM (elevación media y variabilidad espacial) ===

# Ruta al CSV combinado
dem_cv <- read_csv(here::here("Data", "OUT_covars_csv","OUT_DEM_combinado.csv" ))

# Convierte columna .geo (GeoJSON) a geometría válida y calcula métricas
covars_dem  <- st_as_sf(
  data.frame(dem_cv, geometry = geojson_sf(dem_cv$.geo)),
  crs = 4326
  ) |>
  select(-.geo) |>
  mutate(
    dem_cv = stdDev / mean,                   # coeficiente de variación
    log_dem_cv = log(dem_cv + 1),             # log-transformación
    dem_cv_dens = dem_cv / AREA_HA,           # CV densificado por área
    log_dem_cv_dens = log(dem_cv_dens + 1),    # log densificado
    # Estandarizadas
    dem_cv_z = scale(dem_cv)[, 1],
    log_dem_cv_z = scale(log_dem_cv)[, 1],
    dem_cv_dens_z = scale(dem_cv_dens)[, 1],
    log_dem_cv_dens_z = scale(log_dem_cv_dens)[, 1],
    dem_mean_z = scale(mean)[, 1]
    ) |>
  rename(dem_mean = mean, dem_stdDev = stdDev)


# === SLOPE (pendiente media y su variabilidad espacial) ===

slope_cv <- read_csv(here::here("Data", "OUT_covars_csv", "OUT_SLOPE_combinado.csv"))

covars_slope <- st_as_sf(
  data.frame(slope_cv, geometry = geojson_sf(slope_cv$.geo)),
  crs = 4326
  ) |>
  select(-.geo) |>
  mutate(
    #mean = mean / (180 / pi),  # convierte grados a radianes
    #stdDev = stdDev / (180 / pi),
    slope_cv = stdDev / mean,
    log_slope_cv = log(slope_cv + 1),
    slope_cv_dens = slope_cv / AREA_HA,
    log_slope_cv_dens = log(slope_cv_dens + 1),
    # Estandarizadas
    slope_cv_z = scale(slope_cv)[, 1],
    log_slope_cv_z = scale(log_slope_cv)[, 1],
    slope_cv_dens_z = scale(slope_cv_dens)[, 1],
    log_slope_cv_dens_z = scale(log_slope_cv_dens)[, 1],
    slope_mean_z = scale(mean)[, 1]
    ) |>
  rename(slope_mean = mean, slope_stdDev = stdDev)


# === LST temporal (media de CV temporal por píxel, luego agregada por polígono) ===

lst_cv_temp <- read_csv(here::here("Data", "OUT_covars_csv","OUT_LST_cv_temporal_combinado.csv" ))

lst_cv_temp <- read_csv(here::here("Data", "OUT_covars_csv", "OUT_LST_cv_temporal_combinado.csv"))

covars_lst_cv_temp <- st_as_sf(
  data.frame(lst_cv_temp, geometry = geojson_sf(lst_cv_temp$.geo)),
  crs = 4326
) |>
  select(-.geo) |>
  mutate(
    log_lst_cv_temp = log(mean + 1), #acá mean es el promedio de las cv de la serie de tiempo para un polígono
    lst_cv_temp_dens = mean / AREA_HA,
    log_lst_cv_temp_dens = log(lst_cv_temp_dens + 1),
    # Estandarizadas
    lst_cv_temp_z = scale(mean)[, 1],
    log_lst_cv_temp_z = scale(log_lst_cv_temp)[, 1],
    lst_cv_temp_dens_z = scale(lst_cv_temp_dens)[, 1],
    log_lst_cv_temp_dens_z = scale(log_lst_cv_temp_dens)[, 1]
  ) |>
  rename(
    lst_cv_temp = mean,
    lst_cv_temp_sd = stdDev
  )
```

## 2. Post procesamiento

Este bloque construye la tabla base `modelo_df` **uniendo la pedodiversidad observada con las covariables** derivadas de DEM, SLOPE y LST (coeficiente de variación temporal). Se incluyen métricas transformadas y estandarizadas, útiles para el modelado posterior.

```{r join_covars}

# Elimina geometría para unir como tabla
dem_df <- covars_dem |> st_drop_geometry()
slope_df <- covars_slope |> st_drop_geometry()
lst_cv_temp_df <- covars_lst_cv_temp |> st_drop_geometry()

# Une por id_creado, AREA_HA y UCSuelo
modelo_df <- ucs_rao_sf |>
  mutate(
    Q = if_else(Q == 0, 1e-3, Q),              # Evita log(0)
    Qdens = Q / AREA_HA,                       # Densidad de diversidad
    log_Qdens = log(Qdens + 1),                # Transformación log
    log_Qdens01 = (log_Qdens - min(log_Qdens)) / 
                  (max(log_Qdens) - min(log_Qdens)) # Escalado entre 0–1
  ) |>
  left_join(dem_df,          by = c("id_creado", "AREA_HA", "UCSuelo")) |>
  left_join(slope_df,        by = c("id_creado", "AREA_HA", "UCSuelo")) |>
  left_join(lst_cv_temp_df,  by = c("id_creado", "AREA_HA", "UCSuelo"))

# Verifica que la unión fue exitosa
glimpse(modelo_df)
```

Este bloque depura el conjunto de datos para el ajuste de modelos logit que predicen hotspots de pedodiversidad. Se eliminan observaciones con valores faltantes en covariables clave, se construye la variable binaria `log_Qdens_hot95` (indicador de hotspot), y se conserva únicamente el subconjunto completo de datos para modelado.

```{r preparacion_modelado_logit}

# Filtra UCS con covariables completas (sin NA en las variables seleccionadas)
modelo_df_completo <- modelo_df |>
  drop_na(
    log_Qdens,                                # Diversidad logarítmica densificada
    dem_mean, slope_mean,                     # Elevación y pendiente media
    dem_cv_dens, log_dem_cv_dens,             # Densidad y log de CV de elevación
    slope_cv_dens, log_slope_cv_dens,         # Densidad y log de CV de pendiente
    lst_cv_temp, log_lst_cv_temp,             # CV temporal de LST y su log
    lst_cv_temp_dens, log_lst_cv_temp_dens    # Densidad y log de CV temporal de LST
  )


# Calcula el percentil 95 de diversidad (logarítmica densificada)
umbral_hot95 <- quantile(modelo_df_completo$log_Qdens, 0.95, na.rm = TRUE)

# Crea variable binaria de hotspot (1 si es hotspot, 0 si no)
modelo_df_completo <- modelo_df_completo |>
  mutate(log_Qdens_hot95 = as.integer(log_Qdens >= umbral_hot95))
```

Este bloque crea subconjuntos balanceados para ajustar modelos logit explicando hotspots de diversidad. Se comparan dos estrategias:

-   **Estrategia A:** Usar *coldspots* (valores más bajos de diversidad) como clase 0.

-   **Estrategia B:** Seleccionar aleatoriamente una proporción de no-hotspots equivalente a 4 veces el número de hotspots, para aproximar una distribución realista de clases.

```{r seleccion_subconjuntos_balanceados}

# Cuántos hotspots hay en total
n_hot <- modelo_df_completo |> filter(log_Qdens_hot95 == 1) |> nrow()

# Estrategia A: Coldspots (5% inferior de diversidad log_Qdens)
umbral_cold <- quantile(modelo_df_completo$log_Qdens, 0.05, na.rm = TRUE)

#contiene únicamente hotspots (1) y coldspots (0).
modelo_df_cold <- modelo_df_completo |>
  filter(log_Qdens >= umbral_hot95 | log_Qdens <= umbral_cold) |>
  mutate(log_Qdens_hot95 = as.integer(log_Qdens >= umbral_hot95))

# Estrategia B: Selección aleatoria de no-hotspots
# ontiene hotspots (1) y un subconjunto aleatorio balanceado de no-hotspots (0)
# Número total de hotspots (clase positiva)
n_hot <- modelo_df_completo |> filter(log_Qdens_hot95 == 1) |> nrow()

# Número de no-hotspots deseado (proporción 1:3)
n_nohot <- n_hot * 4

# Semilla para reproducibilidad
set.seed(123)

# Selección de muestra con proporción 1:3
modelo_df_balanceado <- modelo_df_completo |>
  filter(
    log_Qdens_hot95 == 1 | 
      row_number() %in% sample(which(log_Qdens_hot95 == 0), n_nohot)
  )



```

## 3. Modelado

Se corre un modelo GLM binomial para explicar los hotspots.

Este bloque ajusta dos modelos binomiales:

### 3.1 Usando hotspots (95%) vs coldspots (5%)

```{r ajuste_modelos_logit_A}

# === Modelo A: Hotspots vs Coldspots ===
glm_hot_cold <- glm(
  formula = log_Qdens_hot95 ~ dem_mean_z + slope_mean_z + log_dem_cv_dens_z +
    log_slope_cv_dens_z + log_lst_cv_temp_dens_z,
  data = modelo_df_cold,
  family = binomial()
)

# Agrega predicción y residuales a modelo_df_cold
modelo_df_cold <- modelo_df_cold |>
  mutate(
    prob_hot_cold = predict(glm_hot_cold, type = "response"),
    resid_hot_cold = residuals(glm_hot_cold, type = "response")
  )

# Reporta ajuste
summary(glm_hot_cold)
performance::r2_tjur(glm_hot_cold)



```

**Modelo A** presentó síntomas claros de *separación perfecta* (perfect separation), como:

-   Coeficientes extremadamente grandes.
-   Errores estándar exorbitantes (\>20,000).
-   R² de Tjur = 1.0 (indicador de sobreajuste extremo).
-   Máximo número de iteraciones sin convergencia robusta.

### 3.2 Usando hotspots (95%) vs muestra aleatoria balanceada de no-hotspots

```{r ajuste_modelos_logit_B}

# === Modelo B: Hotspots vs muestra aleatoria (balanceado) ===
glm_hot_bal <- glm(
  formula = log_Qdens_hot95 ~ dem_mean_z + slope_mean_z + log_dem_cv_dens_z +
    log_slope_cv_dens_z + log_lst_cv_temp_dens_z,
  data = modelo_df_balanceado,
  family = binomial()
)

# Agrega predicción y residuales a modelo_df_balanceado
modelo_df_balanceado <- modelo_df_balanceado |>
  mutate(
    prob_hot_bal = predict(glm_hot_bal, type = "response"),
    resid_hot_bal = residuals(glm_hot_bal, type = "response")
  )

# Reporta ajuste
summary(glm_hot_bal)
performance::r2_tjur(glm_hot_bal)

```

En contraste, el modelo B mostró:

-   Estabilidad numérica adecuada.
-   Coeficientes significativos para algunas variables clave.
-   R² de Tjur = 0.812 (alto, pero plausible).

El \*modelo B es preferido por su robustez, interpretabilidad y aplicabilidad predictiva.\*\* En adelante, nos enfocaremos en describir gráficamente sus efectos, residuales y predicciones espaciales.

## 4. Visualización de resultados

### 4.1 Coeficientes (efectos fijos)

Se muestran los coeficientes con sus intervalos de confianza. Coeficientes alejados de 0 y con intervalos estrechos indican mayor significancia y robustez en su efecto sobre la probabilidad de hotspot.

```{r}

p_coeficientes <- plot_model(glm_hot_bal, 
                             type = "est", 
                             vline.color = "red", 
                             show.values = TRUE, 
                             transform = NULL,
                             value.offset = .3) +
  labs(title = "Coeficientes estimados del modelo") +
  theme_sjplot2() +
  scale_color_sjplot("blambus")

p_coeficientes

# Guarda la figura
ggsave(here("Figures", "coeficientes_logit_b.png"),
       plot = p_coeficientes,
       width = 6,
       height = 3,
       dpi = 350)

```

### 4.2 Gráfica de efectos marginales

Estas curvas muestran cómo varía la probabilidad predicha de hotspot a medida que cambia el valor estandarizado de cada covariable, manteniendo las demás constantes. Este bloque genera curvas marginales para las covariables significativas del modelo logit balanceado (modelo B).

```{r}

# log_dem_cv_dens_z: log(CV de elevación densificado por área), estandarizado
p_margin_log_dem_cv_dens_z <- plot_model(glm_hot_bal, type = "pred", terms = "log_dem_cv_dens_z [all]", title = NULL) +
  labs(x = "log(CV de DEM, densificado y estándar)",
       y = "Probabilidad predicha de hotspot") +
  theme_minimal()

# log_slope_cv_dens_z: log(CV de pendiente densificado por área), estandarizado
p_margin_log_slope_cv_dens_z <- plot_model(glm_hot_bal, type = "pred", terms = "log_slope_cv_dens_z [all]", title = NULL) +
  labs(x = "log(CV de SLOPE, densificado y estándar)",
       y = "Probabilidad predicha de hotspot") +
  theme_minimal()

# log_lst_cv_temp_dens_z: log(CV de temperatura superficial densificado por área), estandarizado
p_margin_log_lst_cv_dens_z <- plot_model(glm_hot_bal, type = "pred", terms = "log_lst_cv_temp_dens_z [all]", title = NULL) +
  labs(x = "log(CV temporal de LST, densificado y estándar)",
       y = "Probabilidad predicha de hotspot") +
  theme_minimal()

# Mosaico de curvas marginales
p_curvas_marginales_logit_b <- p_margin_log_dem_cv_dens_z + p_margin_log_slope_cv_dens_z + p_margin_log_lst_cv_dens_z

# Visualiza las curvas
p_curvas_marginales_logit_b

# Guarda la figura
ggsave(here("Figures", "curvas_marginales_modelo_logit_b.png"),
       plot = p_curvas_marginales_logit_b,
       width = 9,
       height = 4,
       dpi = 350)


```

### 4.3 Residuales

El análisis de los residuales del modelo logit permite evaluar qué tan bien se ajusta el modelo a los datos observados. En modelos GLM (como el logit), los residuales no deben interpretarse igual que en regresiones lineales clásicas, pero siguen siendo cruciales para detectar mal ajuste, patrones no explicados o estructura espacial remanente.

Existen distintos tipos de residuales en modelos binomiales:

Residuos de respuesta (response): diferencia entre el valor observado (0/1) y la probabilidad predicha.

Residuos de Pearson: estandarizados respecto a la varianza esperada bajo el modelo. Útiles para detectar outliers.

Residuos deviance: basados en la función de verosimilitud. Informan sobre la contribución de cada observación al deviance total.

En este caso usamos residuos de tipo response, los más directos para interpretar y visualizar espacialmente.

Un residuo de +1 indica que el modelo predijo 0 pero el valor real fue 1 (hotspot observado, no predicho), mientras que un valor de -1 significa que el modelo predijo un hotspot donde no lo había. Valores cercanos a 0 indican buen ajuste.

```{r}

p_resid_log_dem_cv_dens_z <- ggplot(modelo_df_balanceado, aes(x = log_dem_cv_dens_z, y = resid_hot_bal)) +
  geom_point(alpha = 0.3, color = "#56B4E9") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(y = "Residuos", x = "log(CV de elevación, densificado y estándar)") +
  theme_minimal()

p_resid_log_slope_cv_dens_z <- ggplot(modelo_df_balanceado, aes(x = log_slope_cv_dens_z, y = resid_hot_bal)) +
  geom_point(alpha = 0.3, color = "#56B4E9") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(y = "Residuos", x = "log(CV de pendiente, densificado y estándar)") +
  theme_minimal()

p_resid_log_lst_cv_temp_dens_z <- ggplot(modelo_df_balanceado, aes(x = log_lst_cv_temp_dens_z, y = resid_hot_bal)) +
  geom_point(alpha = 0.3, color = "#56B4E9") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(y = "Residuos", x = "log(CV temporal de temperatura superficial, densificado y estándar)") +
  theme_minimal()


p_resid_balanceado_logit <- p_resid_log_dem_cv_dens_z + p_resid_log_slope_cv_dens_z + p_resid_log_lst_cv_temp_dens_z

ggsave(here("Figures", "mosaico_residuales_logit.png"),
       plot = p_resid_balanceado_logit,
       width = 12,
       height = 5,
       dpi = 350)
```

En esta sección mostramos tres mapas clave para interpretar el modelo logístico:

Hotspots observados: zonas donde la diversidad densificada supera el percentil 95. Sirve como referencia empírica para evaluar el modelo.

Probabilidad predicha de hotspot: valores continuos entre 0 y 1 generados por el modelo. Una alta probabilidad indica que el modelo espera un hotspot allí.

Residuos del modelo: diferencia entre observación y predicción. Permiten identificar zonas donde el modelo sobrestima o subestima la probabilidad de hotspot.

La comparación visual entre estas capas permite detectar áreas donde el modelo falla sistemáticamente o donde hay alta incertidumbre, lo que justifica el análisis espacial posterior.

```{r}

# Extrae los hotspots observados como puntos
hotspots_obs_sf <- modelo_df_balanceado |> 
  filter(log_Qdens_hot95 == 1)

# Mapa 1: solo hotspots observados como puntos, UCS en fondo
p_mapa_obs <- ggplot() +
  geom_sf(data = modelo_df_balanceado, fill = NA, color = "grey90", size = 0.1) +
  geom_sf(data = hotspots_obs_sf, color = col_hot, size = 2) +
  labs(title = "Hotspots observados (puntos)") +
  theme_minimal()

# Mapa 2: probabilidad predicha
p_mapa_pred <- ggplot(modelo_df_balanceado) +
  geom_sf(aes(fill = prob_hot_bal), color = NA) +
  scale_fill_gradientn(
  colours = rev(viridis::plasma(100)),  # ← rev() invierte los colores
  limits = c(0, 0.6),
  oob = scales::squish,
  name = "Probabilidad\npredicha"
  ) +
  labs(title = "Probabilidad predicha de hotspot") +
  theme_minimal()

# Mapa 3: residuales
p_mapa_resid <- ggplot(modelo_df_balanceado) +
  geom_sf(aes(fill = resid_hot_bal), color = NA) +
  scale_fill_gradientn(
    colours = viridis::viridis(100),
    limits = c(-0.5, 0.5),
    name = "Residuo"
  ) +
  labs(title = "Residuales del modelo") +
  theme_minimal()

# Mosaico con patchwork
p_mapas_logit <- p_mapa_obs + p_mapa_pred + p_mapa_resid + plot_layout(ncol = 3)

# Guardar la figura
ggsave(
  filename = here("Figures", "mosaico_mapa_prediccion_logit.png"),
  plot = p_mapas_logit,
  width = 12,
  height = 5.5,
  dpi = 350
)

```

## 5.Autocorrelación espacial de los residuales (Moran I)

A continuación, se evalúa si los residuales del modelo logit presentan autocorrelación espacial, es decir, si las discrepancias entre predicciones y observaciones tienden a agruparse espacialmente. Esta evaluación permite responder preguntas como:

¿Hay zonas del territorio donde el modelo falla sistemáticamente?

¿Podría haber variables omitidas con estructura espacial?

¿Los errores del modelo son aleatorios o siguen patrones regionales?

Para ello, se aplica el índice de Moran I, que mide la autocorrelación espacial global entre los valores de una variable (en este caso, los residuales) y su distribución geográfica.

Usaremos:

-   Centroides de UCS, para definir la posición espacial.
-   Vecinos por k-vecinos más cercanos (por ejemplo k = 6), que garantiza conectividad y es estable en cuanto a escala.

Se usa la vecindad por distancia pues estamos analizando los residuos de un modelo logit, que fue ajustado sobre un subconjunto. Este subconjunto no cubre el espacio completo ni garantiza contigüidad, y muchas UCS seleccionadas no son vecinas entre sí.

```{r analisis_moran_I}

# Usamos los centroides de los UCS para definir relaciones espaciales
modelo_centroides <- modelo_df_balanceado |> 
  st_centroid(of_largest_polygon = TRUE)

# Extraemos coordenadas de los centroides
coords <- st_coordinates(modelo_centroides)

# Construye vecinos por k más cercanos (k=6 es común en análisis ecológicos y espaciales)
k_vecinos <- knearneigh(coords, k = 6)
vecindario <- knn2nb(k_vecinos)

# Matriz de pesos espacial estandarizada (filas suman 1)
pesos <- nb2listw(vecindario, style = "W", zero.policy = TRUE)

# Moran I global sobre residuales del modelo logit
moran_global <- moran.test(modelo_df_balanceado$resid_hot_bal, listw = pesos, zero.policy = TRUE)

print(moran_global)


```

Moran's I \> 0: indica autocorrelación espacial positiva en los residuos: valores similares (altos o bajos) tienden a agruparse espacialmente.

Z-score elevado y p-valor \< 0.001: este patrón es estadísticamente significativo y no aleatorio.

Magnitud de I: aunque el valor absoluto (≈ 0.06) no es alto, es suficiente para rechazar la hipótesis nula de aleatoriedad espacial.

El modelo no captura completamente la estructura espacial de los hotspots de pedodiversidad.

Hay información espacial residual: zonas donde el modelo sobrepredice o subpredice de forma agrupada.

Esto puede deberse a:

-   Covariables espaciales faltantes o mal representadas.
-   Efectos espaciales latentes (estructura de paisaje, geología, clima).
-   Posible efecto MAUP (problemas por escala y forma de unidades espaciales).

Dado este resultado, se justifica implementar modelos espaciales explícitos, como modelos bayesianos con estructuras CAR o SAR (INLA, brms).

```{r}

# Moran local (LISA)
moran_local <- localmoran(modelo_df_balanceado$resid_hot_bal, listw = pesos, zero.policy = TRUE)

# Calcula el lag espacial de los residuos (para el scatterplot)
modelo_df_balanceado <- modelo_df_balanceado |>
  mutate(
    local_moran_I = moran_local[, 1],
    p_valor_local = moran_local[, 5],
    lag_resid = lag.listw(pesos, resid_hot_bal)
  )

# Clasifica tipo de agrupamiento espacial
modelo_df_balanceado <- modelo_df_balanceado |>
  mutate(
    cluster_tipo = case_when(
      resid_hot_bal > 0 & lag_resid > 0 ~ "High-High",
      resid_hot_bal < 0 & lag_resid < 0 ~ "Low-Low",
      resid_hot_bal > 0 & lag_resid < 0 ~ "High-Low",
      resid_hot_bal < 0 & lag_resid > 0 ~ "Low-High",
      TRUE ~ "No significativo"
    ),
    cluster_tipo = ifelse(p_valor_local > 0.05, "No significativo", cluster_tipo)
  )

```

La figura a continuación resume la estructura espacial de los residuales del modelo, evaluando si existen patrones de agrupamiento no explicados por las covariables:

Diagrama de dispersión de Moran local (izquierda): muestra la relación entre cada residuo y el promedio de sus vecinos (lag espacial). Cada punto está coloreado según el tipo de agrupamiento LISA (e.g., High-High, Low-Low). La pendiente indica el grado de autocorrelación local.

Mapa de agrupamientos LISA (centro): clasifica cada unidad en cinco categorías según la combinación de su residuo y el de sus vecinos. Ayuda a identificar zonas con agrupamiento significativo de errores (e.g., agrupaciones de sobrepredicción).

Mapa del estadístico local (Ii) (derecha): representa la magnitud del valor de autocorrelación local, sin categorizarlo. Útil para detectar valores extremos y la intensidad del patrón espacial.

```{r}

# Define colores personalizados desde paleta Zissou1 (viridis-like)
pal <- wes_palette("Zissou1", 100, type = "continuous")
colores_lisa <- c(
  "High-High"        = pal[90],   # rojo intenso
  "Low-Low"          = pal[10],   # azul oscuro
  "High-Low"         = pal[70],   # naranja
  "Low-High"         = pal[30],   # celeste
  "No significativo" = "grey90"   # gris neutro
)

# Gráfico 1: Scatterplot de Moran local coloreado por tipo de agrupamiento
p_scatter_lisa <- ggplot(modelo_df_balanceado, aes(x = resid_hot_bal, y = lag_resid)) +
  geom_point(aes(color = cluster_tipo), alpha = 0.8, size = 1.5) +
  geom_smooth(method = "lm", se = FALSE, color = "black", linewidth = 0.5) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey60") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey60") +
  scale_color_manual(values = colores_lisa) +
  labs(
    title = "Diagrama de dispersión Moran local",
    x = "Residuo del modelo",
    y = "Lag espacial",
    color = "Tipo de agrupamiento"
  ) +
  theme_minimal()

# Gráfico 2: Mapa LISA de agrupamientos espaciales
p_moran_lisa <- ggplot(modelo_df_balanceado) +
  geom_sf(aes(fill = cluster_tipo), color = NA) +
  scale_fill_manual(values = colores_lisa, na.value = "white") +
  labs(title = "Mapa: agrupamientos LISA (residuales)",
       fill = "Tipo de agrupamiento") +
  theme_minimal()

# Gráfico 3: Mapa de valores Ii (magnitude de autocorrelación local)
p_ii_mapa <- ggplot(modelo_df_balanceado) +
  geom_sf(aes(fill = local_moran_I), color = NA) +
  scale_fill_viridis_c(name = "Ii", option = "magma", direction = -1) +
  labs(title = "Mapa: valor del estadístico local (Ii)") +
  theme_minimal()

# Composición de los tres gráficos
p_lisa_tripanel <- p_scatter_lisa + p_moran_lisa + p_ii_mapa + 
  plot_layout(ncol = 3)

# Mostrar y guardar
print(p_lisa_tripanel)

ggsave(
  here::here("Figures", "moran_local_composicion_logit.png"),
  plot = p_lisa_tripanel,
  width = 15,
  height = 5,
  dpi = 300
)

```

En este contexto, un Low-Low indica un conjunto de unidades cartográficas de suelo (UCS) cuyos residuos son consistentemente negativos, y además están rodeadas por otras UCS con residuos negativos, de manera significativa.

Esto sugiere una subpredicción sistemática en esa zona: es decir, el modelo está prediciendo probabilidades más bajas de hotspot que las que realmente se observan.

En resumen: los agrupamientos Low-Low son zonas donde el modelo tiende a subestimar la probabilidad de hotspots, y esa subestimación no es aleatoria sino espacialmente agrupada.
