View(datos_NA_niveles)
correcciones <- c(
#Vichada
"Oxiaquic" = "Oxyaquic",
"Xantic" = "Xanthic",
#Antioquia
"Fluvaquenti" = "Fluventic",
"Fluventicc" = "Fluventic",
"Usthorthents" =  "Ustorthents",
"Hapludoxs" = "Hapludox",
"Kandiudoxs" = "Kandiudox",
"Haplofibrist" = "Haplofibrists",
"Haplofibristss" = "Haplofibrists")
# Correcciones manuales conocidas (puedes agregar más si aparecen otros errores)
datos_largos <- datos_largos |>
mutate(nombre_taxonomico = str_replace_all(nombre_taxonomico, correcciones))
# Añadir niveles taxonómicos usando SoilTaxonomy
datos_niveles <- datos_largos %>%
mutate(
orden = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "order")),
suborden = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "suborder")),
gran_grupo = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "greatgroup")),
subgrupo = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "subgroup"))
)
datos_NA_niveles <- datos_niveles |>
filter(is.na(orden) | is.na(suborden) | is.na(gran_grupo) | is.na(subgrupo))
View(datos_NA_niveles)
View(datos_subgrupo_validos)
palabras_problema <- c(
"Cuerpo",
"Cuerpos",
"Misceláneos",
"Misceláneo",
"Afloramientos",
"Afloramiento",
"Vegetacion",
"Vegetación",
"Otros",
"Zona",
"Zonas",
"Roca",
"Afloramientos Rocosos",
"Misceláneo de playas",
"Pantanos y marismas",
"Misceláneo arenoso"
)
datos_subgrupo_validos <- ucs_depto_piloto_sf |>
mutate(
# Reemplaza en SUBGRUPO la última palabra problemática junto con cualquier coma o espacios antes de ella
SUBGRUPO = str_replace(
SUBGRUPO,
# Patrón regex:
# [,\\s]*  -> cero o más comas o espacios justo antes de la palabra final
# (palabras_problema separadas por |) -> cualquiera de las palabras de la lista
# $ -> que esté al final del texto
str_c("[,\\s]*(", str_c(palabras_problema, collapse = "|"), ")$", collapse = ""),
""  # Reemplaza con cadena vacía, es decir, elimina esa parte
),
#Elimina espacios vacios al principio y al final
SUBGRUPO = str_squish(SUBGRUPO),
# Extrae la primera palabra del texto ya corregido en SUBGRUPO para usarla en el filtro
primer_palabra = word(SUBGRUPO, 1)
) |>
# Filtra filas para quedarse solo con aquellas que:
# - No tienen primer palabra en la lista problemática, o
# - Tienen varios suelos separados por ";"
filter(
!primer_palabra %in% palabras_problema |
str_detect(SUBGRUPO, ";")
) |>
# Elimina la columna auxiliar 'primer_palabra' que ya no se necesita
select(-primer_palabra) |>
# Quita la geometría del objeto sf para evitar problemas en pasos posteriores
sf::st_drop_geometry()
datos_con_error <- datos_subgrupo_validos %>%
mutate(
#Divide el vector en una lista de partes separadas por ;, ignorando espacios después del ;
componentes = str_split(SUBGRUPO, ",\\s*"),
porcentajes = str_split(PORCENTAJE, ",\\s*"),
#Cuenta cuántos componentes tiene cada elemento de la lista
n_componentes = map_int(componentes, length),
n_porcentajes = map_int(porcentajes, length)
) %>%
# Filtra las filas donde el número de componentes difiere del de porcentajes
filter(n_componentes != n_porcentajes)
# Mostrar las UCS problemáticas
print(datos_con_error %>% select(id_creado, SUBGRUPO, PORCENTAJE))
# Segundo, filtrar los datos que fueron excluidos
datos_excluidos <- ucs_depto_piloto_sf |>
st_drop_geometry() |>
anti_join(datos_subgrupo_validos, by = "id_creado")
View(datos_excluidos)
datos_con_error <- datos_subgrupo_validos %>%
mutate(
#Divide el vector en una lista de partes separadas por ;, ignorando espacios después del ;
componentes = str_split(SUBGRUPO, ",\\s*"),
porcentajes = str_split(PORCENTAJE, ",\\s*"),
#Cuenta cuántos componentes tiene cada elemento de la lista
n_componentes = map_int(componentes, length),
n_porcentajes = map_int(porcentajes, length)
) %>%
# Filtra las filas donde el número de componentes difiere del de porcentajes
filter(n_componentes != n_porcentajes)
# Mostrar las UCS problemáticas
print(datos_con_error %>% select(id_creado, SUBGRUPO, PORCENTAJE))
corregir_porcentajes <- function(p_string, n_taxones) {
# Si el string está vacío, es NA o contiene "No aplica" (sin importar mayúsculas)
# asigna porcentajes iguales entre todos los taxones
if (is.na(p_string) || p_string == "" || str_detect(p_string, regex("no aplica", ignore_case = TRUE))) {
p_num <- rep(100 / n_taxones, n_taxones)
es_asignacion_igual <- TRUE
} else {
# Separa el string por comas y limpia espacios
p <- str_trim(str_split(p_string, ",\\s*")[[1]])
# Convierte a numérico suprimiendo advertencias (por textos no numéricos)
p_num <- suppressWarnings(as.numeric(p))
# Si todos los valores son NA después de convertir, asigna valores iguales
if (all(is.na(p_num))) {
p_num <- rep(100 / n_taxones, n_taxones)
es_asignacion_igual <- TRUE
} else {
es_asignacion_igual <- FALSE
# Si hay un porcentaje de más, elimina el último
if (length(p_num) == n_taxones + 1) {
p_num <- p_num[1:n_taxones]
# Si hay uno de menos, calcula el faltante para completar 100 y lo agrega
} else if (length(p_num) == n_taxones - 1) {
faltante <- 100 - sum(p_num, na.rm = TRUE)
p_num <- c(p_num, faltante)
}
# Si aún no coincide la longitud, devuelve NAs y advierte
if (length(p_num) != n_taxones) {
warning("Número de porcentajes no coincide con número de taxones")
return(list(porcentajes = rep(NA_real_, n_taxones), es_asignacion_igual = es_asignacion_igual))
}
# Escala los porcentajes para que sumen exactamente 100 (preserva proporciones)
suma_total <- sum(p_num, na.rm = TRUE)
if (!is.na(suma_total) && suma_total != 100 && suma_total > 0) {
p_num <- 100 * p_num / suma_total
}
}
}
# Devuelve lista con los porcentajes corregidos y flag de asignación automática
return(list(porcentajes = p_num, es_asignacion_igual = es_asignacion_igual))
}
datos_largos <- datos_subgrupo_validos %>%
# Separa los componentes en listas por ",", ";" o "."
mutate(componentes = str_split(SUBGRUPO, ",\\s*|;\\s*|\\.\\s*"),
# Cuenta el número de componentes por fila
n_componentes = map_int(componentes, length),
# Aplica la función corregir_porcentajes que devuelve lista con porcentajes y flag
correcciones = map2(PORCENTAJE, n_componentes, corregir_porcentajes),
# Extrae los porcentajes corregidos
porcentajes = map(correcciones, "porcentajes"),
# Extrae el flag que indica asignación automática
asignacion_igual = map_lgl(correcciones, "es_asignacion_igual"),
# Cuenta los porcentajes corregidos
n_porcentajes = map_int(porcentajes, length)) %>%
# Filtra filas donde número de componentes y porcentajes coinciden
filter(n_componentes == n_porcentajes) %>%
# Expande listas de componentes y porcentajes a filas largas
unnest(c(componentes, porcentajes)) %>%
# Limpia espacios y convierte porcentajes a numérico
mutate(nombre_taxonomico = str_trim(componentes),
porcentaje = porcentajes) %>%
# Selecciona columnas relevantes, incluyendo el flag para seguimiento
select(id_creado, nombre_taxonomico, porcentaje, asignacion_igual)
# Añadir niveles taxonómicos usando SoilTaxonomy
datos_niveles <- datos_largos %>%
mutate(
orden = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "order")),
suborden = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "suborder")),
gran_grupo = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "greatgroup")),
subgrupo = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "subgroup"))
)
datos_NA_niveles <- datos_niveles |>
filter(is.na(orden) | is.na(suborden) | is.na(gran_grupo) | is.na(subgrupo))
datos_NA_niveles <- datos_niveles |>
filter(is.na(orden) | is.na(suborden) | is.na(gran_grupo) | is.na(subgrupo))
View(datos_NA_niveles)
correcciones <- c(
#Vichada
"Oxiaquic" = "Oxyaquic",
"Xantic" = "Xanthic",
#Antioquia
"Fluvaquenti" = "Fluventic",
"Fluventicc" = "Fluventic",
"Usthorthents" =  "Ustorthents",
"Hapludoxs" = "Hapludox",
"Kandiudoxs" = "Kandiudox",
"Haplofibrist" = "Haplofibrists",
"Haplofibristss" = "Haplofibrists")
# Correcciones manuales conocidas (puedes agregar más si aparecen otros errores)
datos_largos <- datos_largos |>
mutate(nombre_taxonomico = str_replace_all(nombre_taxonomico, correcciones))
# Añadir niveles taxonómicos usando SoilTaxonomy
datos_niveles <- datos_largos %>%
mutate(
orden = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "order")),
suborden = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "suborder")),
gran_grupo = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "greatgroup")),
subgrupo = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "subgroup"))
)
datos_NA_niveles <- datos_niveles |>
filter(is.na(orden) | is.na(suborden) | is.na(gran_grupo) | is.na(subgrupo))
View(datos_NA_niveles)
datos_NA_niveles
palabras_problema <- c(
"Cuerpo",
"Cuerpos",
"Misceláneos",
"Misceláneo",
"Afloramientos",
"Afloramiento",
"Vegetacion",
"Vegetación",
"Otros",
"Zona",
"Zonas",
"Roca",
"Afloramientos Rocosos",
"Misceláneo de playas",
"Pantanos y marismas",
"Misceláneo arenoso"
)
datos_subgrupo_validos <- ucs_depto_piloto_sf |>
mutate(
# Reemplaza en SUBGRUPO la última palabra problemática junto con cualquier coma o espacios antes de ella
SUBGRUPO = str_replace(
SUBGRUPO,
# Patrón regex:
# [,\\s]*  -> cero o más comas o espacios justo antes de la palabra final
# (palabras_problema separadas por |) -> cualquiera de las palabras de la lista
# $ -> que esté al final del texto
str_c("[,\\s]*(", str_c(palabras_problema, collapse = "|"), ")$", collapse = ""),
""  # Reemplaza con cadena vacía, es decir, elimina esa parte
),
# Extrae la primera palabra del texto ya corregido en SUBGRUPO para usarla en el filtro
primer_palabra = word(SUBGRUPO, 1)
) |>
# Filtra filas para quedarse solo con aquellas que:
# - No tienen primer palabra en la lista problemática, o
# - Tienen varios suelos separados por ";"
filter(
str_trim(SUBGRUPO) != "",  # Quita filas donde SUBGRUPO quedó vacío
!primer_palabra %in% palabras_problema |
str_detect(SUBGRUPO, ";")
) |>
# Elimina la columna auxiliar 'primer_palabra' que ya no se necesita
select(-primer_palabra) |>
# Quita la geometría del objeto sf para evitar problemas en pasos posteriores
sf::st_drop_geometry()
# Segundo, filtrar los datos que fueron excluidos
datos_excluidos <- ucs_depto_piloto_sf |>
st_drop_geometry() |>
anti_join(datos_subgrupo_validos, by = "id_creado")
datos_con_error <- datos_subgrupo_validos %>%
mutate(
#Divide el vector en una lista de partes separadas por ;, ignorando espacios después del ;
componentes = str_split(SUBGRUPO, ",\\s*"),
porcentajes = str_split(PORCENTAJE, ",\\s*"),
#Cuenta cuántos componentes tiene cada elemento de la lista
n_componentes = map_int(componentes, length),
n_porcentajes = map_int(porcentajes, length)
) %>%
# Filtra las filas donde el número de componentes difiere del de porcentajes
filter(n_componentes != n_porcentajes)
# Mostrar las UCS problemáticas
print(datos_con_error %>% select(id_creado, SUBGRUPO, PORCENTAJE))
corregir_porcentajes <- function(p_string, n_taxones) {
# Si el string está vacío, es NA o contiene "No aplica" (sin importar mayúsculas)
# asigna porcentajes iguales entre todos los taxones
if (is.na(p_string) || p_string == "" || str_detect(p_string, regex("no aplica", ignore_case = TRUE))) {
p_num <- rep(100 / n_taxones, n_taxones)
es_asignacion_igual <- TRUE
} else {
# Separa el string por comas y limpia espacios
p <- str_trim(str_split(p_string, ",\\s*")[[1]])
# Convierte a numérico suprimiendo advertencias (por textos no numéricos)
p_num <- suppressWarnings(as.numeric(p))
# Si todos los valores son NA después de convertir, asigna valores iguales
if (all(is.na(p_num))) {
p_num <- rep(100 / n_taxones, n_taxones)
es_asignacion_igual <- TRUE
} else {
es_asignacion_igual <- FALSE
# Si hay un porcentaje de más, elimina el último
if (length(p_num) == n_taxones + 1) {
p_num <- p_num[1:n_taxones]
# Si hay uno de menos, calcula el faltante para completar 100 y lo agrega
} else if (length(p_num) == n_taxones - 1) {
faltante <- 100 - sum(p_num, na.rm = TRUE)
p_num <- c(p_num, faltante)
}
# Si aún no coincide la longitud, devuelve NAs y advierte
if (length(p_num) != n_taxones) {
warning("Número de porcentajes no coincide con número de taxones")
return(list(porcentajes = rep(NA_real_, n_taxones), es_asignacion_igual = es_asignacion_igual))
}
# Escala los porcentajes para que sumen exactamente 100 (preserva proporciones)
suma_total <- sum(p_num, na.rm = TRUE)
if (!is.na(suma_total) && suma_total != 100 && suma_total > 0) {
p_num <- 100 * p_num / suma_total
}
}
}
# Devuelve lista con los porcentajes corregidos y flag de asignación automática
return(list(porcentajes = p_num, es_asignacion_igual = es_asignacion_igual))
}
datos_largos <- datos_subgrupo_validos %>%
# Separa los componentes en listas por ",", ";" o "."
mutate(componentes = str_split(SUBGRUPO, ",\\s*|;\\s*|\\.\\s*"),
# Cuenta el número de componentes por fila
n_componentes = map_int(componentes, length),
# Aplica la función corregir_porcentajes que devuelve lista con porcentajes y flag
correcciones = map2(PORCENTAJE, n_componentes, corregir_porcentajes),
# Extrae los porcentajes corregidos
porcentajes = map(correcciones, "porcentajes"),
# Extrae el flag que indica asignación automática
asignacion_igual = map_lgl(correcciones, "es_asignacion_igual"),
# Cuenta los porcentajes corregidos
n_porcentajes = map_int(porcentajes, length)) %>%
# Filtra filas donde número de componentes y porcentajes coinciden
filter(n_componentes == n_porcentajes) %>%
# Expande listas de componentes y porcentajes a filas largas
unnest(c(componentes, porcentajes)) %>%
# Limpia espacios y convierte porcentajes a numérico
mutate(nombre_taxonomico = str_trim(componentes),
porcentaje = porcentajes) %>%
# Selecciona columnas relevantes, incluyendo el flag para seguimiento
select(id_creado, nombre_taxonomico, porcentaje, asignacion_igual)
# Añadir niveles taxonómicos usando SoilTaxonomy
datos_niveles <- datos_largos %>%
mutate(
orden = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "order")),
suborden = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "suborder")),
gran_grupo = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "greatgroup")),
subgrupo = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "subgroup"))
)
correcciones <- c(
#Vichada
"Oxiaquic" = "Oxyaquic",
"Xantic" = "Xanthic",
#Antioquia
"Fluvaquenti" = "Fluventic",
"Fluventicc" = "Fluventic",
"Usthorthents" =  "Ustorthents",
"Hapludoxs" = "Hapludox",
"Kandiudoxs" = "Kandiudox",
"Haplofibrist" = "Haplofibrists",
"Haplofibristss" = "Haplofibrists")
# Correcciones manuales conocidas (puedes agregar más si aparecen otros errores)
datos_largos <- datos_largos |>
mutate(nombre_taxonomico = str_replace_all(nombre_taxonomico, correcciones))
# Añadir niveles taxonómicos usando SoilTaxonomy
datos_niveles <- datos_largos %>%
mutate(
orden = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "order")),
suborden = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "suborder")),
gran_grupo = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "greatgroup")),
subgrupo = map_chr(nombre_taxonomico, ~getTaxonAtLevel(.x, level = "subgroup"))
)
datos_NA_niveles <- datos_niveles |>
filter(is.na(orden) | is.na(suborden) | is.na(gran_grupo) | is.na(subgrupo))
View(datos_niveles)
# Tabla de prefijos para órdenes principales (puedes ampliarla)
prefijos_orden <- tibble::tibble(
orden = c("entisols", "inceptisols", "alfisols", "ultisols", "mollisols", "vertisols", "aridisols", "oxisols", "spodosols", "histosols", "andisols", "gelisols"),
prefijo_orden = c("ents", "epts", "alfs", "ults", "olls", "erts", "ids", "ox", "ods", "ists", "ands", "els")
)
# Asocia prefijo de orden a los datos
datos_niveles_limpios <- datos_niveles %>%
left_join(prefijos_orden, by = "orden")
# Define función para generar el prefijo quitando el string de la jerarquia anterior
extraer_prefijo_nuevo <- function(nombre_actual, anterior) {
if (is.na(nombre_actual) | is.na(anterior)) {
return(NA_character_)
} else {
nombre_minuscula <- tolower(nombre_actual)
anterior_minuscula <- tolower(anterior)
nuevo_prefijo <- str_remove(nombre_minuscula, fixed(anterior_minuscula))
nuevo_prefijo <- str_extract(nuevo_prefijo, "^[a-z]+")
return(nuevo_prefijo)
}
}
datos_prefijos <- datos_niveles_limpios |>
mutate(
# El prefijo para suborden se obtiene quitando el prefijo del orden
prefijo_suborden = map2_chr(suborden, prefijo_orden, extraer_prefijo_nuevo),
# El prefijo para gran grupo se obtiene quitando el suborden
prefijo_gran_grupo = map2_chr(gran_grupo, suborden, extraer_prefijo_nuevo),
# El prefijo para subgrupo se obtiene quitando el gran grupo
prefijo_subgrupo = map2_chr(subgrupo, gran_grupo, extraer_prefijo_nuevo),
# convierte a proporción
proporcion = porcentaje / 100
) |>
group_by(id_creado) |>
mutate(ID_INTERNO = row_number()) |>  # identificador único por taxón en cada unidad
ungroup() |>
select(-porcentaje)
View(datos_prefijos)
# Crear combinaciones de pares (i, j) correctamente
pares <- datos_prefijos |>
group_by(id_creado) |>
summarise(
pares = list(tidyr::crossing(ID_1 = ID_INTERNO, ID_2 = ID_INTERNO)),
.groups = "drop" #elimina los grupos que se hayan formado
) |>
unnest(pares)
# Ahora unir los datos de cada par i, j
pares_datos <- pares %>%
left_join((datos_prefijos),
by = c("id_creado", "ID_1" = "ID_INTERNO")
) %>%
left_join((datos_prefijos),
by = c("id_creado", "ID_2" = "ID_INTERNO"),
suffix = c("_i", "_j"))
comparar_prefijos <- function(row) {
#Junta los prefijos del suelo i en un vector
niveles_i <- c(row$prefijo_orden_i, row$prefijo_suborden_i, row$prefijo_gran_grupo_i, row$prefijo_subgrupo_i)
#Junta los prefijos del suelo j en un vector
niveles_j <- c(row$prefijo_orden_j, row$prefijo_suborden_j, row$prefijo_gran_grupo_j, row$prefijo_subgrupo_j)
# Validar en qué niveles ambos tienen datos (no NA)
niveles_validos <- !is.na(niveles_i) & !is.na(niveles_j)
c <- sum(niveles_validos)  # número de niveles comparables
coincidencias <- niveles_i == niveles_j  # TRUE si coinciden por nivel
# No contar como coincidencia en subgrupo si es "typic" y los niveles anteriores son distintos
if (!is.na(row$prefijo_subgrupo_i) && row$prefijo_subgrupo_i == "typic") {
if (!is.na(row$prefijo_gran_grupo_i) && !is.na(row$prefijo_gran_grupo_j) &&
row$prefijo_gran_grupo_i != row$prefijo_gran_grupo_j) {
coincidencias[4] <- FALSE
}
}
x <- sum(coincidencias & niveles_validos)  # número de niveles con coincidencia real
dij <- if (c == 0) NA_real_ else (c - x) / c  # distancia d_ij
return(list(dij = dij, c = c, x = x))  # devolver todo como lista
}
resultado_df <- pares_datos |>
rowwise() |>
mutate(
resultado = list(comparar_prefijos(cur_data())),
dij       = resultado$dij,
c         = resultado$c,
x         = resultado$x,
prod_pipj_dij = proporcion_i * proporcion_j * dij
) |>
ungroup() |>
select(-resultado,
-ID_1,
-ID_2,
-orden_i,
-orden_j,
-suborden_i,
-suborden_j,
- gran_grupo_i,
- gran_grupo_j,
- subgrupo_i,
- subgrupo_j
)
Q_por_ID <- resultado_df %>%
group_by(id_creado) %>%
summarise(
Q = sum(prod_pipj_dij, na.rm = TRUE),
asignacion_igual_i = first(asignacion_igual_i),  # asume que 'unidad' no varía dentro del grupo
.groups = "drop"
)
# Unir los valores de Q con el objeto espacial
datos_sf_q <- ucs_depto_piloto_sf %>%
left_join(Q_por_ID, by = "id_creado")
#Paleta de colores
pal <- wes_palette("Zissou1", 100, type = "continuous")
p_rao_piloto <- ggplot(datos_sf_q) +
geom_sf(aes(fill = Q), color = NA) +
scale_fill_gradientn(colours = pal, na.value = "white") +
labs(
fill = "Entropía Q"
) +
theme_minimal()
# Guarda la figura como PNG
ggsave(
filename = here("Figures", "rao_piloto.png"),
plot = p_rao_piloto,
width = 10,
height = 8,
dpi = 300
)
#Visualiza
p_rao_piloto
#Se crea mosaico
p_mosaico_ucs_rao <- p_ucs_piloto + p_rao_piloto
# Guardar como imagen
ggsave(
filename = here("Figures", "mosaico_ucs_rao.png"),
plot = p_mosaico_ucs_rao,
width = 16,
height = 8,
dpi = 300
)
#Se visualiza
p_mosaico_ucs_rao
View(datos_sf_q)
# Para renderizar el documento
knitr::opts_chunk$set(echo = TRUE)
# Para cargar librerias se verifica pacman
if ("pacman" %in% installed.packages() == FALSE) install.packages("pacman")
# Se cargan las librerias
pacman::p_load(char = c("sf", "dplyr", "ggplot2", "here", "tidyr", "stringr", "purrr", "SoilTaxonomy", "qs","wesanderson", "patchwork"))
# Exporta los datos en formato qs
qs::qsave(datos_sf_q, here::here("Data", "rao_piloto_sf.qs"))
# Exporta los datos en formato qs
qs::qsave(datos_sf_q, here::here("Data", "OUTPUT_rao_piloto_sf.qs"))
View(datos_sf_q)
