source("~/2025_UNAL_PEDODIV/pedodiv-colombia/Scripts/00_miniconda_rgee_setup.R")
# Para cargar librerias se verifica pacman
if ("pacman" %in% installed.packages() == FALSE) install.packages("pacman")
# Carga de librer√≠as "inocentes"
pacman::p_load(char = c("here", "remotes", "sf", "geojsonio","dplyr", "ggplot2", "patchwork", "wesanderson", "qs"))
# Carga librer√≠as que usan Python
library(reticulate)
library(rgee)
library(googledrive)
# ==== Autenticaci√≥n y backend Python ====
ee_clean_user_credentials()      # Limpia credenciales de GEE
ee_clean_pyenv()           # Limpia variables de entorno de reticulate
reticulate::py_run_string("import ee; ee.Authenticate()")
reticulate::py_run_string("import ee; ee.Initialize(project='even-electron-461718-g2')")
# ==== Inicializa rgee (ignora asset_home si aparece, ya existe) ====
tryCatch(
rgee::ee_Initialize(drive = FALSE, project = 'even-electron-461718-g2'),
error = function(e) message("Si pide asset home y ya existe, solo ESC y sigue")
)
#Para exportar como .R plano
# knitr::purl('05_analisis_glm_rao_colombia.qmd')
# Para cargar librerias se verifica pacman
if ("pacman" %in% installed.packages() == FALSE) install.packages("pacman")
# Carga de librer√≠as "inocentes"
pacman::p_load(char = c("here", "remotes", "sf", "geojsonio","dplyr", "ggplot2", "patchwork", "wesanderson", "qs"))
#Selecci√≥n entorno ya existente antes de cualquier llamado que use Python: only needed while the interpreter path was not yet fixed
#reticulate::use_condaenv("rgee_py", required = TRUE)
#reticulate::py_config() # # Verifica que el python sea Miniconda3/envs/rgee_py/python.exe
# Carga librer√≠as que usan Python
library(reticulate)
library(rgee)
library(googledrive)
# ==== Autenticaci√≥n y backend Python ====
ee_clean_user_credentials()      # Limpia credenciales de GEE
#Para exportar como .R plano
# knitr::purl('05_analisis_glm_rao_colombia.qmd')
# Para cargar librerias se verifica pacman
if ("pacman" %in% installed.packages() == FALSE) install.packages("pacman")
# Carga de librer√≠as "inocentes"
pacman::p_load(char = c("here", "remotes", "sf", "geojsonio","dplyr", "ggplot2", "patchwork", "wesanderson", "qs"))
#Selecci√≥n entorno ya existente antes de cualquier llamado que use Python: only needed while the interpreter path was not yet fixed
reticulate::use_condaenv("rgee_py", required = TRUE)
#reticulate::py_config() # # Verifica que el python sea Miniconda3/envs/rgee_py/python.exe
# Carga librer√≠as que usan Python
library(reticulate)
library(rgee)
library(googledrive)
# ==== Autenticaci√≥n y backend Python ====
ee_clean_user_credentials()      # Limpia credenciales de GEE
ee_clean_pyenv()           # Limpia variables de entorno de reticulate
reticulate::py_run_string("import ee; ee.Authenticate()")
reticulate::py_run_string("import ee; ee.Initialize(project='even-electron-461718-g2')")
# ==== Inicializa rgee (ignora asset_home si aparece, ya existe) ====
tryCatch(
rdee::ee_Initialize(
drive       = FALSE,                         # or TRUE if you want Drive export
project     = "even-electron-461718-g2",     # your Cloud Project
asset_home  = "users/cmguiob_g",             # <-- tell rgee the folder exists
quiet       = TRUE
),
error = function(e) message("Si pide asset home y ya existe, solo ESC y sigue")
)
# Se consultan datos de DEM
img <- ee$Image("USGS/SRTMGL1_003")
#Consulta que propiedades est√°n disponibles
img$propertyNames()$getInfo()
# Corre script externo para cargar
source(here::here("Scripts", "00_funcion_carga_ucs_procesadas_qs.R"), encoding = "UTF-8")
# Asignaci√≥n de id √∫nico para cada pol√≠gono
ucs_rao_sf <- ucs_rao_sf |> mutate(id = row_number())
head(ucs_rao_sf)
# Define ruta y nombre de capa de geopackage de departamentos
deptos_ruta <- here("Data", "INP_departamentos_IGAC_Abril_2025.gpkg")
capa_nombre_deptos <- sf::st_layers(deptos_ruta)$name[1]
# Carga geopackage de dpartamentos
departamentos_sf <- sf::st_read(
deptos_ruta,
layer = capa_nombre_deptos,
quiet = TRUE
) |>
# Se seleccionan 21 departamentos de la zona Andina, Caribe y Pac√≠fica
dplyr::filter(DeNombre %in% c(
"Antioquia",
"Atl√°ntico",
"Bol√≠var",
"Boyac√°",
"Caldas",
"Cauca",
"Cesar",
"Choc√≥",
"C√≥rdoba",
"Cundinamarca",
"Huila",
"La Guajira",
"Magdalena",
"Nari√±o",
"Norte de Santander",
"Quind√≠o",
"Risaralda",
"Santander",
"Sucre",
"Tolima",
"Valle del Cauca")
) |>
tidyr::drop_na()
# departamento_1_sf pasa de "SHAPE" a "geometry"
names(departamentos_sf)[names(departamentos_sf) == "SHAPE"] <- "geometry"
departamentos_sf <- sf::st_as_sf(as.data.frame(departamentos_sf), sf_column_name = "geometry")
# Aseguramos que ambos datasets tengan la misma proyecci√≥n
departamentos_sf <- st_transform(departamentos_sf, st_crs(ucs_rao_sf))
# Se unen los pol√≠gonos en uno solo
limite_poly <- st_union(departamentos_sf)
ucs_ee     <- sf_as_ee(ucs_rao_sf)
estudio_ee <- sf_as_ee(limite_poly)
# Carga y suavizado del DEM SRTM 30 m
dem_orig   <- ee$Image("USGS/SRTMGL1_003")$rename("DEM")$clip(estudio_ee)
gauss      <- ee$Kernel$gaussian(radius=3, sigma=2, units="pixels", normalize=TRUE)
dem_smooth <- dem_orig$convolve(gauss)$resample("bilinear")
# 1. Centrar el visor en tu √°rea de inter√©s
Map$setCenter(lon = -74, lat = 4, zoom = 6)
# 2. A√±adir el DEM original (sin suavizar)
Map$addLayer(
dem_orig,
visParams = list(min = 0, max = 3000,
palette = c("blue","green","yellow","red")),
name = "DEM original"
)
# 3. A√±adir el DEM suavizado
Map$addLayer(
dem_smooth,
visParams = list(min = 0, max = 3000,
palette = c("blue","green","yellow","red")),
name = "DEM suavizado"
)
# 7. Importar y ejecutar TAGEE en GEE para atributos de terreno
tagee      <- ee$call("require", "users/zecojls/TAGEE:TAGEE-functions")
reticulate::py_last_error()
#Para exportar como .R plano
# knitr::purl('05_analisis_glm_hotspots.qmd')
if (!"pacman" %in% installed.packages()) install.packages("pacman")
pacman::p_load(here, remotes, sf, geojsonio, dplyr, ggplot2,
patchwork, wesanderson, qs)
# Selecci√≥n entorno ya existente antes de cualquier llamado que use Python
reticulate::use_condaenv("rgee_py", required = TRUE)
## Librer√≠as que usan Python
library(reticulate)
library(rgee)
library(googledrive)
# ==== Autenticaci√≥n y backend Python ====
ee_clean_user_credentials()      # Limpia credenciales de GEE
ee_clean_pyenv()           # Limpia variables de entorno de reticulate
reticulate::py_run_string("import ee; ee.Authenticate()")
reticulate::py_run_string("import ee; ee.Initialize(project='even-electron-461718-g2')")
# Se consultan datos de DEM
img <- ee$Image("USGS/SRTMGL1_003")
#Consulta que propiedades est√°n disponibles
img$propertyNames()$getInfo()
# Consultar una propiedad espec√≠fica, e.g. keywords
img$get("keywords")$getInfo()
# Corre script externo para cargar
source(here::here("Scripts", "00_funcion_carga_ucs_procesadas_qs.R"), encoding = "UTF-8")
# Asignaci√≥n de id √∫nico para cada pol√≠gono
ucs_rao_sf <- ucs_rao_sf |>
sf::st_make_valid() |> #valida geometrias problem√°ticas
dplyr::select(id_creado, UCSuelo, AREA_HA)
ucs_rao_sf <- ucs_rao_sf[!st_is_empty(ucs_rao_sf), ]
plot(st_geometry(ucs_rao_sf))
#Para exportar como .R plano
# knitr::purl('05_analisis_glm_hotspots.qmd')
if (!"pacman" %in% installed.packages()) install.packages("pacman")
pacman::p_load(here, remotes, sf, geojsonio, geojsonsf, dplyr, ggplot2,
patchwork, wesanderson, qs)
# Selecci√≥n entorno ya existente antes de cualquier llamado que use Python
reticulate::use_condaenv("rgee_py", required = TRUE)
## Librer√≠as que usan Python
library(reticulate)
library(rgee)
library(googledrive)
# ==== Autenticaci√≥n y backend Python ====
ee_clean_user_credentials()      # Limpia credenciales de GEE
ee_clean_pyenv()           # Limpia variables de entorno de reticulate
reticulate::py_run_string("import ee; ee.Authenticate()")
reticulate::py_run_string("import ee; ee.Initialize(project='even-electron-461718-g2')")
# === Autenticaci√≥n Google Drive ===
googledrive::drive_auth()
# Se consultan datos de DEM
img <- ee$Image("USGS/SRTMGL1_003")
#Consulta que propiedades est√°n disponibles
img$propertyNames()$getInfo()
# Consultar una propiedad espec√≠fica, e.g. keywords
img$get("keywords")$getInfo()
pacman::p_load(here, remotes, sf, geojsonio, geojsonsf, dplyr, purrr, ggplot2,
patchwork, wesanderson, qs)
combinar_y_subir_csv <- function(propiedad,
carpeta_drive_id_origen = "17yxwhlpgL4EG8inI5u8Nwi08wOrnhJiM",  # GEE_exports
carpeta_drive_id_destino = "1qJ5S25TZaFWzueNhx1M4Gr3P8JYWKGeU",  # Proyecto
carpeta_temporal = "tmp_csv") {
# Crea carpeta temporal local si no existe
if (!dir.exists(carpeta_temporal)) {
dir.create(carpeta_temporal)
}
# Listar archivos en Google Drive (solo .csv con prefijo exacto)
archivos_drive <- googledrive::drive_ls(
path = as_id(carpeta_drive_id_origen),
pattern = glue::glue("^{propiedad}_.*\\.csv$")
) |>
dplyr::filter(stringr::str_ends(name, ".csv"))
if (nrow(archivos_drive) == 0) {
stop(glue::glue("No se encontraron archivos CSV para la propiedad '{propiedad}' en GEE_exports."))
}
message(glue::glue("üì• Descargando {nrow(archivos_drive)} archivos CSV para '{propiedad}'..."))
# Descargar archivos al directorio temporal
purrr::walk2(
archivos_drive$name,
archivos_drive$id,
~ googledrive::drive_download(
file = as_id(.y),
path = file.path(carpeta_temporal, .x),
overwrite = TRUE,
quiet = TRUE
)
)
# Leer y combinar
archivos_locales <- list.files(path = carpeta_temporal,
pattern = paste0("^", propiedad, "_.*\\.csv$"),
full.names = TRUE)
combinado <- purrr::map_dfr(archivos_locales, readr::read_csv, show_col_types = FALSE)
# Escribir archivo combinado
nombre_salida <- paste0("OUT_", propiedad, "_combinado.csv")
ruta_salida <- file.path(carpeta_temporal, nombre_salida)
readr::write_csv(combinado, ruta_salida)
# Subir a carpeta final de proyecto en Drive
archivo_subido <- googledrive::drive_upload(
media = ruta_salida,
path = as_id(carpeta_drive_id_destino),
name = nombre_salida,
overwrite = TRUE
)
message(glue::glue("‚úÖ Archivo combinado subido: {archivo_subido$name} (ID: {archivo_subido$id})"))
# Limpieza autom√°tica
unlink(carpeta_temporal, recursive = TRUE)
message("üßπ Archivos temporales eliminados.")
}
combinar_y_subir_csv("DEM")
rlang::last_trace()
combinar_y_subir_csv <- function(propiedad,
carpeta_drive_id_origen = "17yxwhlpgL4EG8inI5u8Nwi08wOrnhJiM",  # GEE_exports
carpeta_drive_id_destino = "1qJ5S25TZaFWzueNhx1M4Gr3P8JYWKGeU",  # Proyecto
carpeta_temporal = "tmp_csv") {
# Crea carpeta temporal local si no existe
if (!dir.exists(carpeta_temporal)) {
dir.create(carpeta_temporal)
}
# Listar archivos en Google Drive (solo .csv con prefijo exacto)
archivos_drive <- googledrive::drive_ls(
path = as_id(carpeta_drive_id_origen),
pattern = glue::glue("^{propiedad}_.*\\.csv$")
) |>
dplyr::filter(stringr::str_ends(name, ".csv"))
if (nrow(archivos_drive) == 0) {
stop(glue::glue("No se encontraron archivos CSV para la propiedad '{propiedad}' en GEE_exports."))
}
message(glue::glue("üì• Descargando {nrow(archivos_drive)} archivos CSV para '{propiedad}'..."))
# Descargar archivos al directorio temporal
purrr::walk2(
archivos_drive$name,
archivos_drive$id,
~ googledrive::drive_download(
file = as_id(.y),
path = file.path(carpeta_temporal, .x),
overwrite = TRUE
)
)
# Leer y combinar
archivos_locales <- list.files(path = carpeta_temporal,
pattern = paste0("^", propiedad, "_.*\\.csv$"),
full.names = TRUE)
combinado <- purrr::map_dfr(archivos_locales, readr::read_csv, show_col_types = FALSE)
# Escribir archivo combinado
nombre_salida <- paste0("OUT_", propiedad, "_combinado.csv")
ruta_salida <- file.path(carpeta_temporal, nombre_salida)
readr::write_csv(combinado, ruta_salida)
# Subir a carpeta final de proyecto en Drive
archivo_subido <- googledrive::drive_upload(
media = ruta_salida,
path = as_id(carpeta_drive_id_destino),
name = nombre_salida,
overwrite = TRUE
)
message(glue::glue("‚úÖ Archivo combinado subido: {archivo_subido$name} (ID: {archivo_subido$id})"))
# Limpieza autom√°tica
unlink(carpeta_temporal, recursive = TRUE)
message("üßπ Archivos temporales eliminados.")
}
combinar_y_subir_csv("DEM")
combinar_y_subir_csv("SLOPE")
# Ruta al CSV combinado
dem_cv <- read_csv("tmp_csv/OUT_DEM_combinado.csv", show_col_types = FALSE)
# Convierte geometr√≠a desde .geo (GeoJSON como texto) a objeto sf
dem_cv_sf <- st_as_sf(
data.frame(dem_cv, geometry = geojson_sf(dem_cv$.geo)), #convierte a sf
crs = 4326) |>
select(-.geo) |> #elimina columna de geometria obsoleta
mutate(cv = stdDev / mean) #calcula coeficiente de variaci√≥n
# Ruta al CSV combinado
dem_cv <- read_csv(here::here("Data", "OUT_DEM_combinado" ))
# Convierte geometr√≠a desde .geo (GeoJSON como texto) a objeto sf
dem_cv_sf <- st_as_sf(
data.frame(dem_cv, geometry = geojson_sf(dem_cv$.geo)), #convierte a sf
crs = 4326) |>
select(-.geo) |> #elimina columna de geometria obsoleta
mutate(cv = stdDev / mean) #calcula coeficiente de variaci√≥n
# Ruta al CSV combinado
dem_cv <- read_csv(here::here("Data", "OUT_DEM_combinado.csv" ))
# Convierte geometr√≠a desde .geo (GeoJSON como texto) a objeto sf
dem_cv_sf <- st_as_sf(
data.frame(dem_cv, geometry = geojson_sf(dem_cv$.geo)), #convierte a sf
crs = 4326) |>
select(-.geo) |> #elimina columna de geometria obsoleta
mutate(cv = stdDev / mean) #calcula coeficiente de variaci√≥n
pacman::p_load(here, remotes, sf, geojsonio, geojsonsf, dplyr, purrr, readr, ggplot2,
patchwork, wesanderson, qs)
# Ruta al CSV combinado
dem_cv <- read_csv(here::here("Data", "OUT_DEM_combinado.csv" ))
# Ruta al CSV combinado
dem_cv <- read_csv(here::here("Data", "OUT_covars_csv","OUT_DEM_combinado.csv" ))
# Convierte geometr√≠a desde .geo (GeoJSON como texto) a objeto sf
dem_cv_sf <- st_as_sf(
data.frame(dem_cv, geometry = geojson_sf(dem_cv$.geo)), #convierte a sf
crs = 4326) |>
select(-.geo) |> #elimina columna de geometria obsoleta
mutate(cv = stdDev / mean) #calcula coeficiente de variaci√≥n
View(dem_cv_sf)
47.91928/1984.036
# Ruta al CSV combinado
slope_cv <- read_csv(here::here("Data", "OUT_covars_csv","OUT_SLOPE_combinado.csv" ))
# Convierte geometr√≠a desde .geo (GeoJSON como texto) a objeto sf
slope_cv_sf <- st_as_sf(
data.frame(slope_cv, geometry = geojson_sf(slope_cv$.geo)), #convierte a sf
crs = 4326) |>
select(-.geo) |> #elimina columna de geometria obsoleta
mutate(cv = stdDev / mean) #calcula coeficiente de variaci√≥n
# Corre script externo para cargar
source(here::here("Scripts", "00_funcion_carga_ucs_procesadas_qs.R"), encoding = "UTF-8")
# Asignaci√≥n de id √∫nico para cada pol√≠gono
ucs_rao_sf <- ucs_rao_sf |>
sf::st_make_valid() |> #valida geometrias problem√°ticas
dplyr::select(id_creado, UCSuelo, AREA_HA)
ucs_rao_sf <- ucs_rao_sf[!st_is_empty(ucs_rao_sf), ]
#Se verifica visulalmente
ggplot(data = ucs_rao_sf) +
geom_sf(aes(fill = UCSuelo), color = NA) +
theme_void() +
theme(legend.position = "none")
# Ruta al CSV combinado
dem_cv <- read_csv(here::here("Data", "OUT_covars_csv","OUT_DEM_combinado.csv" ))
# Convierte geometr√≠a desde .geo (GeoJSON como texto) a objeto sf
dem_cv_sf <- st_as_sf(
data.frame(dem_cv, geometry = geojson_sf(dem_cv$.geo)), #convierte a sf
crs = 4326) |>
select(-.geo) |> #elimina columna de geometria obsoleta
mutate(cv = stdDev / mean) #calcula coeficiente de variaci√≥n
# Ruta al CSV combinado
slope_cv <- read_csv(here::here("Data", "OUT_covars_csv","OUT_SLOPE_combinado.csv" ))
# Convierte geometr√≠a desde .geo (GeoJSON como texto) a objeto sf
slope_cv_sf <- st_as_sf(
data.frame(slope_cv, geometry = geojson_sf(slope_cv$.geo)), #convierte a sf
crs = 4326) |>
select(-.geo) |> #elimina columna de geometria obsoleta
mutate(cv = stdDev / mean) #calcula coeficiente de variaci√≥n
str(ucs_rao_sf)
View(ucs_rao_sf)
ucs_rao_sf <- ucs_rao_sf |>
sf::st_make_valid()
View(ucs_rao_sf)
# Corre script externo para cargar
source(here::here("Scripts", "00_funcion_carga_ucs_procesadas_qs.R"), encoding = "UTF-8")
View(ucs_rao_sf)
# Asignaci√≥n de id √∫nico para cada pol√≠gono
ucs_rao_sf <- ucs_rao_sf |>
sf::st_make_valid() |> #valida geometrias problem√°ticas
dplyr::select(id_creado, UCSuelo, AREA_HA, Q)
# Inicializa vector de estado
status_vector <- rep(NA_character_, nrow(dem_cv_sf))
# Recorre el log y asigna el estado a cada fila seg√∫n rango
for (i in seq_len(nrow(registro_dem))) {
fila_inicio <- registro_dem$start_idx[i]
fila_fin    <- registro_dem$end_idx[i]
status_val  <- registro_dem$status[i]
status_vector[fila_inicio:fila_fin] <- status_val
}
# A√±adir al objeto sf
dem_cv_sf$status <- status_vector
# Ruta al CSV combinado
dem_cv <- read_csv(here::here("Data", "OUT_covars_csv","OUT_DEM_combinado.csv" ))
# Convierte geometr√≠a desde .geo (GeoJSON como texto) a objeto sf
dem_cv_sf <- st_as_sf(
data.frame(dem_cv, geometry = geojson_sf(dem_cv$.geo)), #convierte a sf
crs = 4326) |>
select(-.geo) |> #elimina columna de geometria obsoleta
mutate(cv = stdDev / mean) #calcula coeficiente de variaci√≥n
# Ruta al CSV combinado
slope_cv <- read_csv(here::here("Data", "OUT_covars_csv","OUT_SLOPE_combinado.csv" ))
# Convierte geometr√≠a desde .geo (GeoJSON como texto) a objeto sf
slope_cv_sf <- st_as_sf(
data.frame(slope_cv, geometry = geojson_sf(slope_cv$.geo)), #convierte a sf
crs = 4326) |>
select(-.geo) |> #elimina columna de geometria obsoleta
mutate(cv = stdDev / mean) #calcula coeficiente de variaci√≥n
str(ucs_rao_sf)
str(dem_cv_sf)
str(slope_cv_sf)
View(slope_cv_sf)
#Para exportar como .R plano
# knitr::purl('05_analisis_glm_hotspots.qmd')
if (!"pacman" %in% installed.packages()) install.packages("pacman")
pacman::p_load(
here,        # rutas del proyecto
remotes,     # instalar desde GitHub
sf,          # vectores espaciales
geojsonio,   # GeoJSON ‚Üî objetos R
geojsonsf,   # GeoJSON ‚Üî sf r√°pido
dplyr,       # manipulaci√≥n tabular
tidyr,
purrr,       # funciones map*
broom,
readr,       # leer CSV r√°pido
performance,
ggplot2,     # gr√°ficos
ggpubr,
patchwork,   # unir gr√°ficos
wesanderson, # paletas de color
qs           # guardar objetos r√°pido
)
# Selecci√≥n entorno ya existente antes de cualquier llamado que use Python
reticulate::use_condaenv("rgee_py", required = TRUE)
## Librer√≠as que usan Python
library(reticulate)
library(rgee)
library(googledrive)
# ==== Autenticaci√≥n y backend Python ====
ee_clean_user_credentials()      # Limpia credenciales de GEE
ee_clean_pyenv()           # Limpia variables de entorno de reticulate
reticulate::py_run_string("import ee; ee.Authenticate()")
reticulate::py_run_string("import ee; ee.Initialize(project='even-electron-461718-g2')")
# === Autenticaci√≥n Google Drive ===
googledrive::drive_auth()
# Corre script externo para cargar
source(here::here("Scripts", "00_funcion_carga_ucs_procesadas_qs.R"), encoding = "UTF-8")
# Asignaci√≥n de id √∫nico para cada pol√≠gono
ucs_rao_sf <- ucs_rao_sf |>
sf::st_make_valid() |> #valida geometrias problem√°ticas
dplyr::select(id_creado, UCSuelo, AREA_HA, Q)
ucs_rao_sf <- ucs_rao_sf[!st_is_empty(ucs_rao_sf), ]
#Se verifica visulalmente
ggplot(data = ucs_rao_sf) +
geom_sf(aes(fill = UCSuelo), color = NA) +
theme_void() +
theme(legend.position = "none")
# Transforma a crs 4326 antes de pasarlo a GEE
ucs_sf_4326 <- st_transform(ucs_rao_sf, 4326)
# #Extrae bounding boxdel √°rea del subconjunto
bb_sf_4326 <- st_bbox(ucs_sf_4326)
# Convertir a rect√°ngulo de Earth Engine
bbox_ee <- ee$Geometry$Rectangle(
coords = list(
bb_sf_4326["xmin"],
bb_sf_4326["ymin"],
bb_sf_4326["xmax"],
bb_sf_4326["ymax"]
),
geodesic = FALSE
)
# Temperatura superficial (LST)
lst_media <- ee$ImageCollection("LANDSAT/LC08/C02/T1_L2")$
filterBounds(bbox_ee)$
filterDate("2013-01-01", "2023-01-01")$
map(function(img) {
img$select("ST_B10")$multiply(0.00341802)$add(149)
})$
median()$
rename("lst")
# Visualizaci√≥n
Map$setCenter(-74, 4, 5)
Map$addLayer(
lst_media,
visParams = list(min = 270, max = 320, palette = c("blue","white","red")),
name  = "LST mediana"
)
vhvv_media <- ee$ImageCollection("COPERNICUS/S1_GRD")$
filterBounds(bbox_ee)$
filterDate("2015-01-01", "2024-01-01")$
filter(ee$Filter$listContains("transmitterReceiverPolarisation", "VV"))$
filter(ee$Filter$listContains("transmitterReceiverPolarisation", "VH"))$
map(function(img) {
img$select("VH")$
divide(img$select("VV"))$
rename("vhvv")
})$
median()$
rename("vhvv")
# Visualizaci√≥n en el visor de rgee
Map$setCenter(lon = -74, lat = 4, zoom = 5)
Map$addLayer(
vhvv_media,
visParams = list(min = 0, max = 2, palette = c("brown", "white", "blue")),
name = "VH/VV mediana"
)
registro_lst <- procesamiento_lotes_imagen(ucs_sf_4326, image = lst_media, start_idx = 1, max_index = 43384, batch_s = 300, reduce_batch_by = 3, variable_name = "LST_media", scale = 100)
registro_vvvh <- procesamiento_lotes_imagen(ucs_sf_4326, image = vhvv_media, start_idx = 1, max_index = 43384, batch_s = 400, reduce_batch_by = 4, variable_name = "VHVV_media", scale = 50)
source(here::here("Scripts", "00_funcion_procesamiento_lotes_imagen.R"), encoding = "UTF-8")
registro_vvvh <- procesamiento_lotes_imagen(ucs_sf_4326, image = vhvv_media, start_idx = 1, max_index = 43384, batch_s = 300, reduce_batch_by = 3, variable_name = "VHVV_media", scale = 50)
