---
title: "Análisis de regresión con modelos lineales generalziados (GLM)"
author: "Carlos M. Guío Blanco"
format: html
editor: visual
---

Este cuaderno implementa en un solo flujo la conexión de R con Google Earth Engine para derivar atributos geomorfométricos e hidroclimáticos satelitales, cuantificar la heterogeneidad interna de estos atributos para cada Unidad Cartográfica de Suelo (UCS) mediante el coeficiente de variación, y finalmente ajustar un modelo logístico que use estas covariables satelitales para explicar la ocurrencia de “hotspots” de pedodiversidad.

**Estructura del script**

1.  **Inicialización**: carga de librerías y autenticación en Earth Engine.
2.  **Carga de vectores**: UCS armonizadas para área de estudio (Andina, Caribe, Pacífico).
3.  **Derivación de rasters**: extracción y cálculo de elevacón, pendiente, curvatura vertical (TAGEE), temperatura superficial (Landsat) y VH/VV (Sentinel 1).
4.  **Extracción de métricas**: media, desviación estándar y CV por polígono para cada variable.
5.  **Modelado**: ensamblaje de datos y ajuste de un GLM logit ponderado por área para predecir hotspots.

```{r configuracion}

#Para exportar como .R plano
# knitr::purl('05_analisis_glm_hotspots.qmd')

if (!"pacman" %in% installed.packages()) install.packages("pacman")
pacman::p_load(
  here,        # rutas del proyecto
  remotes,     # instalar desde GitHub
  sf,          # vectores espaciales
  geojsonio,   # GeoJSON ↔ objetos R
  geojsonsf,   # GeoJSON ↔ sf rápido
  dplyr,       # manipulación tabular
  tidyr,
  purrr,       # funciones map*
  broom,
  readr,       # leer CSV rápido
  performance,
  ggplot2,     # gráficos
  ggpubr,
  patchwork,   # unir gráficos
  wesanderson, # paletas de color
  qs           # guardar objetos rápido
)

# Selección entorno ya existente antes de cualquier llamado que use Python
reticulate::use_condaenv("rgee_py", required = TRUE)

## Librerías que usan Python 
library(reticulate)
library(rgee)
library(googledrive)

# ==== Autenticación y backend Python ====
ee_clean_user_credentials()      # Limpia credenciales de GEE
ee_clean_pyenv()           # Limpia variables de entorno de reticulate
reticulate::py_run_string("import ee; ee.Authenticate()")
reticulate::py_run_string("import ee; ee.Initialize(project='even-electron-461718-g2')")

# === Autenticación Google Drive ===
googledrive::drive_auth()
```

Prueba de funcionamiento de rgee

```{r verifica_configuracion}

# Se consultan datos de DEM
img <- ee$Image("USGS/SRTMGL1_003")

#Consulta que propiedades están disponibles
img$propertyNames()$getInfo()

# Consultar una propiedad específica, e.g. keywords
img$get("keywords")$getInfo()
```

## 1. Carga de datos vectoriales

**Carga de datos de pedodiversidad de UCS**

Los datos producto del procesamiento de Rao, se han subido a un repositorio de Zenodo.

```{r carga_pedodiversidad}

# Corre script externo para cargar
source(here::here("Scripts", "00_funcion_carga_ucs_procesadas_qs.R"), encoding = "UTF-8")

# Asignación de id único para cada polígono
ucs_rao_sf <- ucs_rao_sf |> 
  sf::st_make_valid() |> #valida geometrias problemáticas
  dplyr::select(id_creado, UCSuelo, AREA_HA, Q) 

ucs_rao_sf <- ucs_rao_sf[!st_is_empty(ucs_rao_sf), ]

#Se verifica visulalmente
ggplot(data = ucs_rao_sf) +
  geom_sf(aes(fill = UCSuelo), color = NA) +  
  theme_void() +                             
  theme(legend.position = "none") 
```

**Armonización**

Se definen parámetros de extensión, CRS y resolución para armonizar los datos de GEE con con los datos de pedodiversidad de UCS. Para la definición del área de recorte se toma un buffer sobre el objeto de sf. Esto amortiguará posteriormente efectos de borde en el cálculo de la diversidad. No se recomienda enviar el objeto completo y hacer el buffer en GEE, dado que el envío de un ubjeto con numerosos multipoligonos (como es el caso) es prohibitivo en GEE. Los envios no pueden superar 10MB por tarea.

```{r transforma_crs}

# Transforma a crs 4326 antes de pasarlo a GEE
ucs_sf_4326 <- st_transform(ucs_rao_sf, 4326)


# #Extrae bounding boxdel área del subconjunto
bb_sf_4326 <- st_bbox(ucs_sf_4326)

```

Crea geometria de bbox en GEE usando las coordenadas del bbox creado en R con sf.

```{r  tansform_ee}

# Convertir a rectángulo de Earth Engine
bbox_ee <- ee$Geometry$Rectangle(
  coords = list(
    bb_sf_4326["xmin"], 
    bb_sf_4326["ymin"], 
    bb_sf_4326["xmax"], 
    bb_sf_4326["ymax"]
    ),
  geodesic = FALSE
)

```

## 2. Derivación de variables raster en GEE

A continuación se calculan los índices geomorfométricos e hidroclimáticos. Primero se declaran los objetos raster y se visualizan para verificar. Todos los raster se visualizan en su resolución original.

### 2.1 DEM

Se define el objeto raster de elevación y se visualiza su extensión.

```{r extraccion_dem}

# Carga y suavizado del DEM SRTM 30 m
dem_clip <- ee$Image("USGS/SRTMGL1_003")$clip(bbox_ee)

# Visualiza en el visor antes de exportar (verifica recorte)
Map$setCenter(lon = -74, lat = 4, zoom = 5)
Map$addLayer(
  dem_clip,
  visParams = list(min = 0, max = 3000,
                   palette = viridis::viridis(10)), 
  name = "DEM SRTM (nativo 30m)"
  )

```

### 2.2 Pendiente

```{r extraccion_pendiente}

# Procesamiento de pendiente (slope) a partir del SRTM
slope_clip <- ee$Terrain$
  slope(ee$Image("USGS/SRTMGL1_003"))$
  clip(bbox_ee)$
  multiply(180/pi)$
  rename("slope_deg")

# Visualiza en el visor antes de exportar (verifica recorte)
Map$setCenter(lon = -74, lat = 4, zoom = 5)
Map$addLayer(
  slope_clip,
  visParams = list(min = 0, max = 360,
                   palette = viridis::viridis(10)), 
  name = "Pendiente SRTM (nativo 30m)"
  )
```

### 2.3 Curvatura vertical

A continuación se invoca la función terrainAnalysis del módulo TAGEE en GEE. Al hacerlo se calcula en la nube de Earth Engine un conjunto completo de atributos geomorfométricos a partir del DEM de entrada.TAGEE utliza un DEM base de ...

Cada vez que se llama a py_install() o importa un nuevo módulo con reticulate::import(), reticulate reinicia o “reconfigure” el intérprete Python, y por tanto se debe repetir la inicialización de Earth Engine.

```{r}

# Bloque único de setup (solo la primera vez)
if (!py_module_available("tagee")) {
  py_install(c("tagee","ee_extra","regex","jsbeautifier"),
             envname="rgee_py", pip=TRUE)
}
tagee <- import("tagee",    convert = FALSE)
eeextra <- import("ee_extra", convert = FALSE)

reticulate::py_run_string("import ee; ee.Initialize(project='even-electron-461718-g2')")

# Ejecuta el análisis de terreno (devuelve un ee$Image con múltiples bandas)
dem_attr <- tagee$terrainAnalysis(dem)

# Extrae la banda de Curvatura Vertical
vc_clip <- dem_attr$select("VerticalCurvature")$clip(bbox_ee)


Map$setCenter(lon = -74, lat = 4, zoom = 5)
Map$addLayer(
  vc_clip,
  visParams = list(
    min     = -0.00005,
    max     = +0.00005,
    palette = viridis::viridis(5)
  ),
  name = "Curvatura vertical (±0.00005)"
)

```

### 2.4 Temperatura superficial

La temperatura superficial se obtiene a partir de imágenes de Landsat 8, las cuales tienen resolución de 100m. Se obitene en unidades de ... se transforma...

```{r}

# Temperatura superficial (LST)
lst_media <- ee$ImageCollection("LANDSAT/LC08/C02/T1_L2")$
  filterBounds(bbox_ee)$
  filterDate("2013-01-01", "2023-01-01")$
  map(function(img) {
    img$select("ST_B10")$multiply(0.00341802)$add(149)
  })$
  median()$
  rename("lst")

# Visualización
Map$setCenter(-74, 4, 5)
Map$addLayer(
  lst_media,
  visParams = list(min = 270, max = 320, palette = c("blue","white","red")),
  name  = "LST mediana"
)

```

### 2.5 Índice de polarización

```{r}

vhvv_media <- ee$ImageCollection("COPERNICUS/S1_GRD")$
  filterBounds(bbox_ee)$
  filterDate("2015-01-01", "2024-01-01")$
  filter(ee$Filter$listContains("transmitterReceiverPolarisation", "VV"))$
  filter(ee$Filter$listContains("transmitterReceiverPolarisation", "VH"))$
  map(function(img) {
    img$select("VH")$
      divide(img$select("VV"))$
      rename("vhvv")
  })$
  median()$
  rename("vhvv")

# Visualización en el visor de rgee
Map$setCenter(lon = -74, lat = 4, zoom = 5)
Map$addLayer(
  vhvv_media,
  visParams = list(min = 0, max = 2, palette = c("brown", "white", "blue")),
  name = "VH/VV mediana"
)

```

## 3. Extracción de métricas

La función se encuentra en un script externo. Esta ...

...los raster se muestrean a 50m si su resolución es mas fina, lo cual equivale a escala 1:100.000. Si la resolución es mas gruesa, se utiliza la que esté disponible.

```{r}

source(here::here("Scripts", "00_funcion_procesamiento_lotes_imagen.R"), encoding = "UTF-8")

registro_dem <- procesamiento_lotes_imagen(ucs_sf_4326, image = dem_clip, start_idx = 1, max_index = 43384, variable_name = "DEM", scale = 50)

registro_slope <- procesamiento_lotes_imagen(ucs_sf_4326, image = slope_clip, start_idx = 1, max_index = 43384, variable_name = "SLOPE", scale = 50)

registro_lst <- procesamiento_lotes_imagen(ucs_sf_4326, image = lst_media, start_idx = 1, max_index = 43384, batch_s = 300, reduce_batch_by = 3, variable_name = "LST_media", scale = 100)

registro_vvvh <- procesamiento_lotes_imagen(ucs_sf_4326, image = vhvv_media, start_idx = 1, max_index = 43384, batch_s = 400, reduce_batch_by = 4, variable_name = "VHVV_media", scale = 50)



```

Verificación de tasks enviados

```{r}

verificar_tasks_enviados <- function(log_df) { library(dplyr) library(rgee)

# Extraer todas las tareas activas/pendientes/finalizadas tasks <- ee_manage_task_list() |> as.data.frame() |> arrange(description, state, update_time) |> group_by(description) |> slice_tail(n = 1) |> # conserva solo la última tarea por nombre ungroup() |> select(description, state)

# Unir con el log original según descripción log_df_verificado <- log_df |> left_join(tasks, by = c("task_description" = "description")) |> rename(status_real = state)

return(log_df_verificado) }
```

**Post procesamiento de .csv**

El código a continuación lee todos los .csv de una propiedad (por ejemplo, "slope"),los combina en un solo data.frame, lo guarda como OUT_slope_combinado.csv (o OUT\_<propiedad>\_combinado.csv según corresponda), y lo sube automáticamente al repositorio del proyecto, usando el paquete googledrive.

```{r reubicar_googledrive}

combinar_y_subir_csv <- function(propiedad,
                                 carpeta_drive_id_origen = "17yxwhlpgL4EG8inI5u8Nwi08wOrnhJiM",  # GEE_exports
                                 carpeta_drive_id_destino = "1qJ5S25TZaFWzueNhx1M4Gr3P8JYWKGeU",  # Proyecto
                                 carpeta_temporal = "tmp_csv") {

  # Crea carpeta temporal local si no existe
  if (!dir.exists(carpeta_temporal)) {
    dir.create(carpeta_temporal)
  }

  # Listar archivos en Google Drive (solo .csv con prefijo exacto)
  archivos_drive <- googledrive::drive_ls(
    path = as_id(carpeta_drive_id_origen),
    pattern = glue::glue("^{propiedad}_.*\\.csv$")
  ) |>
    dplyr::filter(stringr::str_ends(name, ".csv"))

  if (nrow(archivos_drive) == 0) {
    stop(glue::glue("No se encontraron archivos CSV para la propiedad '{propiedad}' en GEE_exports."))
  }

  message(glue::glue("📥 Descargando {nrow(archivos_drive)} archivos CSV para '{propiedad}'..."))

  # Descargar archivos al directorio temporal
  purrr::walk2(
    archivos_drive$name,
    archivos_drive$id,
    ~ googledrive::drive_download(
      file = as_id(.y),
      path = file.path(carpeta_temporal, .x),
      overwrite = TRUE
    )
  )

  # Leer y combinar
  archivos_locales <- list.files(path = carpeta_temporal,
                                 pattern = paste0("^", propiedad, "_.*\\.csv$"),
                                 full.names = TRUE)

  combinado <- purrr::map_dfr(archivos_locales, readr::read_csv, show_col_types = FALSE)

  # Escribir archivo combinado
  nombre_salida <- paste0("OUT_", propiedad, "_combinado.csv")
  ruta_salida <- file.path(carpeta_temporal, nombre_salida)
  readr::write_csv(combinado, ruta_salida)

  # Subir a carpeta final de proyecto en Drive
  archivo_subido <- googledrive::drive_upload(
    media = ruta_salida,
    path = as_id(carpeta_drive_id_destino),
    name = nombre_salida,
    overwrite = TRUE
  )

  message(glue::glue("✅ Archivo combinado subido: {archivo_subido$name} (ID: {archivo_subido$id})"))

  # Limpieza automática
  unlink(carpeta_temporal, recursive = TRUE)
  message("🧹 Archivos temporales eliminados.")
}

```

Aplica la función para las covariables

```{r}

combinar_y_subir_csv("DEM")

combinar_y_subir_csv("SLOPE")
```

Se convierte geometria de geojson a sf

```{r}


# Ruta al CSV combinado
dem_cv <- read_csv(here::here("Data", "OUT_covars_csv","OUT_DEM_combinado.csv" ))

# Convierte geometría desde .geo (GeoJSON como texto) a objeto sf
dem_cv_sf <- st_as_sf(
  data.frame(dem_cv, geometry = geojson_sf(dem_cv$.geo)), #convierte a sf
  crs = 4326) |>
  select(-.geo) |> #elimina columna de geometria obsoleta
  mutate(cv = stdDev / mean) #calcula coeficiente de variación

# Ruta al CSV combinado
slope_cv <- read_csv(here::here("Data", "OUT_covars_csv","OUT_SLOPE_combinado.csv" ))

# Convierte geometría desde .geo (GeoJSON como texto) a objeto sf
slope_cv_sf <- st_as_sf(
  data.frame(slope_cv, geometry = geojson_sf(slope_cv$.geo)), #convierte a sf
  crs = 4326) |>
  select(-.geo) |> #elimina columna de geometria obsoleta
  mutate(cv = stdDev / mean) #calcula coeficiente de variación


```

Se añaden columnas de log

```{r}

# Inicializa vector de estado
status_vector <- rep(NA_character_, nrow(dem_cv_sf))

# Recorre el log y asigna el estado a cada fila según rango
for (i in seq_len(nrow(registro_dem))) {
  fila_inicio <- registro_dem$start_idx[i]
  fila_fin    <- registro_dem$end_idx[i]
  status_val  <- registro_dem$status[i]

  status_vector[fila_inicio:fila_fin] <- status_val
}

# Añadir al objeto sf
dem_cv_sf$status <- status_vector
```

## 4. Modelado GLM

Ya que `dem_cv_sf`, `slope_cv_sf` y `ucs_rao_sf` comparten `id_creado` como identificador único, se hace un `left_join` sucesivo para combinar sus métricas

```{r}

# Extraer solo columnas útiles de dem y slope
dem_df <- dem_cv_sf |> 
  st_drop_geometry() |> 
  select(id_creado, dem_cv = cv)

slope_df <- slope_cv_sf |> 
  st_drop_geometry() |> 
  select(id_creado, slope_cv = cv)

# Unir a la tabla base
modelo_df <- ucs_rao_sf |>
  mutate(
    Q = if_else(Q == 0, 1e-3, Q),               # evitar log(0)
    Qdens = Q / AREA_HA,                        # diversidad por unidad de área
    log_Qdens = log(Qdens),                     # log-transformación
    log_Qdens01 = (log_Qdens - min(log_Qdens)) / 
                  (max(log_Qdens) - min(log_Qdens)) # escalado entre 0–1
  ) |>
  left_join(
    dem_cv_sf |> st_drop_geometry() |> select(id_creado, dem_cv = cv),
    by = "id_creado"
  ) |>
  left_join(
    slope_cv_sf |> st_drop_geometry() |> select(id_creado, slope_cv = cv),
    by = "id_creado"
  ) 

```

Separo los datos con y sin NA, para inspección y para correr modelo

```{r}

# Subconjunto sin NA: usado para modelado
modelo_df_completo <- modelo_df |> drop_na(log_Qdens, dem_cv, slope_cv)

# Subconjunto con al menos un NA
modelo_df_NA <- modelo_df |> filter(
  is.na(log_Qdens) | is.na(dem_cv) | is.na(slope_cv)
)
```

Se establecen los percentiles y clasifican los extremos:

```{r}

umbral95 <- quantile(modelo_df_completo$log_Qdens, 0.95, na.rm = TRUE)

# 1. Agregar variable binaria a modelo_df_completo
modelo_df_completo <- modelo_df_completo |>
  mutate(
    log_Qdens_hot95 = as.integer(log_Qdens >= umbral95)
  )

```

Se explora la distribucion de las covariables

```{r}

summary(modelo_df_completo$dem_cv)
hist(modelo_df_completo$dem_cv, breaks = 100)
```

Se corre un modelo GLM binomial para explicar los hotspots

```{r}

# 2. Ajustar modelo directamente sobre modelo_df_completo
glm_hot <- glm(log_Qdens_hot95 ~ dem_cv + slope_cv,
               data = modelo_df_completo,
               family = binomial())

# 3. Calcular predicciones y residuos en la misma tabla
modelo_df_completo <- modelo_df_completo |>
  mutate(
    prob_hot95 = predict(glm_hot, newdata = modelo_df_completo, type = "response"),
    resid_hot95 = residuals(glm_hot, type = "response")
  )

#Resumen estadístico
summary(glm_hot)
performance::r2_tjur(glm_hot)


```

### 4.1 Visualización de resultados

Líneas de regresión con intervalos, puntos y R²

```{r}


# Curva de respuesta usando predicción sobre una grilla
newdata_dem <- data.frame(
  dem_cv = seq(min(modelo_df_completo$dem_cv), max(modelo_df_completo$dem_cv), length.out = 200),
  slope_cv = mean(modelo_df_completo$slope_cv, na.rm = TRUE)
)

newdata_dem$prob <- predict(glm_hot, newdata = newdata_dem, type = "response")

ggplot(modelo_df_completo, aes(x = dem_cv, y = log_Qdens_hot95)) +
  geom_jitter(height = 0.05, alpha = 0.3) +
  geom_line(data = newdata_dem, aes(x = dem_cv, y = prob), color = "blue", size = 1) +
  labs(
    title = "Curva ajustada: prob(hotspot) ~ dem_cv",
    x = "DEM CV",
    y = "Hotspot observado (0/1) y predicho"
  )

```

Mapas de predicción y residuo

```{r}

# Mapa de predicción (probabilidad de ser hotspot)
map_pred_hot <- ggplot(modelo_df) +
  geom_sf(aes(fill = prob_hot95), color = NA) +
  scale_fill_viridis_c(option = "B") +
  labs(title = "Predicción: Probabilidad de Hotspot (≥95%)")

# Mapa de residuo del modelo binomial
map_resid_hot <- ggplot(modelo_df) +
  geom_sf(aes(fill = resid_hot95), color = NA) +
  scale_fill_gradient2() +
  labs(title = "Residuo modelo binomial")

# Mostrar juntos
map_pred_hot + map_resid_hot
```
