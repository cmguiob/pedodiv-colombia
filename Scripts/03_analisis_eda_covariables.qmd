---
title: "An√°lisis de exploratorio de covariables"
author: "Carlos M. Gu√≠o Blanco"
format: html
editor: visual
---

Este cuaderno implementa en un solo flujo la conexi√≥n de R con Google Earth Engine para derivar atributos geomorfom√©tricos e hidroclim√°ticos satelitales, cuantificar la heterogeneidad interna de estos atributos para cada Unidad Cartogr√°fica de Suelo (UCS) mediante el coeficiente de variaci√≥n,

**Estructura del script**

1.  **Inicializaci√≥n**: carga de librer√≠as y autenticaci√≥n en Earth Engine.
2.  **Carga de vectores**: UCS armonizadas para √°rea de estudio (Andina, Caribe, Pac√≠fico).
3.  **Derivaci√≥n de rasters**: extracci√≥n y c√°lculo de elevac√≥n, pendiente, curvatura vertical (TAGEE), temperatura superficial (Landsat) y VH/VV (Sentinel 1).
4.  **Extracci√≥n de m√©tricas**: media, desviaci√≥n est√°ndar y CV por pol√≠gono para cada variable.

```{r configuracion}

#Para exportar como .R plano
# knitr::purl('03_analisis_eda_covariables.qmd')

if (!"pacman" %in% installed.packages()) install.packages("pacman")
pacman::p_load(
  here,        # rutas relativas del proyecto
  sf,          # lectura y manipulaci√≥n de objetos espaciales vectoriales
  httr,        # peticiones HTTP REST (consulta servicio Mapa Geol√≥gico)
  geojsonsf,   # GeoJSON ‚Üî sf r√°pido (geojson_sf)
  dplyr,       # gram√°tica de datos: mutate, select, joins
  tidyr,       # ‚úó (no usado; pivot, unnest‚Ä¶)
  stringr,     # utilidades de texto y regex
  purrr,       # programaci√≥n funcional: map*, walk*
  broom,       # ‚úó (no usado; tidy de modelos)
  readr,       # lectura/escritura r√°pida de CSV
  ggdist,      # distribuciones y ‚Äòraincloud‚Äô/histinterval
  scales,      # transformaciones y breaks de ejes
  ggplot2,     # visualizaci√≥n de datos
  patchwork,   # combinaci√≥n de gr√°ficos ggplot
  wesanderson, # paletas continuas y discretas
  qs           # ‚úó (no usado; serializaci√≥n r√°pida .qs)
)

#Paleta de colores
pal <- wes_palette("Zissou1", 100, type = "continuous")

# Ajusta tama√±o de letra para todo e lscript
theme(base_size = 14)

# Selecci√≥n entorno ya existente antes de cualquier llamado que use Python
reticulate::use_condaenv("rgee_py", required = TRUE)

## Librer√≠as que usan Python 
library(reticulate)
library(rgee)
library(googledrive)

# ==== Autenticaci√≥n y backend Python ====
# Se fuerzan credenciales limpias para evitar colisiones de proyectos GEE entre sesiones
ee_clean_user_credentials()      # Limpia credenciales de GEE
ee_clean_pyenv()           # Limpia variables de entorno de reticulate
reticulate::py_run_string("import ee; ee.Authenticate()")
reticulate::py_run_string("import ee; ee.Initialize(project='even-electron-461718-g2')") #cuenta gmail propia
#reticulate::py_run_string("import ee; ee.Initialize(project='optimal-signer-459113-i1')") #cuenta UNAL

# === Autenticaci√≥n Google Drive ===
googledrive::drive_auth()
```

Prueba de funcionamiento de rgee

```{r verifica_configuracion}

# Se consultan datos de DEM
img <- ee$Image("USGS/SRTMGL1_003")

#Consulta que propiedades est√°n disponibles
img$propertyNames()$getInfo()

# Consultar una propiedad espec√≠fica, e.g. keywords
img$get("keywords")$getInfo()
```

## 1. Carga de datos vectoriales

### 1.1 Carga de datos de pedodiversidad de UCS

Los datos producto del procesamiento de Rao, se han subido a un repositorio de Zenodo. Estos se utilizan ac√° para derivar las covariables a nivel de pol√≠gono de UCS. Por tal raz√≥n, solo se importan variables que no tengan NAs.

```{r carga_pedodiversidad}

# Corre script externo para cargar
source(here::here("Scripts", "00_funcion_carga_ucs_procesadas_qs.R"), encoding = "UTF-8")

# Asignaci√≥n de id √∫nico para cada pol√≠gono
ucs_rao_sf <- ucs_rao_sf |> 
  sf::st_make_valid() |> #valida geometrias problem√°ticas
  dplyr::select(id_creado, UCSuelo, AREA_HA) 

ucs_rao_sf <- ucs_rao_sf[!st_is_empty(ucs_rao_sf), ]

#Se verifica visulalmente
ggplot(data = ucs_rao_sf) +
  geom_sf(aes(fill = UCSuelo), color = NA) +  
  theme_void() +                             
  theme(legend.position = "none") 
```

### 1.2 Carga de datos de unidades geol√≥gicas SGC

Las unidades geol√≥gicas son un insumo que se utilizar√° posteriormente para los modelos jer√°rquicos. Estos datos se cargan via API del servicio de ArcGIS que usa el Servicio Geol√≥gico Colombiano. No requieren token.

```{r geologia_descarga_reclasificacion}

# Se desagrega la url b√°sica en sus componentes
url <- httr::parse_url("https://srvags.sgc.gov.co/arcgis/rest/services/Mapa_Geologico_Colombia/Mapa_Geologico_Colombia_V2023/MapServer")

layer_id <- "733"

url$path <- paste(url$path, layer_id, "query", sep = "/")

# Se agregan componentes a la URL para solicitud de informaci√≥n
url$query <- list(where = "1=1", # para recuperar todos los features
                  outFields = "*", #para recuperar todos los campos
                  returnGeometry = "true", #retorna geometrias
                  f = "geojson") #retorna formato geojson

# Se construye la url
url_solicitud <- httr::build_url(url)

# Para recuperar los datos espaciales se usa la librer√≠a sf
respuesta <- httr::GET(url_solicitud)

#Se examina la respuesta
print(respuesta)

# Descarga del mapa geol√≥gico 1 : 500 000 y clasificaci√≥n de unidades por era (m√°s joven)
geo_sf_wgs84 <- sf::st_read(url_solicitud) |>
  sf::st_make_valid() |>
  mutate(
    # LIMPIEZA -----------------------------------------------------------------
    edad_limpia = Edad %>% 
      str_replace_all("\\?", "") %>%    # quita ‚Äú?‚Äù
      str_trim() %>%                    # quita espacios extremos
      str_squish(),                     # colapsa espacios m√∫ltiples
    
    # RECLASIFICACI√ìN POR ERA (la M√ÅS JOVEN domina) ----------------------------
    era_geo = case_when(
      # 1) CENOZOICO  ----------------------------------------------------------
      str_detect(edad_limpia, regex(
        "paleoceno|eoceno|oligoceno|mioceno|plioceno|pleistoceno|holoceno|
         aquitaniano|burdigaliano|langhiano|serravaliano|tortoniano|messiniano|
         zancliano|rupeliano|thanetiano|lutetiano|bartoniano|priaboniano|
         selandiano|daniense|chattiano",
        ignore_case = TRUE)
      ) ~ "Cenozoico",
      
      # 2) MESOZOICO  ----------------------------------------------------------
      str_detect(edad_limpia, regex(
        "tri√°sico|jur√°sico|cret√°cico|berriasiano|valanginiano|barremiano|
         aptiano|albiano|cenomaniano|turoniano|coniaciano|santoniano|
         campaniano|maastrichtiano",
        ignore_case = TRUE)
      ) ~ "Mesozoico",
      
      # 3) PALEOZOICO ----------------------------------------------------------
      str_detect(edad_limpia, regex(
        "c√°mbrico|ordov√≠cico|sil√∫rico|dev√≥nico|mississipiano|pridoliano|
         carbon√≠fero|pennsylvaniano|p√©rmico",
        ignore_case = TRUE)
      ) ~ "Paleozoico",
      
      # 4) PROTEROZOICO --------------------------------------------------------
      str_detect(edad_limpia, regex(
        "sideriano|rhyaciano|orosiriano|statheriano|calymmiano|ectasiano|
         steniano|toniano|criog√©nico|ediacariano|mesoproterozoico|
         neoproterozoico|proterozoico",
        ignore_case = TRUE)
      ) ~ "Proterozoico",
      
      # 5) SIN DATO ------------------------------------------------------------
      TRUE ~ "Sin_dato"
    )
  ) |>
  select(descripcion_geo = Descripcion, era_geo)



#Se visualizan datos geogr√°ficamente (edad, sin leyenda)
p_mapa_geo <- ggplot2::ggplot(geo_sf_wgs84) +
  geom_sf(aes(fill = era_geo), color = NA) +
  scale_fill_manual(
    name   = "Era geol√≥gica",                         # (1) t√≠tulo de la leyenda
    breaks = c("Cenozoico", "Mesozoico",              # (3) orden joven ‚Üí antiguo
               "Paleozoico", "Proterozoico", "Sin_dato"),
    values = c(                                       # (2) colores por categor√≠a
      Cenozoico   = "#f8ea1e",
      Mesozoico   = "#5bc5ea",
      Paleozoico  = "#a9c6a8",
      Proterozoico= "#ea5173",
      Sin_dato    = "gray90"
    ),
    drop = FALSE                                      # muestra todas las clases aunque falten
  ) +
  theme_minimal()

p_mapa_geo
```

### 1.3 Armonizaci√≥n con GEE

Se definen par√°metros de extensi√≥n, CRS y resoluci√≥n para armonizar los datos de GEE con con los datos de pedodiversidad de UCS. Para la definici√≥n del √°rea de recorte se toma un buffer sobre el objeto de sf. Esto amortiguar√° posteriormente efectos de borde en el c√°lculo de la diversidad. No se recomienda enviar el objeto completo y hacer el buffer en GEE, dado que el env√≠o de un ubjeto con numerosos multipoligonos (como es el caso) es prohibitivo en GEE. Los envios no pueden superar 10MB por tarea.

```{r transforma_crs}

# Transforma a crs 4326 antes de pasarlo a GEE
ucs_sf_4326 <- st_transform(ucs_rao_sf, 4326)


# #Extrae bounding boxdel √°rea del subconjunto
bb_sf_4326 <- st_bbox(ucs_sf_4326)

```

Crea geometria de bbox en GEE usando las coordenadas del bbox creado en R con sf.

```{r  tansform_ee}

# Convertir a rect√°ngulo de Earth Engine
bbox_ee <- ee$Geometry$Rectangle(
  coords = list(
    bb_sf_4326["xmin"], 
    bb_sf_4326["ymin"], 
    bb_sf_4326["xmax"], 
    bb_sf_4326["ymax"]
    ),
  geodesic = FALSE
)

```

## 2. Derivaci√≥n de variables raster en GEE

A continuaci√≥n se calculan los √≠ndices geomorfom√©tricos e hidroclim√°ticos. Primero se declaran los objetos raster y se visualizan para verificar. Todos los raster se visualizan en su resoluci√≥n original.

### 2.1 DEM

Se define el objeto raster de elevaci√≥n y se visualiza su extensi√≥n.

```{r extraccion_dem}

# Carga y suavizado del DEM SRTM 30 m
dem_clip <- ee$Image("USGS/SRTMGL1_003")$clip(bbox_ee)

# Visualiza en el visor antes de exportar (verifica recorte)
Map$setCenter(lon = -74, lat = 4, zoom = 5)
Map$addLayer(
  dem_clip,
  visParams = list(min = 0, max = 3000,
                   palette = viridis::viridis(10)), 
  name = "DEM SRTM (nativo 30m)"
  )

```

### 2.2 Pendiente

```{r extraccion_pendiente}

# Procesamiento de pendiente (slope) a partir del SRTM
slope_clip <- ee$Terrain$
  slope(ee$Image("USGS/SRTMGL1_003"))$
  clip(bbox_ee)$
  rename("slope_deg")  # valores ya est√°n en grados

# Visualiza en el visor antes de exportar (verifica recorte)
Map$setCenter(lon = -74, lat = 4, zoom = 5)
Map$addLayer(
  slope_clip,
  visParams = list(min = 0, max = 50,
                   palette = viridis::viridis(10)), 
  name = "Pendiente SRTM (nativo 30m)"
  )
```

### 2.3 Curvatura vertical

A continuaci√≥n se invoca la funci√≥n terrainAnalysis del m√≥dulo TAGEE en GEE. Al hacerlo se calcula en la nube de Earth Engine un conjunto completo de atributos geomorfom√©tricos a partir del DEM de entrada.TAGEE utliza un DEM base de ...

Cada vez que se llama a py_install() o importa un nuevo m√≥dulo con reticulate::import(), reticulate reinicia o ‚Äúreconfigure‚Äù el int√©rprete Python, y por tanto se debe repetir la inicializaci√≥n de Earth Engine.

```{r}

# Bloque √∫nico de setup (solo la primera vez)
if (!py_module_available("tagee")) {
  py_install(c("tagee","ee_extra","regex","jsbeautifier"),
             envname="rgee_py", pip=TRUE)
}
tagee <- import("tagee",    convert = FALSE)
eeextra <- import("ee_extra", convert = FALSE)

reticulate::py_run_string("import ee; ee.Initialize(project='even-electron-461718-g2')")

# Ejecuta el an√°lisis de terreno (devuelve un ee$Image con m√∫ltiples bandas)
dem_attr <- tagee$terrainAnalysis(dem_clip)

# Extrae la banda de Curvatura Vertical
vc_clip <- dem_attr$select("VerticalCurvature")$clip(bbox_ee)


Map$setCenter(lon = -74, lat = 4, zoom = 5)
Map$addLayer(
  vc_clip,
  visParams = list(
    min     = -0.00005,
    max     = +0.00005,
    palette = viridis::viridis(5)
  ),
  name = "Curvatura vertical (¬±0.00005)"
)

```

### 2.4 Temperatura superficial

La temperatura superficial se obtiene a partir de la banda 10 de im√°genes de Landsat 8, las cuales tienen resoluci√≥n de 100m. Se toma una serie de tiempo de 10 a√±os: de 2013 a 2023. Se derivan dos conjuntos de datos:

-   El CV temporal es un proxy de **variabilidad clim√°tica en el tiempo**, pixel a pixel, en un per√≠odo de 10 a√±os.

**Coeficiente de variaci√≥n temporal de LST** (por p√≠xel, ¬∞C)

Se usa la colecci√≥n para extraer estad√≠sticas **temporales por p√≠xel**, como promedio, desviaci√≥n est√°ndar o coeficiente de variaci√≥n (CV). Se transforma a ¬∞C antes de calcular las estad√≠sticas. El coeficiente de variaci√≥n obtenido por pixel representa la variabilidad de la temperatura en el tiempo para cada coordenada. El promedio de los CVs se promedia luego para cada pol√≠gono.

```{r}

# Colecci√≥n de L8 LST convertida a ¬∞C
lst_collection <- ee$ImageCollection("LANDSAT/LC08/C02/T1_L2")$
  filterBounds(bbox_ee)$            #descarta las im√°genes cuyo footprint no toca tu bbox_ee
  filterDate("2013-01-01", "2023-01-01")$
  map(function(img) {
    img$select("ST_B10")$
      multiply(0.00341802)$          # escala
      add(149.0)$                    # offset
      subtract(273.15)$              # K ‚Üí ¬∞C
      rename("lst_celsius")$
      clip(bbox_ee)                  # recorte geom√©trico
  })

# ‚îÄ‚îÄ CV TEMPORAL POR P√çXEL ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
lst_temp_mean <- lst_collection$mean()$rename("lst_temp_mean")
lst_temp_sd   <- lst_collection$reduce(ee$Reducer$stdDev())$rename("lst_temp_sd")
lst_temp_cv   <- lst_temp_sd$divide(lst_temp_mean)$rename("lst_temp_cv")

# Verificaci√≥n visual en el visor de Earth Engine
Map$setCenter(lon = -74, lat = 4, zoom = 5)
Map$addLayer(
  lst_temp_cv, 
  list(min = 0, max = 0.3, palette = c("blue","orange","red")),
  "LST CV temporal"
)
```

**Media espacial de LST**

En este bloque se calcula la **media espacial** de la colecci√≥n ya corregida (cada p√≠xel representa la temperatura mediana en 10 a√±os). Es un resumen central espacial, complementario al CV, que representa condiciones t√©rmicas t√≠picas en cada lugar.

```{r}


# Colecci√≥n de L8 LST convertida a ¬∞C
lst_collection <- ee$ImageCollection("LANDSAT/LC08/C02/T1_L2")$
  filterBounds(bbox_ee)$            #descarta las im√°genes cuyo footprint no toca tu bbox_ee
  filterDate("2013-01-01", "2023-01-01")$
  map(function(img) {
    img$select("ST_B10")$
      multiply(0.00341802)$          # escala
      add(149.0)$                    # offset
      subtract(273.15)$              # K ‚Üí ¬∞C
      rename("lst_celsius")$
      clip(bbox_ee)          # recorte geom√©trico
  })

# ‚îÄ‚îÄ (2) MEDIA ESPACIAL (PROMEDIO) POR P√çXEL ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
lst_media_espacial <- lst_collection$mean()$rename("lst_media_espacial")

# Verificaci√≥n visual en el visor de Earth Engine
Map$setCenter(lon = -74, lat = 4, zoom = 5)
Map$addLayer(
  lst_media_espacial, 
  list(min = 10, max = 45, palette = c("blue","white","red")),
  "LST media (¬∞C)"
)


```

### 2.5 Precipitaci√≥n

**CV temporal de la precipitaci√≥n (CHIRPS, 2013-2023)**

Para cuantificar cu√°n irregular es la lluvia a lo largo del a√±o, tomamos la base diaria CHIRPS (0,05¬∞ ‚âà 5 km) y la agregamos a totales mensuales por p√≠xel. Sobre los 132 meses resultantes (enero 2013 ‚Äì diciembre 2023) calculamos, para cada celda, la media y la desviaci√≥n est√°ndar mensual y derivamos el coeficiente de variaci√≥n (CV = sd / media). El mapa final resalta los lugares donde la precipitaci√≥n mensual es m√°s variable: valores altos indican reg√≠menes pluviales muy irregulares, mientras que valores bajos corresponden a climas con lluvias m√°s estables en el tiempo. Al promediar este CV dentro de cada UCS obtendremos una medida de variabilidad clim√°tica propia de cada pol√≠gono.

```{r}

# Colecci√≥n diaria recortada
chirps_daily <- ee$ImageCollection("UCSB-CHG/CHIRPS/DAILY")$
  filterBounds(bbox_ee)$  #descarta las im√°genes cuyo footprint no toca tu bbox_ee
  filterDate("2013-01-01", "2023-01-01")

# ‚îÄ‚îÄ Agregaci√≥n mensual (mm por mes) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
chirps_monthly_ic <- ee$ImageCollection(
  ee$List$sequence(2013, 2023)$map(ee_utils_pyfunc(function(y) {
    ee$List$sequence(1, 12)$map(ee_utils_pyfunc(function(m) {
      start <- ee$Date$fromYMD(y, m, 1)
      end   <- start$advance(1, "month")
      chirps_daily$
        filterDate(start, end)$
        sum()$                         # mm del mes
        clip(bbox_ee)$
        set("system:time_start", start)
    }))
  }))$flatten()
)

# ‚îÄ‚îÄ (1) CV TEMPORAL POR P√çXEL (mensual) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
precip_mean_temp <- chirps_monthly_ic$mean()$rename("precip_mean_temp")
precip_sd_temp   <- chirps_monthly_ic$reduce(ee$Reducer$stdDev())$rename("precip_sd_temp")
precip_cv_temp   <- precip_sd_temp$divide(precip_mean_temp)$rename("precip_cv_temp")

# Verificaci√≥n visual en el visor de Earth Engine
Map$setCenter(lon = -74, lat = 4, zoom = 5)
Map$addLayer(
  precip_cv_temp,
  list(min = 0, max = 1, palette = c("blue","orange","red")),
  "Precip CV temporal (mensual)"
)

```

**Precipitaci√≥n media espacial (CHIRPS, 2013-2023)**

A partir de la misma serie diaria CHIRPS calculamos el promedio diario de precipitaci√≥n para todo el periodo 2013-2023. Esta operaci√≥n produce, por p√≠xel, la lluvia media (mm d√≠a‚Åª¬π) representativa de la √∫ltima d√©cada. Al reducir esta capa sobre los pol√≠gonos de suelo obtenemos, para cada UCS, un indicador sencillo de disponibilidad h√≠drica promedio que servir√° como covariable en los modelos de pedodiversidad.

```{r}

# Colecci√≥n diaria recortada
chirps_daily <- ee$ImageCollection("UCSB-CHG/CHIRPS/DAILY")$
  filterBounds(bbox_ee)$ # descarta las im√°genes cuyo footprint no toca tu bbox_ee
  filterDate("2013-01-01", "2023-01-01")

# ‚îÄ‚îÄ (2) MEDIA ESPACIAL POR P√çXEL (mm/d√≠a) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
precip_media_espacial <- chirps_daily$
  mean()$
  rename("precip_media_espacial")$
  clip(bbox_ee)          # recorte geom√©trico

# Verificaci√≥n visual en el visor de Earth Engine
Map$setCenter(lon = -74, lat = 4, zoom = 5)
Map$addLayer(
  precip_media_espacial,
  list(min = 0, max = 15, palette = c("blue","white","red")),
  "Precip media espacial (mm/d√≠a)"
)
```

## 3. Extracci√≥n de m√©tricas

Falta texto coherence: La funci√≥n se encuentra en un script externo.... rgee para la extracci√≥n. ...los raster se muestrean a 50m si su resoluci√≥n es mas fina, lo cual equivale a escala 1:100.000. Si la resoluci√≥n es mas gruesa, se utiliza la que est√© disponible.

```{r exporta_covariables_poligonos}

# Extrae estad√≠sticas (mean / sd) por UCS y las env√≠a a Drive en lotes adaptativos
source(here::here("Scripts", "00_funcion_procesamiento_lotes_imagen.R"), encoding = "UTF-8")

registro_dem <- procesamiento_lotes_imagen(ucs_sf_4326, image = dem_clip, start_idx = 1, max_index = 43384, variable_name = "DEM", scale = 50)

registro_slope <- procesamiento_lotes_imagen(ucs_sf_4326, image = slope_clip, start_idx = 1, max_index = 43384, batch_s = 400, reduce_batch_by = 4, variable_name = "SLOPE", scale = 50)

registro_lst_esp <- procesamiento_lotes_imagen(ucs_sf_4326, image = lst_media_espacial, start_idx = 1, max_index = 43384, batch_s = 300, reduce_batch_by = 3, variable_name = "LST_media_espacial", scale = 50)

registro_lst_temp <- procesamiento_lotes_imagen(ucs_sf_4326, image = lst_temp_cv, start_idx = 1, max_index = 43384, batch_s = 300, reduce_batch_by = 3, variable_name = "LST_cv_temporal", scale = 50)

registro_precip_cv_temporal <- procesamiento_lotes_imagen(ucs_sf_4326, image = precip_cv_temp, start_idx = 1, max_index = nrow(ucs_sf_4326), batch_s = 300, reduce_batch_by = 3, variable_name  = "PRECIP_cv_temporal", scale = 500)

registro_precip_esp <- procesamiento_lotes_imagen(ucs_sf_4326, image = precip_media_espacial, start_idx = 1, max_index = 43384, batch_s = 300,   reduce_batch_by = 3, variable_name  = "PRECIP_media_espacial", scale = 500)


```

**Post procesamiento de .csv**

El c√≥digo a continuaci√≥n lee todos los .csv de una propiedad (por ejemplo, "slope"),los combina en un solo data.frame, lo guarda como OUT_slope_combinado.csv (o OUT\_<propiedad>\_combinado.csv seg√∫n corresponda), y lo sube autom√°ticamente al repositorio del proyecto, usando el paquete googledrive.

```{r reubicar_googledrive}

# Copia local de archivos combinados para reproducibilidad offline
combinar_y_subir_csv <- function(propiedad,
                                 carpeta_drive_id_origen = "17yxwhlpgL4EG8inI5u8Nwi08wOrnhJiM",  # GEE_exports
                                 carpeta_drive_id_destino = "1qJ5S25TZaFWzueNhx1M4Gr3P8JYWKGeU",  # Proyecto
                                 carpeta_temporal = "tmp_csv") {

  # Crea carpeta temporal local si no existe
  if (!dir.exists(carpeta_temporal)) {
    dir.create(carpeta_temporal)
  }

  # Listar archivos en Google Drive (solo .csv con prefijo exacto)
  archivos_drive <- googledrive::drive_ls(
    path = as_id(carpeta_drive_id_origen),
    pattern = glue::glue("^{propiedad}_.*\\.csv$")
  ) |>
    dplyr::filter(stringr::str_ends(name, ".csv"))

  if (nrow(archivos_drive) == 0) {
    stop(glue::glue("No se encontraron archivos CSV para la propiedad '{propiedad}' en GEE_exports."))
  }

  message(glue::glue("üì• Descargando {nrow(archivos_drive)} archivos CSV para '{propiedad}'..."))

  # Descargar archivos al directorio temporal
  purrr::walk2(
    archivos_drive$name,
    archivos_drive$id,
    ~ googledrive::drive_download(
      file = as_id(.y),
      path = file.path(carpeta_temporal, .x),
      overwrite = TRUE
    )
  )

  # Leer y combinar
  archivos_locales <- list.files(path = carpeta_temporal,
                                 pattern = paste0("^", propiedad, "_.*\\.csv$"),
                                 full.names = TRUE)

  combinado <- purrr::map_dfr(archivos_locales, readr::read_csv, show_col_types = FALSE)

  # Escribir archivo combinado
  nombre_salida <- paste0("OUT_", propiedad, "_combinado.csv")
  ruta_salida <- file.path(carpeta_temporal, nombre_salida)
  readr::write_csv(combinado, ruta_salida)

  # Subir a carpeta final de proyecto en Drive
  archivo_subido <- googledrive::drive_upload(
    media = ruta_salida,
    path = as_id(carpeta_drive_id_destino),
    name = nombre_salida,
    overwrite = TRUE
  )

  message(glue::glue("‚úÖ Archivo combinado subido: {archivo_subido$name} (ID: {archivo_subido$id})"))

  # Limpieza autom√°tica
  unlink(carpeta_temporal, recursive = TRUE)
  message("üßπ Archivos temporales eliminados.")
}

```

Aplica la funci√≥n para las covariables. Esto se corre solo una vez, para combinar los csv por lotes.

```{r aplica_funcion_combinacion}

combinar_y_subir_csv("DEM")

combinar_y_subir_csv("SLOPE")

combinar_y_subir_csv("LST_cv_temporal")

combinar_y_subir_csv("LST_media_espacial") #falta

combinar_y_subir_csv("precip_cv_temporal")

combinar_y_subir_csv("precip_media_espacial") #falta


```

Se cargan y se convierte geometria de geojson a sf

```{r}

# === DEM (elevaci√≥n media y variabilidad espacial) ===

# Ruta al CSV combinado
dem_cv <- read_csv(here::here("Data", "OUT_covars_csv","OUT_DEM_combinado.csv" ))

# Convierte columna .geo (GeoJSON) a geometr√≠a v√°lida y calcula m√©tricas
covars_dem  <- st_as_sf(
  data.frame(dem_cv, geometry = geojson_sf(dem_cv$.geo)),
  crs = 4326
  ) |>
  mutate(
    dem_cv = stdDev / mean,                   # coeficiente de variaci√≥n
    log_dem_cv = log(dem_cv + 1),             # log-transformaci√≥n
    dem_cv_dens = dem_cv / AREA_HA,           # CV densificado por √°rea
    log_dem_cv_dens = log(dem_cv_dens + 1),    # log densificado
    # Estandarizadas
    dem_cv_z = scale(dem_cv)[, 1],
    log_dem_cv_z = scale(log_dem_cv)[, 1],
    dem_cv_dens_z = scale(dem_cv_dens)[, 1],
    log_dem_cv_dens_z = scale(log_dem_cv_dens)[, 1],
    dem_mean_z = scale(mean)[, 1]
    ) |>
  rename(dem_mean = mean) |>
    select(-.geo, -stdDev) |>


# === SLOPE (pendiente media y su variabilidad espacial) ===

slope_cv <- read_csv(here::here("Data", "OUT_covars_csv", "OUT_SLOPE_combinado.csv"))

covars_slope <- st_as_sf(
  data.frame(slope_cv, geometry = geojson_sf(slope_cv$.geo)),
  crs = 4326
  ) |>
  mutate(
    slope_cv = stdDev / mean,
    log_slope_cv = log(slope_cv + 1),
    slope_cv_dens = slope_cv / AREA_HA,
    log_slope_cv_dens = log(slope_cv_dens + 1),
    # Estandarizadas
    slope_cv_z = scale(slope_cv)[, 1],
    log_slope_cv_z = scale(log_slope_cv)[, 1],
    slope_cv_dens_z = scale(slope_cv_dens)[, 1],
    log_slope_cv_dens_z = scale(log_slope_cv_dens)[, 1],
    slope_mean_z = scale(mean)[, 1]
    ) |>
  rename(slope_mean = mean) |>
  select(-.geo, -stdDev)


# === LST media espacial (media de 2013-2023 por p√≠xel, luego agregada) =====

lst_media_esp <- read_csv(
  here::here("Data", "OUT_covars_csv", "OUT_LST_media_espacial_combinado.csv"),
  show_col_types = FALSE
)

covars_lst_media <- st_as_sf(
  data.frame(lst_mean_esp, geometry = geojson_sf(lst_mean_esp$.geo)),
  crs = 4326
  ) |>
  mutate(
    log_lst_mean = log(mean + 1),
    lst_mean_dens       = mean / AREA_HA,
    log_lst_mean_dens   = log(lst_mean_dens + 1),
    # Estandarizadas
    lst_mean_z          = scale(mean)[, 1],
    log_lst_mean_z      = scale(log_lst_mean)[, 1],
    lst_mean_dens_z     = scale(lst_mean_dens)[, 1],
    log_lst_mean_dens_z = scale(log_lst_mean_dens)[, 1]
  ) |>
  rename(lst_mean = mean) |>
  select(-.geo, -stdDev)


# === LST CV temporal (media de CV temporal por p√≠xel, luego agregada por pol√≠gono) ===

lst_cv_temp <- read_csv(here::here("Data", "OUT_covars_csv", "OUT_LST_cv_temporal_combinado.csv"))

covars_lst_cv_temp <- st_as_sf(
  data.frame(lst_cv_temp, geometry = geojson_sf(lst_cv_temp$.geo)),
  crs = 4326
  ) |>
  mutate(
    log_lst_cv_temp = log(mean + 1), #mean es el promedio de las cv de la serie de tiempo para un pol√≠gono
    lst_cv_temp_dens = mean / AREA_HA,
    log_lst_cv_temp_dens = log(lst_cv_temp_dens + 1),
    # Estandarizadas
    lst_cv_temp_z = scale(mean)[, 1],
    log_lst_cv_temp_z = scale(log_lst_cv_temp)[, 1],
    lst_cv_temp_dens_z = scale(lst_cv_temp_dens)[, 1],
    log_lst_cv_temp_dens_z = scale(log_lst_cv_temp_dens)[, 1]
  ) |>
  rename(
    lst_cv_temp = mean,
  ) |>
  select(-.geo, -stdDev)

# === Precipitaci√≥n CV temporal mensual (CHIRPS 2013-2023) ====================

precip_cv_temp <- read_csv(
  here::here("Data", "OUT_covars_csv", "OUT_PRECIP_cv_temporal_combinado.csv"),
  show_col_types = FALSE
)

covars_precip_cv_temp <- st_as_sf(
  data.frame(precip_cv_temp, geometry = geojson_sf(precip_cv_temp$.geo)),
  crs = 4326
  ) |>
  mutate(
    log_precip_cv_temp        = log(mean + 1),
    precip_cv_temp_dens       = mean / AREA_HA,
    log_precip_cv_temp_dens   = log(precip_cv_temp_dens + 1),
    # Estandarizadas
    precip_cv_temp_z          = scale(mean)[, 1],
    log_precip_cv_temp_z      = scale(log_precip_cv_temp)[, 1],
    precip_cv_temp_dens_z     = scale(precip_cv_temp_dens)[, 1],
    log_precip_cv_temp_dens_z = scale(log_precip_cv_temp_dens)[, 1]
  ) |>
  rename(precip_cv_temp = mean) |>
  select(-.geo, -stdDev)

# === Precipitaci√≥n media espacial (2013-2023, mm) =======================

precip_mean_esp <- read_csv(
  here::here("Data", "OUT_covars_csv", "OUT_precip_mediana_espacial_combinado.csv"),
  show_col_types = FALSE
)

covars_precip_mean <- st_as_sf(
  data.frame(precip_mean_esp, geometry = geojson_sf(precip_mean_esp$.geo)),
  crs = 4326
  ) |>
  mutate(
    log_precip_mean        = log(mean + 1),
    precip_mean_dens       = mean / AREA_HA,
    log_precip_mean_dens   = log(precip_mean_dens + 1),
    # Estandarizadas
    precip_mean_z          = scale(mean)[, 1],
    log_precip_mean_z      = scale(log_precip_mean)[, 1],
    precip_mean_dens_z     = scale(precip_mean_dens)[, 1],
    log_precip_mean_dens_z = scale(log_precip_mean_dens)[, 1]
  ) |>
  rename(precip_mean = mean) |>
  select(-.geo, -stdDev)

```

Para asegurar la continuidad espacial de los an√°lisis, se verifican los intervalos incompletos entre 1 y 43384. El script llamar√° a `procesamiento_lotes_imagen()` s√≥lo sobre los intervalos faltantes, conservando la l√≥gica de lotes adaptativos.

```{r}

# FUNCI√ìN utilitaria que  detecta filas faltantes y las agrupa en intervalos
ids_faltantes_por_intervalo <- function(id_vector,
                                        id_total = 1:43384) {

  faltantes <- setdiff(id_total, id_vector) |> sort()
  if (length(faltantes) == 0)
    return(tibble::tibble(start_idx = integer(), end_idx = integer()))

  # agrupa contiguos
  cortes <- c(1, which(diff(faltantes) > 1) + 1, length(faltantes) + 1)
  tibble::tibble(
    start_idx = faltantes[cortes[-length(cortes)]],
    end_idx   = faltantes[cortes[-1] - 1]
  )
}

# LISTA de tablas sf ya cargadas (una por covariable)
covars_list <- list(
  DEM_mean_cv        = covars_dem,
  SLOPE_mean_cv      = covars_slope,
  LST_mean_spatial   = covars_lst_media,
  LST_cv_temporal    = covars_lst_cv_temp,
  PRECIP_mean_spatial= covars_precip_mean,
  PRECIP_cv_temporal = covars_precip_cv_temp
)

# Verifica faltantes, imprime resumen y guarda intervalos
intervalos_faltantes <- purrr::imap_dfr(
  covars_list,
  function(tbl, nombre) {
    falt <- ids_faltantes_por_intervalo(tbl$id_creado)
    dplyr::mutate(falt, variable = nombre, .before = 1)
  }
)

print(intervalos_faltantes)

# ---------------------------------------------------------------------------
# Bucle para re-lanzar descargas s√≥lo donde falte
# ---------------------------------------------------------------------------

intervalos_faltantes |> 
  dplyr::filter(variable == "PRECIP_cv_temporal") |>        # elige la covariable
  purrr::pwalk(function(variable, start_idx, end_idx) {

    mensaje <- glue::glue("‚Üª Descargando {variable}: {start_idx}‚Äì{end_idx}")
    message(mensaje)

    procesamiento_lotes_imagen(
      sf_data     = ucs_sf_4326,
      image       = precip_cv_temp,        # ajustar para cada imagen
      start_idx   = start_idx,
      max_index   = end_idx,
      batch_s     = 50,
      reduce_batch_by = 3,
      variable_name  = variable,
      scale       = 500                     # ajustar para cada imagen
    )
  })

```


## 4. EDA covariables

Ya que `dem_cv_sf`, `slope_cv_sf` y `ucs_rao_sf` comparten `id_creado` como identificador √∫nico, se hace un `left_join` sucesivo para combinar sus m√©tricas

```{r}

# Elimina la columna de indices creada por GEE
dem_sf <- covars_dem |> select(-system.index)
slope_sf <- covars_slope |>  select(-system.index)
lst_cv_sf <- covars_lst_cv_temp |> select(-system.index)
lst_med_sf <- covars_lst_media |> select(-system.index)
precip_cv_sf <- covars_precip_cv_temp |> select(-system.index)
precip_med_sf <- covars_precip_cv_temp |> select(-system.index)

# Unir a la tabla base
modelo_df <- ucs_rao_sf |>
  mutate(
    #Q = if_else(Q == 0, 1e-3, Q),               # evitar log(0)
    Qdens = Q / AREA_HA,                        # diversidad por unidad de √°rea
    log_Qdens = log(Qdens + 1),                     # log-transformaci√≥n
    log_Qdens01 = (log_Qdens - min(log_Qdens)) / 
                  (max(log_Qdens) - min(log_Qdens)) # escalado entre 0‚Äì1
  ) |>
  left_join(dem_sf |> st_drop_geometry(),        by = c("id_creado", "AREA_HA", "UCSuelo")) |>
  left_join(slope_sf |> st_drop_geometry(),      by = c("id_creado", "AREA_HA", "UCSuelo")) |>
  left_join(lst_cv_sf  |> st_drop_geometry(),    by = c("id_creado", "AREA_HA", "UCSuelo")) |>
  left_join(lst_med_sf |> st_drop_geometry(),    by = c("id_creado", "AREA_HA", "UCSuelo")) |>
  left_join(precip_cv_sf |> st_drop_geometry(),  by = c("id_creado", "AREA_HA", "UCSuelo")) |>
  left_join(precip_med_sf |> st_drop_geometry(), by = c("id_creado", "AREA_HA", "UCSuelo")) |>
  

```

Se verifican visualmente las distribuciones de las covariables para SLOPE

```{r}
p_slope_mean <- ggplot(modelo_df, aes(slope_mean)) +
  ggdist::stat_histinterval(fill = "#56B4E9", color = "black", .width = c(0.5, 0.9)) +
  geom_density(aes(y = after_stat(scaled)), color = "#FFD700", size = 0.8) +
  labs(title = "Distribuci√≥n de media de SLOPE", y = "Frecuencia", x = "Media de DEM")

p_slope_mean


p_log_slope_cv <- ggplot(modelo_df, aes(log_slope_cv)) +
  ggdist::stat_histinterval(fill = "#56B4E9", color = "black", .width = c(0.5, 0.9)) +
  geom_density(aes(y = after_stat(scaled)), color = "#FFD700", size = 0.8) +
  labs(title = "Distribuci√≥n de log CV de SLOPE", y = "Frecuencia", x = "Log CV de SLOPE")

p_log_slope_cv

p_log_slope_cv_dens <- ggplot(modelo_df, aes(log_slope_cv_dens)) +
  ggdist::stat_histinterval(fill = "#56B4E9", color = "black", .width = c(0.5, 0.9)) +
  geom_density(aes(y = after_stat(scaled)), color = "#FFD700", size = 0.8) +
  labs(title = "Distribuci√≥n de log densidad CV de SLOPE", y = "Frecuencia", x = "Log densidad de CV de SLOPE")

p_log_slope_cv_dens

p_mosaico_distr_slope <- p_slope_mean + p_log_slope_cv + p_log_slope_cv_dens + plot_layout(ncol = 3, widths = c(1, 1))
```

Se verifican visualmente las distribuciones de las covariables para DEM

```{r}
p_dem_mean <- ggplot(modelo_df, aes(dem_mean)) +
  ggdist::stat_histinterval(fill = "#56B4E9", color = "black", .width = c(0.5, 0.9)) +
  geom_density(aes(y = after_stat(scaled)), color = "#FFD700", size = 0.8) +
  labs(title = "Distribuci√≥n de media de DEM", y = "Frecuencia", x = "Media de DEM")

p_dem_mean


p_log_dem_cv <- ggplot(modelo_df, aes(log_dem_cv)) +
  ggdist::stat_histinterval(fill = "#56B4E9", color = "black", .width = c(0.5, 0.9)) +
  geom_density(aes(y = after_stat(scaled)), color = "#FFD700", size = 0.8) +
  labs(title = "Distribuci√≥n de log CV de DEM", y = "Frecuencia", x = "Log media de DEM")

p_log_dem_cv

p_log_dem_cv_dens <- ggplot(modelo_df, aes(log_dem_cv_dens)) +
  ggdist::stat_histinterval(fill = "#56B4E9", color = "black", .width = c(0.5, 0.9)) +
  geom_density(aes(y = after_stat(scaled)), color = "#FFD700", size = 0.8) +
  labs(title = "Distribuci√≥n de log densidad CV de DEM", y = "Frecuencia", x = "Log media de DEM")

p_log_dem_cv_dens

p_mosaico_distr_DEM <- p_dem_mean + p_log_dem_cv + p_log_dem_cv_dens + plot_layout(ncol = 3, widths = c(1, 1))
```

Visualizaci√≥n espacial de las covariables

```{r}
p_mapa_dem_mean <- ggplot(modelo_df |> filter(dem_mean >=0)) +
  geom_sf(aes(fill = dem_mean), color = NA) +
  scale_fill_gradientn(colours = pal, na.value = "white") + 
  labs(title = "Mapa de media de DEM", fill = "Media") +
  theme_minimal()

p_mapa_dem_mean

p_mapa_slope_mean <- ggplot(modelo_df) +
  geom_sf(aes(fill = slope_mean), color = NA) +
  scale_fill_gradientn(colours = pal, na.value = "white") + 
  labs(title = "Mapa de media de SLOPE", fill = "Media") +
  theme_minimal()

p_mapa_slope_mean

p_mapa_log_dem_cv <- ggplot(modelo_df |> filter(log_dem_cv >=0)) +
  geom_sf(aes(fill = dem_cv), color = NA) +
  scale_fill_gradientn(
    colours = pal,
    na.value = "white",
    trans = "log10",
    breaks = scales::trans_breaks("log10", function(x) 10^x)
  ) +
  labs(title = "Mapa de CV de DEM - escalado log", fill = "CV") +
  theme_minimal()

p_mapa_log_dem_cv

p_mapa_log_slope_cv <- ggplot(modelo_df) +
  geom_sf(aes(fill = slope_cv), color = NA) +
  scale_fill_gradientn(
    colours = pal,
    na.value = "white",
    trans = "log10",
    breaks = scales::trans_breaks("log10", function(x) 10^x)
  ) +
  labs(title = "Mapa de log(CV de SLOPE)", fill = "CV") +
  theme_minimal()

p_mapa_log_slope_cv

p_mapa_log_dem_cv_dens <- ggplot(modelo_df) +
  geom_sf(aes(fill = dem_cv_dens), color = NA) +
  scale_fill_gradientn(
    colours = pal,
    na.value = "white",
    trans = "log10",
    breaks = scales::trans_breaks("log10", function(x) 10^x)
  ) +
  labs(title = "Mapa de log(densidad de CV de DEM)", fill = "Densidad CV") +
  theme_minimal()

p_mapa_log_dem_cv_dens

p_mapa_log_slope_cv_dens <- ggplot(modelo_df) +
  geom_sf(aes(fill = slope_cv_dens), color = NA) +
  scale_fill_gradientn(
    colours = pal,
    na.value = "white",
    trans = "log10",
    breaks = scales::trans_breaks("log10", function(x) 10^x)
  ) +
  labs(title = "Mapa de log(densidad de CV de SLOPE)", fill = "Densidad CV") +
  theme_minimal()

p_mapa_log_slope_cv_dens

p_mapas_covs <- p_mapa_dem_mean + p_mapa_slope_mean + p_mapa_log_dem_cv + p_mapa_log_slope_cv + p_mapa_log_dem_cv_dens + p_mapa_log_slope_cv_dens+ plot_layout(ncol = 2, widths = c(1, 1))


#guarda el √∫ltimo gr√°fico generado
ggsave(here("Figures", "mosaico_mapa_covariables_DEM.png"),
       plot = p_mapas_covs,
       width = 8,
       height = 10,
       dpi = 350)

```
