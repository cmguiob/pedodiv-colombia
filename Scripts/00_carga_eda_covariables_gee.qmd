---
title: "Carga y procesamiento de covariables GEE via rgee"
author: "Carlos M. Guío Blanco"
format: html
editor: visual
---

Se debe identificar si Python 3 está instalado, en caso que no, instalarlo. La función de carga de datos de GEE usará la versión de Python 3 instalada. En caso de necesitar direccionar a reticulate a una instalación de python deseada de miniconda, se crea un entorno llamado "rgee_py" con Python 3.12 (compatible y recomendado)

```{r configuracion}

#Para exportar como .R plano
# knitr::purl('05_analisis_glm_rao_colombia.qmd')

# Para cargar librerias se verifica pacman
if ("pacman" %in% installed.packages() == FALSE) install.packages("pacman")

# Carga de librerías "inocentes"
pacman::p_load(char = c("here", "remotes", "sf", "geojsonio","dplyr", "ggplot2", "patchwork", "wesanderson", "qs"))

# ==== Creación de ambiente Miniconda para reticulate ============================

#Esto solo se necesita hacerlo una vez.
#reticulate::conda_create("rgee_py", packages = "python=3.12")
reticulate::py_config()  # Verifica que el python sea Miniconda3/envs/rgee_py/python.exe
ee_check() # Check non-R dependencies

# ==== Selección entorno ya existente antes de cualquier llamado que use Python ====
reticulate::use_condaenv("rgee_py", required = TRUE)
reticulate::py_config() # Asegúrate que la ruta sea TU Miniconda global y TU entorno rgee_py

# Carga librerías que usan Python
library(reticulate)
library(rgee)
library(googledrive)


# ==== Autenticación y backend Python ====
ee_clean_user_credentials()      # Limpia credenciales de GEE
ee_clean_pyenv()           # Limpia variables de entorno de reticulate
reticulate::py_run_string("import ee; ee.Authenticate()")
reticulate::py_run_string("import ee; ee.Initialize(project='even-electron-461718-g2')")

# ==== Inicializa rgee (ignora asset_home si aparece, ya existe) ====
tryCatch(
  rgee::ee_Initialize(drive = FALSE, project = 'even-electron-461718-g2'),
  error = function(e) message("Si pide asset home y ya existe, solo ESC y sigue")
)
```

## 1. Verificación de funcionamiento de rgee

Se prueba una consulta simple

```{r verifica_info}

# Se consultan datos de DEM
img <- ee$Image("USGS/SRTMGL1_003")

#Consulta que propiedades están disponibles
img$propertyNames()$getInfo()

# Consultar una propiedad específica, e.g. keywords
img$get("keywords")$getInfo()
```

Se prueba una visualización simple

```{r verifica_imagen}

vis_params <- list(
  min = 0,
  max = 3000,
  palette = c("440154", "21908d", "fdae61", "fee08b", "ffffbf", "a6d96a", "1a9850")
)

# Centra en Colombia
Map$setCenter(lon = -74, lat = 4, zoom = 5)
Map$addLayer(img, vis_params, "SRTM DEM")
```

## 2. Carga de datos

### 2.1 Carga de datos de pedodiversidad de UCS

Los datos producto del procesamiento de Rao, se han subido a un repositorio de Zenodo.

```{r carga_pedodiversidad}

# Corre script externo
source(here::here("Scripts", "00_funcion_carga_ucs_procesadas_qs.R"), encoding = "UTF-8")

head(ucs_rao_sf)
```

### 2.2 Carga de polígono de área de estudio

Se cargan los polígonos de los departamentos de la zona andina, pacífica y caribe. Se fusionan en uno solo y se armonizan con el crs de pedodiversidad de UCS, para delimitar el área de estudio.

```{r carga_poligono}

# Define ruta y nombre de capa de geopackage de departamentos
deptos_ruta <- here("Data", "INP_departamentos_IGAC_Abril_2025.gpkg")
capa_nombre_deptos <- sf::st_layers(deptos_ruta)$name[1]

# Carga geopackage de dpartamentos
departamentos_sf <- sf::st_read(
  deptos_ruta,
  layer = capa_nombre_deptos,
  quiet = TRUE
  ) |>
  # Se seleccionan 21 departamentos de la zona Andina, Caribe y Pacífica
  dplyr::filter(DeNombre %in% c(
    "Antioquia", 
    "Atlántico",
    "Bolívar",
    "Boyacá",
    "Caldas",
    "Cauca",
    "Cesar",
    "Chocó", 
    "Córdoba",
    "Cundinamarca",
    "Huila",
    "La Guajira",
    "Magdalena",
    "Nariño",
    "Norte de Santander",
    "Quindío",
    "Risaralda",
    "Santander", 
    "Sucre",
    "Tolima",
    "Valle del Cauca")
    ) |>
  tidyr::drop_na()
  

# departamento_1_sf pasa de "SHAPE" a "geometry"
names(departamentos_sf)[names(departamentos_sf) == "SHAPE"] <- "geometry"
departamentos_sf <- sf::st_as_sf(as.data.frame(departamentos_sf), sf_column_name = "geometry")

# Aseguramos que ambos datasets tengan la misma proyección
departamentos_sf <- st_transform(departamentos_sf, st_crs(ucs_rao_sf))

# Se unen los polígonos en uno solo
limite_poly <- st_union(departamentos_sf) 

# Aplica un buffer pequeño (ejemplo: 1 km) para limitar efectos de borde
limite_buffer <- st_buffer(limite_poly, dist = 1000)
```

### 2.3 Carga de datos de Google Earth Engine

A continuación se definien y envían parámetros de procesamiento generales para todos los productos satelitales, para ejecutar en GEE. Los datos ya procesados se envian a Google Drive a la carpeta GEE_exports, desde donde deben reubicarse. Las tareas se puede monitorear en [Earth Engine Task Manager](#0)

Se definen parámetros de extensión, CRS y resolución para armonizar los datos de GEE con con los datos de pedodiversidad de UCS. Para la definición del área de recorte se toma un buffer. Esto amortiguará posteriormente efectos de borde en el cálculo de la diversidad.

```{r parametros_gee}

# Crea el buffer en metros en 9377
buffer_10km_sf <- st_buffer(limite_poly, dist = 10000) 
# TRANSFORMA EL BUFFER A 4326 *ANTES* DE PASARLO A GEE
buffer_10km_sf_4326 <- st_transform(buffer_10km_sf, 4326)
# Convierte buffer a GEE
buffer_10km_gee <- sf_as_ee(buffer_10km_sf_4326)
buffer_10km_bbox <- buffer_10km_gee$bounds()

target_crs <- "EPSG:4326"    # Sistema soportado por GEE para exportación universal
target_scale <- 50           # Resolución de pixel objetivo (50 m)
export_folder <- "GEE_exports" # Carpeta destino en Google Drive "My Drive"
```

**DEM SRTM 30 m (remuestreado a 50 m)**

Se procesa GEE y se envía a cuenta de Google Drive asociada en el proceso de autenticación.

```{r tarea_DEM}

# 1. Selecciona DEM SRTM 30m y recorta al buffer del área de estudio
dem <- ee$Image("USGS/SRTMGL1_003")$clip(buffer_10km_bbox)

# 2. Visualiza en el visor antes de exportar (verifica recorte)
Map$setCenter(lon = -74, lat = 4, zoom = 5)
Map$addLayer(dem, visParams = list(min = 0, max = 3000), name = "DEM SRTM (nativo 30m)")

```

Se **envía una tarea a la nube de Google Earth Engine**. GEE procesa la imagen (el clip, reproyección, remuestreo, etc.) y la **exporta a Google Drive** como un archivo GeoTIFF.

```{r}

# 3. Remuestrea y reproyecta a 50m, CRS 9377 para garantizar co-registro con otras variables
dem_proj <- dem$reproject(crs = target_crs, scale = target_scale)


# 4. Exporta a Google Drive, con todos los parámetros del stack final
task_dem <- ee$batch$Export$image$toDrive(
  image = dem_proj,                          # imagen a exportar
  description = "DEM_SRTM_50m_4326",         # nombre descriptivo de la tarea
  folder = export_folder,                    # carpeta en tu Google Drive
  fileNamePrefix = "DEM_SRTM_50m_4326",      # nombre del archivo
  region = buffer_10km_bbox,                # región a exportar (el buffer de 100 km)
  scale = target_scale,                      # resolución (50 m)
  crs = target_crs,                          # proyección
  maxPixels = 1e13                           # límite para exportar imágenes grandes
)

# 5. Inicia la tarea de exportación (esto se procesa en la nube de GEE).
task_dem$start()
```

**Pendiente a partir SRTM 30 m (remuestreado a 50 m)**

```{r}

# Calcula pendiente (grados) usando el DEM ya recortado
slope <- ee$Terrain$slope(dem)

# Visualiza para revisar el resultado antes de exportar
Map$addLayer(slope, visParams = list(min = 0, max = 45, palette = c("white", "yellow", "red")), name = "Pendiente")

# Reproyecta a 50 m y CRS 4326
slope_proj <- slope$reproject(crs = target_crs, scale = target_scale)

# Exporta a Google Drive
task_slope <- ee$batch$Export$image$toDrive(
  image = slope_proj,
  description = "Slope_50m_4326",
  folder = export_folder,
  fileNamePrefix = "Slope_50m_4326",
  region = buffer_10km_bbox,
  scale = target_scale,
  crs = target_crs,
  maxPixels = 1e13
)
task_slope$start()
```

**LST Landsat 8 (mediana)**

```{r}

# 1. Selecciona la colección de imágenes de Landsat 8 Collection 2 Nivel 2 (procesamiento superficial)
landsat_col <- ee$ImageCollection("LANDSAT/LC08/C02/T1_L2")

# 2. Filtra la colección espacialmente al buffer definido
landsat_col <- landsat_col$filterBounds(buffer_10km_bbox)

# 3. Filtra la colección temporalmente al rango de fechas deseado (2013–2023)
landsat_col <- landsat_col$filterDate("2013-01-01", "2023-01-01")

# 4. Aplica una función a cada imagen para:
#    a) Seleccionar la banda térmica "ST_B10"
#    b) Convertirla a Kelvin según el factor de escala Landsat 8 (ver USGS)
landsat_kelvin <- landsat_col$map(function(img) {
  img$select("ST_B10")$multiply(0.00341802)$add(149.0)$copyProperties(img, img$propertyNames())
})

# 5. Calcula la mediana temporal pixel a pixel (mediana multianual de temperatura superficial)
lst_median <- landsat_kelvin$median()$clip(buffer_10km_bbox)

# 6. Visualiza para verificar valores y cobertura antes de exportar
Map$addLayer(lst_median, visParams = list(min = 270, max = 320, palette = c("blue", "white", "red")), name = "LST (Landsat 8 mediana)")

# 7. Reproyecta a 50 m y CRS 4326 para garantizar co-registro
lst_proj <- lst_median$reproject(crs = target_crs, scale = target_scale)

# 8. Exporta a Google Drive
task_lst <- ee$batch$Export$image$toDrive(
  image = lst_proj,
  description = "LST_Landsat_median_50m_4326",
  folder = export_folder,
  fileNamePrefix = "LST_Landsat_median_50m_4326",
  region = buffer_10km_bbox,
  scale = target_scale,
  crs = target_crs,
  maxPixels = 1e13
)
task_lst$start()

```

**Sentinel-1 VH/VV (Mediana multianual)**

Se usa **Sentinel-1 VH/VV como proxy de humedad superficial** porque en la banda C, la retrodispersión procedente de suelos desnudos o con vegetación rala está fuertemente influida por la constante dieléctrica de la superficie, la cual depende, a su vez, del contenido volumétrico de agua. Utilizar conjuntamente los canales de polarización cruzada (VH) y copolarizada (VV) —o bien su cociente— reduce los efectos de la rugosidad superficial y aumenta la sensibilidad a la humedad (Ulaby & Elachi, Radar Remote Sensing, 1990).

```{r}

# 1. Selecciona la colección Sentinel-1 GRD (Ground Range Detected)
s1_col <- ee$ImageCollection("COPERNICUS/S1_GRD")

# 2. Filtra espacialmente al buffer
s1_col <- s1_col$filterBounds(buffer_10km_bbox)

# 3. Filtra temporalmente al rango deseado (2015–2024)
s1_col <- s1_col$filterDate("2015-01-01", "2024-01-01")

# 4. Filtra imágenes que tengan ambas polarizaciones VV y VH
s1_col <- s1_col$
  filter(ee$Filter$listContains("transmitterReceiverPolarisation", "VV"))$
  filter(ee$Filter$listContains("transmitterReceiverPolarisation", "VH"))

# 5. Filtra solo imágenes en órbita ascendente (opcional, para reducir sesgo angular)
s1_col <- s1_col$filter(ee$Filter$eq("orbitProperties_pass", "ASCENDING"))

# 6. Selecciona solo las bandas VH y VV
s1_col <- s1_col$select(c("VH", "VV"))

# 7. Calcula la razón VH/VV para cada imagen de la colección
vh_vv_ratio <- s1_col$map(function(img) {
  img$select("VH")$divide(img$select("VV"))$rename("VH_VV_ratio")$copyProperties(img, img$propertyNames())
})

# 8. Calcula la mediana temporal pixel a pixel
vh_vv_median <- vh_vv_ratio$median()$clip(buffer_10km_bbox)

# 9. Visualiza antes de exportar
Map$addLayer(vh_vv_median, visParams = list(min = 0, max = 1, palette = c("red", "white", "blue")), name = "Sentinel-1 VH/VV (mediana)")

# 10. Reproyecta y exporta
vh_vv_proj <- vh_vv_median$reproject(crs = target_crs, scale = target_scale)

task_vhvv <- ee$batch$Export$image$toDrive(
  image = vh_vv_proj,
  description = "Sentinel1_VH_VV_median_50m_4326",
  folder = export_folder,
  fileNamePrefix = "Sentinel1_VH_VV_median_50m_4326",
  region = buffer_10km_bbox,
  scale = target_scale,
  crs = target_crs,
  maxPixels = 1e13
)
task_vhvv$start()


```

**Precipitación CHIRPS (mediana multianual)**

```{r}


# 1. Selecciona la colección CHIRPS diaria (UCSB-CHG/CHIRPS/DAILY)
chirps_col <- ee$ImageCollection("UCSB-CHG/CHIRPS/DAILY")

# 2. Filtra al área de trabajo (buffer)
chirps_col <- chirps_col$filterBounds(buffer_10km_bbox)

# 3. Filtra al rango de fechas de interés (2000–2020)
chirps_col <- chirps_col$filterDate("2000-01-01", "2020-12-31")

# 4. Calcula la mediana multianual pixel a pixel
precip_median <- chirps_col$median()$clip(buffer_10km_bbox)

# 5. Visualiza antes de exportar
Map$addLayer(precip_median, visParams = list(min = 0, max = 4000, palette = c("white", "blue")), name = "CHIRPS Precipitación mediana")

# 6. Reproyecta y exporta a 50m y CRS 4326
precip_proj <- precip_median$reproject(crs = target_crs, scale = target_scale)

task_precip <- ee$batch$Export$image$toDrive(
  image = precip_proj,
  description = "CHIRPS_Precip_median_50m_4326",
  folder = export_folder,
  fileNamePrefix = "CHIRPS_Precip_median_50m_4326",
  region = buffer_10km_bbox,
  scale = target_scale,
  crs = target_crs,
  maxPixels = 1e13
)
task_precip$start()

```

Verificación de serie de tiempo

```{r}


```

## 3. Reubicación de los archivos exportados de GEE

```{r}

drive_auth()  # Esto abre una ventana de autenticación en el navegador

# Obtén la carpeta de origen por nombre
carpeta_origen <- drive_get("GEE_exports")

# Lista los archivos en esa carpeta
archivos <- drive_ls(path = carpeta_origen)

carpeta_destino_id <- "1y46LYQ8Ppaszi4qbrAn6SlTdoFfw2hMk"

#Mueve todos los archivos listados a la carpeta de destino por su ID
purrr::walk(archivos$id, function(file_id) {
  drive_mv(as_id(file_id), path = as_id(carpeta_destino_id))
})

# Verifica lista los archivos en la carpeta destino por ID
drive_ls(path = as_id(carpeta_destino_id))

```
